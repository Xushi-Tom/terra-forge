#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import re
import threading
import math
import subprocess
import glob
import shutil
from datetime import datetime
from flask import Flask, request, jsonify, send_file

from config import config, taskStatus, taskProcesses, taskLock
from utils import *

# ä»»åŠ¡åœæ­¢æ ‡å¿—å­—å…¸
taskStopFlags = {}

# æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å‡½æ•°
def generateSmartRecommendations(fileSizeGb, tileType="map", userMinZoom=None, userMaxZoom=None, cpuCount=4, memoryTotalGb=8):
    """
    æ ¹æ®æ–‡ä»¶å¤§å°å’Œç³»ç»Ÿèµ„æºç”Ÿæˆæ™ºèƒ½é…ç½®æ¨è
    
    @param fileSizeGb æ–‡ä»¶å¤§å°ï¼ˆGBï¼‰
    @param tileType ç“¦ç‰‡ç±»å‹ï¼Œå¯é€‰å€¼ï¼šmapï¼ˆåœ°å›¾ï¼‰ã€terrainï¼ˆåœ°å½¢ï¼‰
    @param userMinZoom ç”¨æˆ·æŒ‡å®šçš„æœ€å°ç¼©æ”¾çº§åˆ«
    @param userMaxZoom ç”¨æˆ·æŒ‡å®šçš„æœ€å¤§ç¼©æ”¾çº§åˆ«
    @param cpuCount CPUæ ¸å¿ƒæ•°
    @param memoryTotalGb ç³»ç»Ÿæ€»å†…å­˜ï¼ˆGBï¼‰
    @return åŒ…å«æ¨èé…ç½®çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        recommendations = {}
        
        # æ ¹æ®æ–‡ä»¶å¤§å°å’Œç“¦ç‰‡ç±»å‹è¿›è¡Œä¼˜åŒ–æ¨è
        if tileType == "terrain":
            # åœ°å½¢åˆ‡ç‰‡æ¨èé…ç½®
            if fileSizeGb < 0.5:
                recommendations["maxZoom"] = 16
                recommendations["minZoom"] = 0
                recommendations["processes"] = min(cpuCount // 2, 4)  # åœ°å½¢åˆ‡ç‰‡æ¶ˆè€—æ›´å¤šèµ„æº
                recommendations["maxMemory"] = "4g"  # åœ°å½¢åˆ‡ç‰‡ä½¿ç”¨GBå•ä½
            elif fileSizeGb < 2:
                recommendations["maxZoom"] = 15
                recommendations["minZoom"] = 0
                recommendations["processes"] = min(cpuCount // 2, 6)
                recommendations["maxMemory"] = "6g"
            elif fileSizeGb < 8:
                recommendations["maxZoom"] = 14
                recommendations["minZoom"] = 0
                recommendations["processes"] = min(cpuCount // 2, 8)
                recommendations["maxMemory"] = "8g"
            else:
                recommendations["maxZoom"] = 13
                recommendations["minZoom"] = 0
                recommendations["processes"] = min(cpuCount // 2, 10)
                recommendations["maxMemory"] = "12g"
            
            # åœ°å½¢åˆ‡ç‰‡å›ºå®šé…ç½®
            recommendations["tileFormat"] = "terrain"  # åœ°å½¢ç“¦ç‰‡æ ¼å¼
            recommendations["quality"] = 100
            recommendations["compression"] = True
            recommendations["decompress"] = True
            recommendations["autoZoom"] = True
            recommendations["zoomStrategy"] = "conservative"
            
            # æ ¹æ®ç³»ç»Ÿå†…å­˜è°ƒæ•´
            if memoryTotalGb < 8:
                recommendations["maxMemory"] = "4g"
                recommendations["processes"] = min(recommendations["processes"], 2)
            elif memoryTotalGb < 16:
                recommendations["maxMemory"] = "6g"
                recommendations["processes"] = min(recommendations["processes"], 4)
            elif memoryTotalGb >= 32:
                recommendations["maxMemory"] = "16g"
                recommendations["processes"] = min(recommendations["processes"], 12)
        
        else:
            # åœ°å›¾åˆ‡ç‰‡æ¨èé…ç½®
            if fileSizeGb < 1:
                recommendations["maxZoom"] = 18
                recommendations["minZoom"] = 0
                recommendations["tileFormat"] = "png"
                recommendations["quality"] = 90
                recommendations["processes"] = min(cpuCount - 1, 6)
                recommendations["maxMemory"] = max(2048, int(memoryTotalGb * 1024 * 0.3))  # 30%ç³»ç»Ÿå†…å­˜ï¼ŒMBå•ä½
            elif fileSizeGb < 5:
                recommendations["maxZoom"] = 16
                recommendations["minZoom"] = 0
                recommendations["tileFormat"] = "webp"
                recommendations["quality"] = 85
                recommendations["processes"] = min(cpuCount - 1, 8)
                recommendations["maxMemory"] = max(4096, int(memoryTotalGb * 1024 * 0.4))  # 40%ç³»ç»Ÿå†…å­˜
            elif fileSizeGb < 20:
                recommendations["maxZoom"] = 15
                recommendations["minZoom"] = 0
                recommendations["tileFormat"] = "webp"
                recommendations["quality"] = 80
                recommendations["processes"] = min(cpuCount - 1, 10)
                recommendations["maxMemory"] = max(6144, int(memoryTotalGb * 1024 * 0.5))  # 50%ç³»ç»Ÿå†…å­˜
            else:
                recommendations["maxZoom"] = 14
                recommendations["minZoom"] = 0
                recommendations["tileFormat"] = "webp"
                recommendations["quality"] = 75
                recommendations["processes"] = min(cpuCount - 1, 12)
                recommendations["maxMemory"] = max(8192, int(memoryTotalGb * 1024 * 0.6))  # 60%ç³»ç»Ÿå†…å­˜
            
            # åœ°å›¾åˆ‡ç‰‡é¢å¤–é…ç½®
            recommendations["resampling"] = "bilinear"
            recommendations["autoZoom"] = True
            recommendations["zoomStrategy"] = "conservative"
            recommendations["optimizeFile"] = True
            recommendations["createOverview"] = fileSizeGb > 2  # å¤§æ–‡ä»¶å»ºè®®åˆ›å»ºæ¦‚è§ˆ
            recommendations["useOptimizedMode"] = True
            
            # æ ¹æ®ç³»ç»Ÿå†…å­˜è¿›ä¸€æ­¥è°ƒæ•´
            if memoryTotalGb < 8:
                recommendations["processes"] = min(recommendations["processes"], 4)
                recommendations["maxMemory"] = min(recommendations["maxMemory"], 2048)
            elif memoryTotalGb < 16:
                recommendations["processes"] = min(recommendations["processes"], 6)
                recommendations["maxMemory"] = min(recommendations["maxMemory"], 4096)
        
        # ç”¨æˆ·æŒ‡å®šçš„çº§åˆ«ä¼˜å…ˆ
        if userMinZoom is not None:
            recommendations["minZoom"] = userMinZoom
        if userMaxZoom is not None:
            recommendations["maxZoom"] = userMaxZoom
        
        # ç¡®ä¿è¿›ç¨‹æ•°åˆç†
        recommendations["processes"] = max(1, min(recommendations["processes"], cpuCount))
        
        return recommendations
    except Exception as e:
        logMessage(f"ç”Ÿæˆæ¨èé…ç½®å¤±è´¥: {e}", "ERROR")
        return None

def detectOptimalZoomLevels(filePath):
    """
    æ£€æµ‹åŸºäºæ–‡ä»¶åˆ†è¾¨ç‡çš„æœ€ä½³ç¼©æ”¾çº§åˆ«
    
    @param filePath æ–‡ä»¶è·¯å¾„
    @return åŒ…å«æœ€ä½³ç¼©æ”¾çº§åˆ«çš„å­—å…¸ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        info = getFileInfo(filePath)
        if "error" in info:
            return None
        
        # åŸºäºæ–‡ä»¶å¤§å°å’Œåˆ†è¾¨ç‡è®¡ç®—æœ€ä½³çº§åˆ«
        width = info.get("width", 0)
        height = info.get("height", 0)
        
        if width <= 0 or height <= 0:
            return None
        
        # è®¡ç®—åˆé€‚çš„æœ€å¤§çº§åˆ«
        maxDim = max(width, height)
        optimalMaxZoom = min(18, int(math.log2(maxDim / 256)) + 1)
        
        return {
            "minZoom": 0,
            "maxZoom": optimalMaxZoom,
            "reason": f"åŸºäºå›¾åƒåˆ†è¾¨ç‡ {width}x{height} è®¡ç®—"
        }
    except Exception as e:
        logMessage(f"æ£€æµ‹æœ€ä½³çº§åˆ«å¤±è´¥: {e}", "ERROR")
        return None

def optimizeTiff(filePath, outputPath=None, compressionType="lzw"):
    """
    ä¼˜åŒ–TIFFæ–‡ä»¶ï¼ŒåŒ…æ‹¬å‹ç¼©ã€åˆ†å—å’ŒBigTIFFæ”¯æŒ
    
    @param filePath è¾“å…¥TIFFæ–‡ä»¶è·¯å¾„
    @param outputPath è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œä¸ºNoneæ—¶è‡ªåŠ¨ç”Ÿæˆ
    @param compressionType å‹ç¼©ç±»å‹ï¼Œé»˜è®¤ä¸ºlzw
    @return ä¼˜åŒ–åçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        if not outputPath:
            outputPath = filePath.replace(".tif", "_optimized.tif")
        
        # æ„å»ºgdalwarpå‘½ä»¤
        cmd = [
            "gdalwarp",
            "-co", f"COMPRESS={compressionType}",
            "-co", "TILED=YES",
            "-co", "BIGTIFF=IF_SAFER",
            filePath,
            outputPath
        ]
        
        # æ‰§è¡Œä¼˜åŒ–
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = process.communicate()
        
        if process.returncode == 0:
            logMessage(f"TIFFä¼˜åŒ–å®Œæˆ: {outputPath}", "INFO")
            return outputPath
        else:
            logMessage(f"TIFFä¼˜åŒ–å¤±è´¥: {stderr.decode()}", "ERROR")
            return None
    except Exception as e:
        logMessage(f"TIFFä¼˜åŒ–å¼‚å¸¸: {e}", "ERROR")
        return None

def decompressTerrainFiles(terrainDir: str) -> bool:
    """ä½¿ç”¨gzipè§£å‹terrainæ–‡ä»¶"""
    import gzip
    try:
        terrainFiles = []
        for root, dirs, files in os.walk(terrainDir):
            for file in files:
                if file.endswith('.terrain'):
                    terrainFiles.append(os.path.join(root, file))
        
        decompressedCount = 0
        for terrainFile in terrainFiles:
            try:
                # æ£€æŸ¥æ˜¯å¦ä¸ºgzipå‹ç¼©æ–‡ä»¶
                with open(terrainFile, 'rb') as f:
                    magic = f.read(2)
                    if magic == b'\x1f\x8b':  # gzipé­”æ•°
                        # è§£å‹æ–‡ä»¶
                        tempFile = terrainFile + '.tmp'
                        with gzip.open(terrainFile, 'rb') as fIn:
                            with open(tempFile, 'wb') as fOut:
                                shutil.copyfileobj(fIn, fOut)
                        
                        # æ›¿æ¢åŸæ–‡ä»¶
                        os.replace(tempFile, terrainFile)
                        decompressedCount += 1
            except Exception as e:
                logMessage(f"è§£å‹æ–‡ä»¶å¤±è´¥ {terrainFile}: {e}", "ERROR")
                continue
        
        logMessage(f"è§£å‹å®Œæˆï¼Œå¤„ç†äº† {decompressedCount} ä¸ªæ–‡ä»¶")
        return True
    except Exception as e:
        logMessage(f"è§£å‹terrainæ–‡ä»¶å¤±è´¥: {e}", "ERROR")
        return False

def createTerrainPyramid(source_path):
    """ä¸ºå¤§åœ°å½¢æ–‡ä»¶åˆ›å»ºé‡‘å­—å¡”æ¦‚è§ˆï¼Œæå‡CTBå¤„ç†æ•ˆç‡"""
    try:
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰é‡‘å­—å¡”æ–‡ä»¶
        ovr_file = source_path + '.ovr'
        if os.path.exists(ovr_file):
            logMessage(f"é‡‘å­—å¡”æ–‡ä»¶å·²å­˜åœ¨: {os.path.basename(ovr_file)}")
            return True
        
        # è·å–æ–‡ä»¶å¤§å°ï¼Œé€‰æ‹©åˆé€‚çš„é‡‘å­—å¡”çº§åˆ«
        file_size_gb = os.path.getsize(source_path) / (1024**3)
        
        if file_size_gb > 50:
            levels = [2, 4, 8, 16, 32, 64, 128, 256]  # è¶…å¤§æ–‡ä»¶
        elif file_size_gb > 20:
            levels = [2, 4, 8, 16, 32, 64, 128]       # å¤§æ–‡ä»¶
        else:
            levels = [2, 4, 8, 16, 32, 64]            # ä¸­ç­‰æ–‡ä»¶
        
        # æ‰§è¡Œgdaladdoå‘½ä»¤åˆ›å»ºé‡‘å­—å¡”
        cmd = [
            'gdaladdo', 
            '-r', 'average',  # å¹³å‡å€¼é‡‡æ ·ï¼Œé€‚åˆDEM
            '--config', 'COMPRESS_OVERVIEW', 'LZW',  # å‹ç¼©èŠ‚çœç©ºé—´
            source_path
        ] + [str(level) for level in levels]
        
        logMessage(f"åˆ›å»ºé‡‘å­—å¡”: gdaladdo -r average {os.path.basename(source_path)} {' '.join(map(str, levels))}")
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['GDAL_CACHEMAX'] = '1024'  # 1GBç¼“å­˜
        
        # æ‰§è¡Œå‘½ä»¤
        result = runCommand(cmd, env=env)
        
        if result["success"] and os.path.exists(ovr_file):
            ovr_size_mb = os.path.getsize(ovr_file) / (1024**2)
            logMessage(f"é‡‘å­—å¡”åˆ›å»ºæˆåŠŸ: {ovr_size_mb:.1f}MB")
            return True
        else:
            logMessage(f"é‡‘å­—å¡”åˆ›å»ºå¤±è´¥: {result.get('stderr', '')}", "WARNING")
            return False
            
    except Exception as e:
        logMessage(f"é‡‘å­—å¡”åˆ›å»ºå¼‚å¸¸: {str(e)}", "ERROR")
        return False

def optimizedGdal2tilesByLevels(filePath, outputDir, minZoom=0, maxZoom=18, processes=4, tileFormat="png", quality=85):
    """
    åˆ†çº§ç”Ÿæˆç“¦ç‰‡ï¼Œé€çº§å¤„ç†ä»¥ä¼˜åŒ–æ€§èƒ½
    
    @param filePath è¾“å…¥æ–‡ä»¶è·¯å¾„
    @param outputDir è¾“å‡ºç›®å½•
    @param minZoom æœ€å°ç¼©æ”¾çº§åˆ«
    @param maxZoom æœ€å¤§ç¼©æ”¾çº§åˆ«
    @param processes å¹¶è¡Œè¿›ç¨‹æ•°
    @param tileFormat ç“¦ç‰‡æ ¼å¼ï¼špngã€webpã€jpeg
    @param quality å›¾ç‰‡è´¨é‡ï¼ˆ0-100ï¼‰
    @return å¤„ç†æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    try:
        # æ£€æŸ¥è¾“å‡ºç›®å½•
        if not os.path.exists(outputDir):
            os.makedirs(outputDir)
        
        # åˆ†çº§å¤„ç†
        for zoom in range(minZoom, maxZoom + 1):
            zoomOutputDir = os.path.join(outputDir, str(zoom))
            if not os.path.exists(zoomOutputDir):
                os.makedirs(zoomOutputDir)
            
            # æ„å»ºgdal2tileså‘½ä»¤
            cmd = [
                "gdal2tiles.py",
                "-z", f"{zoom}-{zoom}",
                "-w", "none",
                "--processes", str(processes),
                filePath,
                zoomOutputDir
            ]
            
            if tileFormat == "webp":
                cmd.extend(["--webp-quality", str(quality)])
            elif tileFormat == "jpeg":
                cmd.extend(["--jpeg-quality", str(quality)])
            
            # æ‰§è¡Œå‘½ä»¤
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            stdout, stderr = process.communicate()
            
            if process.returncode != 0:
                logMessage(f"çº§åˆ« {zoom} ç”Ÿæˆå¤±è´¥: {stderr.decode()}", "ERROR")
                return False
            
            logMessage(f"çº§åˆ« {zoom} ç”Ÿæˆå®Œæˆ", "INFO")
        
        return True
    except Exception as e:
        logMessage(f"åˆ†çº§ç”Ÿæˆç“¦ç‰‡å¤±è´¥: {e}", "ERROR")
        return False

def createTileGridIndex(tifFiles, outputPath, minZoom, maxZoom, tileSize=256):
    """
    åˆ›å»ºç“¦ç‰‡ç½‘æ ¼ç´¢å¼•ï¼ˆSHPåˆ†å¹…çŸ¢é‡æ …æ ¼ï¼‰
    
    @param tifFiles TIFæ–‡ä»¶åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @param minZoom æœ€å°ç¼©æ”¾çº§åˆ«
    @param maxZoom æœ€å¤§ç¼©æ”¾çº§åˆ«
    @param tileSize ç“¦ç‰‡å¤§å°
    @return ç“¦ç‰‡ç´¢å¼•ç»“æœ
    """
    try:
        logMessage(f"å¼€å§‹åˆ›å»ºç“¦ç‰‡ç½‘æ ¼ç´¢å¼•ï¼š{len(tifFiles)} ä¸ªæ–‡ä»¶ï¼Œçº§åˆ« {minZoom}-{maxZoom}")
        
        # æ­¥éª¤1ï¼šè·å–æ‰€æœ‰æ–‡ä»¶çš„åœ°ç†è¾¹ç•Œ
        allBounds = []
        for tifFile in tifFiles:
            bounds = getFileGeographicBounds(tifFile)
            if bounds and "west" in bounds:
                allBounds.append({
                    "file": tifFile,
                    "west": bounds["west"],
                    "south": bounds["south"], 
                    "east": bounds["east"],
                    "north": bounds["north"]
                })
                logMessage(f"æ–‡ä»¶è¾¹ç•Œ: {os.path.basename(tifFile)} [{bounds['west']:.6f}, {bounds['south']:.6f}, {bounds['east']:.6f}, {bounds['north']:.6f}]")
        
        if not allBounds:
            return {"success": False, "error": "æ— æ³•è·å–ä»»ä½•æ–‡ä»¶çš„åœ°ç†è¾¹ç•Œ"}
        
        # æ­¥éª¤2ï¼šè®¡ç®—æ€»ä½“è¾¹ç•Œ
        totalWest = min(b["west"] for b in allBounds)
        totalSouth = min(b["south"] for b in allBounds)  
        totalEast = max(b["east"] for b in allBounds)
        totalNorth = max(b["north"] for b in allBounds)
        
        logMessage(f"æ€»ä½“è¾¹ç•Œ: [{totalWest:.6f}, {totalSouth:.6f}, {totalEast:.6f}, {totalNorth:.6f}]")
        
        # æ­¥éª¤3ï¼šç”Ÿæˆæ‰€æœ‰çº§åˆ«çš„ç“¦ç‰‡ç½‘æ ¼ç´¢å¼•
        tileIndex = []
        
        for zoom in range(minZoom, maxZoom + 1):
            # è®¡ç®—è¯¥çº§åˆ«çš„ç“¦ç‰‡èŒƒå›´ï¼ˆä¿®å¤åæ ‡è®¡ç®—ï¼‰
            # è¥¿åŒ—è§’ â†’ å·¦ä¸Šè§’ç“¦ç‰‡åæ ‡ï¼ˆminX, minYï¼‰
            minTileX, minTileY = deg2tile(totalNorth, totalWest, zoom)
            # ä¸œå—è§’ â†’ å³ä¸‹è§’ç“¦ç‰‡åæ ‡ï¼ˆmaxX, maxYï¼‰
            maxTileX, maxTileY = deg2tile(totalSouth, totalEast, zoom)
            
            # ç¡®ä¿èŒƒå›´æ­£ç¡®
            minTileX = max(0, min(minTileX, maxTileX))
            maxTileX = min((1 << zoom) - 1, max(minTileX, maxTileX))
            minTileY = max(0, min(minTileY, maxTileY))
            maxTileY = min((1 << zoom) - 1, max(minTileY, maxTileY))
            
            logMessage(f"çº§åˆ« {zoom}: ç“¦ç‰‡èŒƒå›´ X({minTileX}-{maxTileX}) Y({minTileY}-{maxTileY})")
            
            # ä¸ºæ¯ä¸ªç“¦ç‰‡åˆ›å»ºè¯¦ç»†ç´¢å¼•
            for tileX in range(minTileX, maxTileX + 1):
                for tileY in range(minTileY, maxTileY + 1):
                    # è®¡ç®—ç“¦ç‰‡åœ°ç†è¾¹ç•Œ
                    tileWest, tileNorth = tile2deg(tileX, tileY, zoom)
                    tileEast, tileSouth = tile2deg(tileX + 1, tileY + 1, zoom)
                    
                    # æŸ¥æ‰¾ä¸è¯¥ç“¦ç‰‡ç›¸äº¤çš„TIFæ–‡ä»¶
                    intersectingFiles = []
                    for fileInfo in allBounds:
                        if (fileInfo["west"] <= tileEast and fileInfo["east"] >= tileWest and
                            fileInfo["south"] <= tileNorth and fileInfo["north"] >= tileSouth):
                            intersectingFiles.append({
                                "file": fileInfo["file"],
                                "bounds": [fileInfo["west"], fileInfo["south"], fileInfo["east"], fileInfo["north"]],
                                "filename": os.path.basename(fileInfo["file"])
                            })
                    
                    # åªä¸ºæœ‰æ•°æ®çš„ç“¦ç‰‡åˆ›å»ºç´¢å¼•ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰
                    if intersectingFiles:
                        tileInfo = {
                            "z": zoom,
                            "x": tileX,
                            "y": tileY,
                            "bounds": [tileWest, tileSouth, tileEast, tileNorth],
                            "sourceFiles": intersectingFiles,
                            "sourceCount": len(intersectingFiles),
                            "tileSize": tileSize,
                            "area": (tileEast - tileWest) * (tileNorth - tileSouth)
                        }
                        tileIndex.append(tileInfo)
        
        logMessage(f"âœ… ç“¦ç‰‡ç½‘æ ¼ç´¢å¼•åˆ›å»ºå®Œæˆï¼šæ€»è®¡ {len(tileIndex)} ä¸ªæœ‰æ•ˆç“¦ç‰‡")
        
        return {
            "success": True,
            "tileIndex": tileIndex,
            "totalTiles": len(tileIndex),
            "totalBounds": [totalWest, totalSouth, totalEast, totalNorth],
            "zoomLevels": f"{minZoom}-{maxZoom}",
            "sourceFiles": len(tifFiles)
        }
        
    except Exception as e:
        logMessage(f"åˆ›å»ºç“¦ç‰‡ç½‘æ ¼ç´¢å¼•å¤±è´¥: {e}", "ERROR")
        return {"success": False, "error": str(e)}

def deg2tile(lat_deg, lon_deg, zoom):
    """å°†åœ°ç†åæ ‡è½¬æ¢ä¸ºç“¦ç‰‡åæ ‡"""
    import math
    lat_rad = math.radians(lat_deg)
    n = 2.0 ** zoom
    x = int((lon_deg + 180.0) / 360.0 * n)
    y = int((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)
    return (x, y)

def tile2deg(x, y, zoom):
    """å°†ç“¦ç‰‡åæ ‡è½¬æ¢ä¸ºåœ°ç†åæ ‡"""
    import math
    n = 2.0 ** zoom
    lon_deg = x / n * 360.0 - 180.0
    lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * y / n)))
    lat_deg = math.degrees(lat_rad)
    return (lon_deg, lat_deg)

def runCommand(cmd, cwd=None, env=None):
    """æ‰§è¡Œç³»ç»Ÿå‘½ä»¤"""
    try:
        result = subprocess.run(
            cmd, 
            capture_output=True, 
            text=True, 
            cwd=cwd,
            env=env,
            timeout=3600  # 1å°æ—¶è¶…æ—¶
        )
        return {
            "success": result.returncode == 0,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode
        }
    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "error": "å‘½ä»¤æ‰§è¡Œè¶…æ—¶"
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

def processHighPerformanceTiles(tileIndex, outputPath, resampling="near", max_workers=None, batch_size=50, user_processes=None, taskId=None):
    """
    é«˜æ€§èƒ½æ‰¹é‡ç“¦ç‰‡å¤„ç†ï¼Œç›®æ ‡ï¼šæ¯ç§’1000ç“¦ç‰‡
    
    @param tileIndex ç“¦ç‰‡ç´¢å¼•åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param max_workers æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°
    @param batch_size æ‰¹é‡å¤§å°
    @param user_processes ç”¨æˆ·æŒ‡å®šçš„è¿›ç¨‹æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    @param taskId ä»»åŠ¡IDï¼ˆç”¨äºåœæ­¢æ£€æŸ¥ï¼‰
    @return å¤„ç†ç»“æœç»Ÿè®¡
    """
    import multiprocessing as mp
    import queue
    import time
    import tempfile
    import os
    import threading
    from concurrent.futures import ProcessPoolExecutor, as_completed
    
    total_tiles = len(tileIndex)
    start_time = time.time()
    
    # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è¿›ç¨‹æ•°
    if max_workers is None:
        cpu_count = mp.cpu_count()
        if user_processes and user_processes > 0:
            # ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†è¿›ç¨‹æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·çš„å€¼
            max_workers = user_processes
        else:
            if total_tiles < 100:
                max_workers = min(4, cpu_count)
            elif total_tiles < 1000:
                max_workers = min(cpu_count, 32)
            else:
                max_workers = min(cpu_count * 2, 32)
    
    # åˆ›å»ºåœæ­¢æ ‡å¿—æ–‡ä»¶å
    stop_flag_file = f"/tmp/stop_flag_{taskId}.txt" if taskId else None
    
    # å¯åŠ¨åœæ­¢æ£€æŸ¥çº¿ç¨‹
    stop_checker_thread = None
    if taskId:
        def stop_checker():
            """åœæ­¢æ£€æŸ¥çº¿ç¨‹ï¼šç›‘æ§ä»»åŠ¡çŠ¶æ€ï¼Œä¸€æ—¦æ£€æµ‹åˆ°åœæ­¢å°±åˆ›å»ºåœæ­¢æ ‡å¿—æ–‡ä»¶"""
            while True:
                try:
                    # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
                    with taskLock:
                        task_data = taskStatus.get(taskId)
                    if task_data and task_data.get("status") == "stopped":
                        # åˆ›å»ºåœæ­¢æ ‡å¿—æ–‡ä»¶
                        if stop_flag_file:
                            with open(stop_flag_file, 'w') as f:
                                f.write("STOP")
                            logMessage(f"åœæ­¢æ ‡å¿—æ–‡ä»¶å·²åˆ›å»º: {stop_flag_file}")
                        break
                    
                    # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
                    time.sleep(1)
                except Exception as e:
                    logMessage(f"åœæ­¢æ£€æŸ¥çº¿ç¨‹é”™è¯¯: {e}", "WARNING")
                    time.sleep(1)
        
        stop_checker_thread = threading.Thread(target=stop_checker, daemon=True)
        stop_checker_thread.start()
        logMessage(f"åœæ­¢æ£€æŸ¥çº¿ç¨‹å·²å¯åŠ¨ï¼Œç›‘æ§ä»»åŠ¡: {taskId}")
    
    # è®¡ç®—æ‰¹æ¬¡å¤§å°
    batch_size = calculateOptimalBatchSize(total_tiles, max_workers)
    
    # åˆ›å»ºæ‰¹æ¬¡
    batches = []
    for i in range(0, total_tiles, batch_size):
        batch = tileIndex[i:i + batch_size]
        batches.append({
            'tiles': batch,
            'batch_idx': i // batch_size,
            'stop_flag_file': stop_flag_file  # ä¼ é€’åœæ­¢æ ‡å¿—æ–‡ä»¶è·¯å¾„
        })
    
    logMessage(f"ğŸš€ å¯åŠ¨é«˜æ€§èƒ½ç“¦ç‰‡å¤„ç†: {total_tiles}ç“¦ç‰‡, {max_workers}è¿›ç¨‹, æ‰¹é‡å¤§å°{batch_size}")
    logMessage(f"ğŸ“¦ ç“¦ç‰‡åˆ†æ‰¹å®Œæˆ: {len(batches)}æ‰¹æ¬¡")
    
    # ç»Ÿè®¡ä¿¡æ¯
    processed_tiles = 0
    failed_tiles = 0
    batch_results = []
    
    # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†æ‰¹æ¬¡
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰æ‰¹æ¬¡
        future_to_batch = {
            executor.submit(processTileBatch, batch['tiles'], outputPath, resampling, batch['batch_idx'], batch['stop_flag_file']): batch 
            for batch in batches
        }
        
        # æ”¶é›†ç»“æœ
        for future in as_completed(future_to_batch):
            batch = future_to_batch[future]
            try:
                result = future.result()
                processed_tiles += result['processed']
                failed_tiles += result['failed']
                batch_results.append(result)
                
                # æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢
                if result.get('stopped', False):
                    logMessage(f"æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå…¶ä»–ä»»åŠ¡")
                    # å–æ¶ˆå…¶ä»–æœªå®Œæˆçš„ä»»åŠ¡
                    for f in future_to_batch:
                        if not f.done():
                            f.cancel()
                    break
                    
            except Exception as e:
                failed_tiles += batch_size
                logMessage(f"æ‰¹æ¬¡ {batch['batch_idx']} å¤„ç†å¼‚å¸¸: {e}", "ERROR")
    
    # æ¸…ç†åœæ­¢æ ‡å¿—æ–‡ä»¶
    if stop_flag_file and os.path.exists(stop_flag_file):
        try:
            os.remove(stop_flag_file)
            logMessage(f"åœæ­¢æ ‡å¿—æ–‡ä»¶å·²æ¸…ç†: {stop_flag_file}")
        except:
            pass
    
    # è®¡ç®—å¹³å‡é€Ÿåº¦
    total_time = time.time() - start_time
    average_speed = processed_tiles / total_time if total_time > 0 else 0
    
    # è¿”å›ç»“æœ
    return {
        "success": True,
        "processed_tiles": processed_tiles,
        "failed_tiles": failed_tiles,
        "total_tiles": total_tiles,
        "batch_results": batch_results,
        "average_speed": average_speed,
        "total_time": total_time
    }

def processTileBatch(tiles, outputPath, resampling, batch_idx, stop_flag_file=None):
    """
    å¤„ç†ä¸€æ‰¹ç“¦ç‰‡
    
    @param tiles ç“¦ç‰‡åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param batch_idx æ‰¹æ¬¡ç´¢å¼•
    @param stop_flag_file åœæ­¢æ ‡å¿—æ–‡ä»¶è·¯å¾„
    @return å¤„ç†ç»“æœ
    """
    import os
    import time
    
    processed = 0
    failed = 0
    
    for tile in tiles:
        # æ£€æŸ¥åœæ­¢æ ‡å¿—æ–‡ä»¶
        if stop_flag_file and os.path.exists(stop_flag_file):
            logMessage(f"æ‰¹æ¬¡ {batch_idx} æ£€æµ‹åˆ°åœæ­¢ä¿¡å·ï¼Œç»ˆæ­¢å¤„ç†")
            return {
                "processed": processed,
                "failed": failed,
                "batch_idx": batch_idx,
                "stopped": True
            }
        
        try:
            # å¤„ç†å•ä¸ªç“¦ç‰‡
            result = processSingleTileOptimized(tile, outputPath, resampling)
            if result["success"]:
                processed += 1
            else:
                failed += 1
        except Exception as e:
            failed += 1
            logMessage(f"ç“¦ç‰‡å¤„ç†å¼‚å¸¸: {e}", "ERROR")
    
    return {
        "processed": processed,
        "failed": failed,
        "batch_idx": batch_idx,
        "stopped": False
    }

def calculateOptimalBatchSize(tile_count, max_workers, target_speed=1000):
    """
    æ ¹æ®ç“¦ç‰‡æ•°é‡å’Œå·¥ä½œè¿›ç¨‹æ•°è®¡ç®—æœ€ä¼˜æ‰¹é‡å¤§å°
    
    @param tile_count ç“¦ç‰‡æ€»æ•°
    @param max_workers å·¥ä½œè¿›ç¨‹æ•°
    @param target_speed ç›®æ ‡é€Ÿåº¦ï¼ˆç“¦ç‰‡/ç§’ï¼‰
    @return æœ€ä¼˜æ‰¹é‡å¤§å°
    """
    # åŸºç¡€è®¡ç®—ï¼šæ¯ä¸ªè¿›ç¨‹æ¯ç§’å¤„ç†çš„ç“¦ç‰‡æ•°
    tiles_per_worker_per_sec = target_speed / max_workers
    
    # å‡è®¾æ¯æ‰¹æ¬¡å¤„ç†æ—¶é—´ä¸º2-5ç§’ï¼ˆè€ƒè™‘è¿›ç¨‹å¯åŠ¨å¼€é”€ï¼‰
    optimal_batch_time = 3.0
    
    # è®¡ç®—æ‰¹é‡å¤§å°
    batch_size = int(tiles_per_worker_per_sec * optimal_batch_time)
    
    # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
    if tile_count < 100:
        batch_size = min(batch_size, 10)
    elif tile_count < 1000:
        batch_size = min(batch_size, 50)
    elif tile_count < 10000:
        batch_size = min(batch_size, 100)
    else:
        batch_size = min(batch_size, 200)
    
    # æœ€å°æ‰¹é‡å¤§å°
    batch_size = max(batch_size, 5)
    
    return batch_size

def processSingleTileOptimized(tileInfo, tilesDir, resampling="near", temp_dir=None):
    """
    ä¼˜åŒ–çš„å•ç“¦ç‰‡å¤„ç†ï¼ˆå‡å°‘IOï¼Œä¼˜åŒ–GDALå‘½ä»¤ï¼‰
    ä½¿ç”¨ä¸¤æ­¥æ³•ï¼šgdalwarp -> GTiff -> gdal_translate -> PNG
    
    @param tileInfo ç“¦ç‰‡ç´¢å¼•ä¿¡æ¯
    @param tilesDir ç“¦ç‰‡è¾“å‡ºç›®å½•
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param temp_dir ä¸´æ—¶ç›®å½•
    @return å¤„ç†ç»“æœ
    """
    try:
        zoom, tileX, tileY = tileInfo["z"], tileInfo["x"], tileInfo["y"]
        tileBounds = tileInfo["bounds"]  # [west, south, east, north]
        sourceFiles = tileInfo["sourceFiles"]
        
        # åˆ›å»ºç“¦ç‰‡ç›®å½•
        tileDir = os.path.join(tilesDir, str(zoom), str(tileX))
        os.makedirs(tileDir, exist_ok=True)
        
        # ç“¦ç‰‡æ–‡ä»¶è·¯å¾„
        tileFile = os.path.join(tileDir, f"{tileY}.png")
        
        # å¦‚æœç“¦ç‰‡å·²å­˜åœ¨ä¸”ä¸ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†
        if os.path.exists(tileFile) and os.path.getsize(tileFile) > 0:
            return {
                "success": True,
                "tileFile": tileFile,
                "skipped": True,
                "tilePath": f"{zoom}/{tileX}/{tileY}.png"
            }
        
        # å‡†å¤‡æºæ–‡ä»¶åˆ—è¡¨
        sourceFileList = [sf["file"] for sf in sourceFiles]
        
        # ä½¿ç”¨ä¸´æ—¶ç›®å½•å‡å°‘IOå†²çª
        if temp_dir:
            tempTileFile = os.path.join(temp_dir, f"tile_{zoom}_{tileX}_{tileY}.tif")
        else:
            tempTileFile = tileFile.replace('.png', '_temp.tif')
        
        # ç¬¬ä¸€æ­¥ï¼šgdalwarpç”ŸæˆGTiff
        cmd1 = [
            "gdalwarp",
            "-te", str(tileBounds[0]), str(tileBounds[1]), str(tileBounds[2]), str(tileBounds[3]),
            "-ts", "256", "256",
            "-r", resampling,
            "-of", "GTiff",  # è¾“å‡ºGTiff
            "-co", "TILED=YES",
            "-co", "COMPRESS=LZW",
            "-srcnodata", "0",
            "-dstnodata", "0",
            "-dstalpha",
            "-multi",  # å¯ç”¨å¤šçº¿ç¨‹å¤„ç†
            "-wm", "128",  # å·¥ä½œå†…å­˜128MB
            "-q"  # é™é»˜æ¨¡å¼å‡å°‘è¾“å‡º
        ] + sourceFileList + [tempTileFile]
        
        # æ‰§è¡Œç¬¬ä¸€æ­¥å‘½ä»¤
        result1 = subprocess.run(cmd1, capture_output=True, text=True, timeout=30)
        
        if result1.returncode != 0:
            return {
                "success": False,
                "error": f"gdalwarpå¤±è´¥: {result1.stderr}"
            }
        
        # ç¬¬äºŒæ­¥ï¼šgdal_translateè½¬æ¢ä¸ºPNG
        cmd2 = [
            "gdal_translate",
            "-of", "PNG",
            "-co", "WORLDFILE=NO",
            tempTileFile,
            tileFile
        ]
        
        result2 = subprocess.run(cmd2, capture_output=True, text=True, timeout=30)
        
        # æ¸…ç†ä¸´æ—¶GTiffæ–‡ä»¶
        try:
            if os.path.exists(tempTileFile):
                os.remove(tempTileFile)
        except:
            pass
        
        if result2.returncode == 0:
            return {
                "success": True,
                "tileFile": tileFile,
                "sourceCount": len(sourceFiles),
                "method": "ä¼˜åŒ–ä¸¤æ­¥æ³•gdalwarp+translate",
                "tilePath": f"{zoom}/{tileX}/{tileY}.png"
            }
        else:
            return {
                "success": False,
                "error": f"PNGè½¬æ¢å¤±è´¥: {result2.stderr}"
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

def processSingleTileFromIndex(tileInfo, tilesDir, resampling="near"):
    """
    æ ¹æ®ç´¢å¼•ä¿¡æ¯å¤„ç†å•ä¸ªç“¦ç‰‡ï¼ˆæ— VRTï¼Œç›´æ¥GDALåˆ‡å‰²ï¼‰
    
    @param tileInfo ç“¦ç‰‡ç´¢å¼•ä¿¡æ¯
    @param tilesDir ç“¦ç‰‡è¾“å‡ºç›®å½•
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @return å¤„ç†ç»“æœ
    """
    try:
        zoom, tileX, tileY = tileInfo["z"], tileInfo["x"], tileInfo["y"]
        tileBounds = tileInfo["bounds"]  # [west, south, east, north]
        sourceFiles = tileInfo["sourceFiles"]
        
        # åˆ›å»ºç“¦ç‰‡ç›®å½•
        tileDir = os.path.join(tilesDir, str(zoom), str(tileX))
        os.makedirs(tileDir, exist_ok=True)
        
        # ç“¦ç‰‡æ–‡ä»¶è·¯å¾„
        tileFile = os.path.join(tileDir, f"{tileY}.png")
        
        # å‡†å¤‡æºæ–‡ä»¶åˆ—è¡¨
        sourceFileList = [sf["file"] for sf in sourceFiles]
        tempTileFile = tileFile.replace('.png', '_temp.tif')
        
        # æ·»åŠ è¾¹ç•Œé‡å å¤„ç†æ¶ˆé™¤ç¼éš™
        west, south, east, north = tileBounds
        overlap = 0.0001  # è¾¹ç•Œé‡å é‡ï¼ˆåº¦ï¼‰
        expandedBounds = [west - overlap, south - overlap, east + overlap, north + overlap]
        
        # æ ¸å¿ƒï¼šgdalwarpç›´æ¥å¤„ç†å¤šä¸ªè¾“å…¥æ–‡ä»¶ï¼ˆæ— VRTä¸­é—´å±‚ + ç¼éš™ä¿®å¤ï¼‰
        cmd = [
            "gdalwarp",
            "-te", str(expandedBounds[0]), str(expandedBounds[1]), str(expandedBounds[2]), str(expandedBounds[3]),  # æ‰©å±•è¾¹ç•Œæ¶ˆé™¤ç¼éš™
            "-ts", "256", "256",  # ç“¦ç‰‡å°ºå¯¸
            "-r", resampling,
            "-of", "GTiff",
            "-co", "TILED=YES", 
            "-co", "COMPRESS=LZW",
            "-co", "BIGTIFF=IF_SAFER",
            "-srcnodata", "0",  # æºæ–‡ä»¶nodataå€¼
            "-dstnodata", "0",  # ç›®æ ‡æ–‡ä»¶nodataå€¼
            "-dstalpha",  # æ·»åŠ Alphaé€šé“å¤„ç†é€æ˜åº¦
            "-multi"  # å¤šçº¿ç¨‹å¤„ç†
        ] + sourceFileList + [tempTileFile]  # å¤šä¸ªè¾“å…¥ + ä¸€ä¸ªè¾“å‡º
        
        warpResult = runCommand(cmd)
        
        if not warpResult["success"]:
            return {
                "success": False,
                "error": f"gdalwarpå¤±è´¥: {warpResult.get('stderr', 'æœªçŸ¥é”™è¯¯')}"
            }
        
        # è½¬æ¢ä¸ºPNG
        cmd2 = [
            "gdal_translate",
            "-of", "PNG",
            "-co", "WORLDFILE=NO",
            tempTileFile,
            tileFile
        ]
        
        translateResult = runCommand(cmd2)
        
        # æ¸…ç†ä¸´æ—¶GTiffæ–‡ä»¶
        try:
            if os.path.exists(tempTileFile):
                os.remove(tempTileFile)
        except:
            pass
        
        if not translateResult["success"]:
            return {
                "success": False,
                "error": f"PNGè½¬æ¢å¤±è´¥: {translateResult.get('stderr', 'æœªçŸ¥é”™è¯¯')}"
            }
        
        return {
            "success": True,
            "tileFile": tileFile,
            "sourceCount": len(sourceFiles),
            "method": "ç›´æ¥gdalwarp+translate",
            "tilePath": f"{zoom}/{tileX}/{tileY}.png"
        }
            
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

def generateShapefileIndex(tileIndex, outputPath, generateShp=True):
    """
    ç”Ÿæˆç“¦ç‰‡ç´¢å¼•çš„Shapefileæ–‡ä»¶ï¼ˆSHPåˆ†å¹…çŸ¢é‡æ …æ ¼ï¼‰
    
    @param tileIndex ç“¦ç‰‡ç´¢å¼•åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @return ç”Ÿæˆç»“æœ
    """
    try:
        import json
        import hashlib
        
        # è®¡ç®—ç“¦ç‰‡ç´¢å¼•çš„å“ˆå¸Œå€¼ï¼Œç”¨äºæ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ
        index_key = []
        for tile in tileIndex:
            tile_key = f"{tile['z']}/{tile['x']}/{tile['y']}"
            index_key.append(tile_key)
        index_str = '|'.join(sorted(index_key))
        current_hash = hashlib.md5(index_str.encode('utf-8')).hexdigest()
        
        # å®šä¹‰æ–‡ä»¶è·¯å¾„
        geojsonFile = os.path.join(outputPath, "tile_index.geojson")
        shpFile = os.path.join(outputPath, "tile_index.shp")
        hashFile = os.path.join(outputPath, ".tile_index_hash")
        
        # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨ç°æœ‰æ–‡ä»¶
        can_reuse = False
        if os.path.exists(hashFile):
            try:
                with open(hashFile, 'r') as f:
                    existing_hash = f.read().strip()
                if existing_hash == current_hash:
                    # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if os.path.exists(geojsonFile):
                        if os.path.exists(shpFile):
                            logMessage(f"ğŸ”„ æ£€æµ‹åˆ°ç›¸åŒç´¢å¼•ï¼Œå¤ç”¨ç°æœ‰SHPå’ŒGeoJSONæ–‡ä»¶")
                            can_reuse = True
                        else:
                            logMessage(f"ğŸ”„ æ£€æµ‹åˆ°ç›¸åŒç´¢å¼•ï¼Œå¤ç”¨GeoJSONæ–‡ä»¶ï¼Œé‡æ–°ç”ŸæˆSHPæ–‡ä»¶")
                            can_reuse = "geojson_only"
                    else:
                        logMessage(f"âš ï¸ ç´¢å¼•å“ˆå¸ŒåŒ¹é…ä½†æ–‡ä»¶ç¼ºå¤±ï¼Œé‡æ–°ç”Ÿæˆ")
            except Exception as e:
                logMessage(f"âš ï¸ è¯»å–ç´¢å¼•å“ˆå¸Œå¤±è´¥: {e}")
        
        if can_reuse is True:
            # å®Œå…¨å¤ç”¨ç°æœ‰æ–‡ä»¶
            return {
                "success": True,
                "shpFile": shpFile,
                "geojsonFile": geojsonFile,
                "totalFeatures": len(tileIndex),
                "reused": True
            }
        
        # ç”ŸæˆGeoJSONæ ¼å¼çš„ç“¦ç‰‡ç´¢å¼•
        features = []
        
        for tile in tileIndex:
            # å®‰å…¨å¤„ç†boundsï¼Œå°è¯•ä¿®å¤è€Œä¸æ˜¯è·³è¿‡
            tileBounds = tile.get("bounds", [])
            if not tileBounds or len(tileBounds) != 4:
                # å°è¯•ä»ç“¦ç‰‡åæ ‡è®¡ç®—bounds
                try:
                    z, x, y = tile["z"], tile["x"], tile["y"]
                    # ä½¿ç”¨tile2degå‡½æ•°è®¡ç®—ç“¦ç‰‡è¾¹ç•Œ
                    west, north = tile2deg(x, y, z)
                    east, south = tile2deg(x + 1, y + 1, z)
                    tileBounds = [west, south, east, north]
                    logMessage(f"ğŸ”§ ä¿®å¤ç“¦ç‰‡bounds: {z}/{x}/{y} -> {tileBounds}", "INFO")
                except Exception as e:
                    logMessage(f"âŒ æ— æ³•ä¿®å¤ç“¦ç‰‡boundsï¼Œè·³è¿‡: {tile.get('z', '?')}/{tile.get('x', '?')}/{tile.get('y', '?')} é”™è¯¯: {e}", "ERROR")
                    continue
            
            west, south, east, north = tileBounds
            
            feature = {
                "type": "Feature",
                "properties": {
                    "z": tile["z"],
                    "x": tile["x"], 
                    "y": tile["y"],
                    "sourceCount": tile["sourceCount"],
                    "area": tile.get("area", 0),
                    "tileSize": tile.get("tileSize", 256),
                    "sourceFiles": [sf["filename"] for sf in tile["sourceFiles"]],
                    "tilePath": f"{tile['z']}/{tile['x']}/{tile['y']}.png"
                },
                "geometry": {
                    "type": "Polygon",
                    "coordinates": [[
                        [west, south],
                        [east, south],
                        [east, north],
                        [west, north],
                        [west, south]
                    ]]
                }
            }
            features.append(feature)
        
        geojson = {
            "type": "FeatureCollection",
            "crs": {
                "type": "name",
                "properties": {
                    "name": "urn:ogc:def:crs:OGC:1.3:CRS84"
                }
            },
            "features": features
        }
        
        # å¦‚æœä¸æ˜¯ä»…å¤ç”¨GeoJSONï¼Œåˆ™ä¿å­˜æ–°çš„GeoJSONæ–‡ä»¶
        if can_reuse != "geojson_only":
            with open(geojsonFile, 'w', encoding='utf-8') as f:
                json.dump(geojson, f, indent=2, ensure_ascii=False)
            logMessage(f"âœ… GeoJSONç“¦ç‰‡ç´¢å¼•å·²ç”Ÿæˆ: {geojsonFile}")
        else:
            logMessage(f"ğŸ”„ å¤ç”¨ç°æœ‰GeoJSONæ–‡ä»¶: {geojsonFile}")
        
        # ä½¿ç”¨ogr2ogrè½¬æ¢ä¸ºShapefile
        cmd = [
            "ogr2ogr",
            "-f", "ESRI Shapefile",
            "-overwrite",  # è¦†ç›–ç°æœ‰æ–‡ä»¶
            shpFile,
            geojsonFile
        ]
        
        result = runCommand(cmd)
        
        if result["success"]:
            logMessage(f"âœ… SHPç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ: {shpFile}")
            
            # ä¿å­˜ç´¢å¼•å“ˆå¸Œå€¼
            try:
                with open(hashFile, 'w') as f:
                    f.write(current_hash)
                logMessage(f"ğŸ’¾ ç´¢å¼•å“ˆå¸Œå·²ä¿å­˜: {current_hash[:8]}...")
            except Exception as e:
                logMessage(f"âš ï¸ ä¿å­˜ç´¢å¼•å“ˆå¸Œå¤±è´¥: {e}", "WARNING")
            
            return {
                "success": True,
                "shpFile": shpFile,
                "geojsonFile": geojsonFile,
                "totalFeatures": len(features),
                "reused": False
            }
        else:
            # å³ä½¿SHPç”Ÿæˆå¤±è´¥ï¼ŒGeoJSONä»ç„¶å¯ç”¨
            logMessage(f"âš ï¸ SHPè½¬æ¢å¤±è´¥ï¼Œä½†GeoJSONå¯ç”¨: {result.get('stderr', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
            
            # ä»ç„¶ä¿å­˜å“ˆå¸Œå€¼ï¼ˆé’ˆå¯¹GeoJSONï¼‰
            try:
                with open(hashFile, 'w') as f:
                    f.write(current_hash)
            except:
                pass
            
            return {
                "success": True,
                "shpFile": None,
                "geojsonFile": geojsonFile,
                "totalFeatures": len(features),
                "warning": f"SHPè½¬æ¢å¤±è´¥: {result.get('stderr', 'æœªçŸ¥é”™è¯¯')}",
                "reused": False
            }
        
    except Exception as e:
        logMessage(f"âŒ ç”ŸæˆShapefileç´¢å¼•å¤±è´¥: {e}", "ERROR")
        return {
            "success": False,
            "error": str(e)
        }

def verifyTilesIntegrity(outputPath, metadata):
    """
    éªŒè¯ç“¦ç‰‡æ–‡ä»¶çš„å®Œæ•´æ€§
    
    @param outputPath è¾“å‡ºè·¯å¾„
    @param metadata ç°æœ‰å…ƒæ•°æ®
    @return æ˜¯å¦å®Œæ•´
    """
    try:
        # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(outputPath):
            logMessage(f"è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {outputPath}")
            return False
        
        # æ£€æŸ¥åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        processed_tiles = metadata.get("processedTiles", 0)
        if processed_tiles == 0:
            logMessage(f"æ²¡æœ‰å·²å¤„ç†çš„ç“¦ç‰‡")
            return False
        
        # æ£€æŸ¥æˆåŠŸç‡
        success_rate_str = metadata.get("successRate", "0%")
        try:
            success_rate = float(success_rate_str.replace("%", ""))
            if success_rate < 50:  # æˆåŠŸç‡ä½äº50%è®¤ä¸ºä¸å®Œæ•´
                logMessage(f"ç“¦ç‰‡æˆåŠŸç‡è¿‡ä½: {success_rate}%")
                return False
        except:
            logMessage(f"æ— æ³•è§£ææˆåŠŸç‡: {success_rate_str}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç“¦ç‰‡ç´¢å¼•ä¿¡æ¯
        tile_index = metadata.get("tileIndex", [])
        if not tile_index:
            logMessage(f"ç¼ºå°‘ç“¦ç‰‡ç´¢å¼•ä¿¡æ¯")
            return False
        
        # éšæœºæ£€æŸ¥å‡ ä¸ªç“¦ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        import random
        sample_size = min(10, len(tile_index))  # æœ€å¤šæ£€æŸ¥10ä¸ªç“¦ç‰‡
        sample_tiles = random.sample(tile_index, sample_size)
        
        missing_count = 0
        for tile in sample_tiles:
            z, x, y = tile['z'], tile['x'], tile['y']
            tile_path = os.path.join(outputPath, str(z), str(x), f"{y}.png")
            if not os.path.exists(tile_path):
                missing_count += 1
        
        # å¦‚æœè¶…è¿‡30%çš„é‡‡æ ·ç“¦ç‰‡ç¼ºå¤±ï¼Œè®¤ä¸ºä¸å®Œæ•´
        missing_rate = missing_count / sample_size
        if missing_rate > 0.3:
            logMessage(f"ç“¦ç‰‡æ–‡ä»¶ç¼ºå¤±ç‡è¿‡é«˜: {missing_rate*100:.1f}%")
            return False
        
        logMessage(f"ç“¦ç‰‡å®Œæ•´æ€§éªŒè¯é€šè¿‡: æˆåŠŸç‡{success_rate}%, é‡‡æ ·ç¼ºå¤±ç‡{missing_rate*100:.1f}%")
        return True
        
    except Exception as e:
        logMessage(f"ç“¦ç‰‡å®Œæ•´æ€§éªŒè¯å¤±è´¥: {e}", "WARNING")
        return False

def cleanupTasksByCount(maxTasks=100):
    """
    æŒ‰æ•°é‡æ¸…ç†ä»»åŠ¡ï¼Œåˆ é™¤æœ€æ—§çš„ä»»åŠ¡ä»¥æ§åˆ¶å†…å­˜ä½¿ç”¨
    
    @param maxTasks ä¿ç•™çš„æœ€å¤§ä»»åŠ¡æ•°
    @return æ¸…ç†çš„ä»»åŠ¡æ•°é‡
    """
    try:
        with taskLock:
            taskIds = list(taskStatus.keys())
            if len(taskIds) > maxTasks:
                # æŒ‰æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€è€çš„ä»»åŠ¡
                taskIds.sort(key=lambda tid: taskStatus[tid].get("startTime", ""))
                toDelete = taskIds[:-maxTasks]
                
                for taskId in toDelete:
                    # åœæ­¢è¿è¡Œä¸­çš„ä»»åŠ¡
                    if taskId in taskProcesses:
                        try:
                            taskProcesses[taskId].terminate()
                            del taskProcesses[taskId]
                        except:
                            pass
                    
                    # åˆ é™¤ä»»åŠ¡çŠ¶æ€
                    if taskId in taskStatus:
                        del taskStatus[taskId]
                
                logMessage(f"æ¸…ç†äº† {len(toDelete)} ä¸ªæ—§ä»»åŠ¡", "INFO")
                return len(toDelete)
            
            return 0
    except Exception as e:
        logMessage(f"æ¸…ç†ä»»åŠ¡å¤±è´¥: {e}", "ERROR")
        return 0

def healthCheck():
    """
    å¥åº·æ£€æŸ¥æ¥å£ï¼Œè¿”å›æœåŠ¡çŠ¶æ€ä¿¡æ¯
    
    @return åŒ…å«æœåŠ¡çŠ¶æ€çš„JSONå“åº”
    """
    logMessage("æ”¶åˆ°å¥åº·æ£€æŸ¥è¯·æ±‚", "INFO")
    response = {
        "status": "healthy",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "version": "1.0.0"
    }
    logMessage("å¥åº·æ£€æŸ¥å“åº”æ­£å¸¸", "INFO")
    return jsonify(response)

def listDataSources(subpath=''):
    """
    è·å–æ•°æ®æºåˆ—è¡¨ï¼Œæ”¯æŒå­ç›®å½•æµè§ˆå’Œåœ°ç†èŒƒå›´ç­›é€‰
    
    @param subpath å­ç›®å½•è·¯å¾„ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ ¹ç›®å½•
    @return åŒ…å«æ•°æ®æºä¿¡æ¯çš„JSONå“åº”
    """
    try:
        logMessage(f"æ”¶åˆ°æ•°æ®æºåˆ—è¡¨è¯·æ±‚ï¼Œå­è·¯å¾„: '{subpath}'", "INFO")
        datasourceDir = config["dataSourceDir"]
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        if subpath:
            fullPath = os.path.join(datasourceDir, subpath)
        else:
            fullPath = datasourceDir
            
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿è·¯å¾„åœ¨å…è®¸çš„ç›®å½•å†…
        fullPath = os.path.abspath(fullPath)
        datasourceDir = os.path.abspath(datasourceDir)
        if not fullPath.startswith(datasourceDir):
            logMessage(f"è·¯å¾„è®¿é—®è¢«æ‹’ç»: {fullPath}", "WARNING")
            return jsonify({"error": "è·¯å¾„ä¸å…è®¸è®¿é—®"}), 403
            
        if not os.path.exists(fullPath):
            logMessage(f"è¯·æ±‚çš„è·¯å¾„ä¸å­˜åœ¨: {fullPath}", "WARNING")
            return jsonify({"error": "è·¯å¾„ä¸å­˜åœ¨"}), 404
            
        if not os.path.isdir(fullPath):
            logMessage(f"è¯·æ±‚çš„è·¯å¾„ä¸æ˜¯ç›®å½•: {fullPath}", "WARNING")
            return jsonify({"error": "è·¯å¾„ä¸æ˜¯ç›®å½•"}), 400
        
        # è§£æåœ°ç†èŒƒå›´ç­›é€‰å‚æ•°
        searchBounds = None
        boundsParam = request.args.get('bounds')
        if boundsParam:
            try:
                boundsData = json.loads(boundsParam)
                if isinstance(boundsData, list):
                    searchBounds = boundsData
                else:
                    searchBounds = [boundsData]
            except:
                return jsonify({"error": "åœ°ç†èŒƒå›´å‚æ•°æ ¼å¼é”™è¯¯"}), 400
        
        # æ‰«æç›®å½•
        directories = []
        datasources = []
        
        try:
            items = os.listdir(fullPath)
            items.sort()
            
            for item in items:
                itemPath = os.path.join(fullPath, item)
                
                if os.path.isdir(itemPath):
                    # ç›®å½•
                    directories.append({
                        "name": item,
                        "type": "directory",
                        "path": os.path.join(subpath, item) if subpath else item
                    })
                elif os.path.isfile(itemPath):
                    # æ–‡ä»¶
                    fileExt = os.path.splitext(item)[1].lower()
                    if fileExt in config["supportedFormats"]:
                        fileSize = os.path.getsize(itemPath)
                        
                        fileInfo = {
                            "name": item,
                            "type": "file",
                            "size": fileSize,
                            "sizeFormatted": formatFileSize(fileSize),
                            "extension": fileExt,
                            "path": os.path.join(subpath, item) if subpath else item
                        }
                        
                        # åœ°ç†èŒƒå›´ç­›é€‰
                        if searchBounds:
                            try:
                                fileBounds = getFileGeographicBounds(itemPath)
                                if fileBounds and checkBoundsIntersection(fileBounds, searchBounds):
                                    # æ·»åŠ åœ°ç†è¾¹ç•Œä¿¡æ¯
                                    fileInfo["geoBounds"] = fileBounds
                                    datasources.append(fileInfo)
                            except Exception as e:
                                logMessage(f"è·å–æ–‡ä»¶åœ°ç†ä¿¡æ¯å¤±è´¥ {item}: {e}", "WARNING")
                                # å³ä½¿åœ°ç†ä¿¡æ¯è·å–å¤±è´¥ï¼Œä»ç„¶æ·»åŠ æ–‡ä»¶
                                datasources.append(fileInfo)
                        else:
                            # è·å–åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
                            try:
                                detailedInfo = getFileInfo(itemPath)
                                if "geoBounds" in detailedInfo:
                                    fileInfo["geoBounds"] = detailedInfo["geoBounds"]
                            except Exception as e:
                                logMessage(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {item}: {e}", "WARNING")
                            # æ— è®ºæ˜¯å¦æˆåŠŸè·å–è¯¦ç»†ä¿¡æ¯ï¼Œéƒ½æ·»åŠ æ–‡ä»¶
                            datasources.append(fileInfo)
        
        except PermissionError:
            return jsonify({"error": "æƒé™ä¸è¶³"}), 403
        
        # è®¡ç®—çˆ¶çº§è·¯å¾„
        parentPath = None
        if subpath:
            pathParts = subpath.split('/')
            if len(pathParts) > 1:
                parentPath = '/'.join(pathParts[:-1])
            else:
                parentPath = ""
        
        response = {
            "currentPath": subpath,
            "parentPath": parentPath,
            "directories": directories,
            "datasources": datasources,
            "totalDirectories": len(directories),
            "totalFiles": len(datasources),
            "count": len(datasources)
        }
        
        # å¦‚æœæœ‰åœ°ç†ç­›é€‰ï¼Œæ·»åŠ ç­›é€‰ä¿¡æ¯
        if searchBounds:
            response["filterInfo"] = {
                "boundsFilter": searchBounds,
                "filteredCount": len(datasources),
                "message": f"å·²æ ¹æ®åœ°ç†èŒƒå›´ç­›é€‰ï¼Œæ‰¾åˆ° {len(datasources)} ä¸ªåŒ¹é…æ–‡ä»¶"
            }
            logMessage(f"åœ°ç†èŒƒå›´ç­›é€‰å®Œæˆï¼Œæ‰¾åˆ° {len(datasources)} ä¸ªåŒ¹é…æ–‡ä»¶", "INFO")
        
        logMessage(f"æ•°æ®æºåˆ—è¡¨è¯·æ±‚å¤„ç†å®Œæˆï¼Œè¿”å› {len(directories)} ä¸ªç›®å½•ï¼Œ{len(datasources)} ä¸ªæ–‡ä»¶", "INFO")
        return jsonify(response)
    except Exception as e:
        logMessage(f"æ•°æ®æºåˆ—è¡¨è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({"error": str(e)}), 500

def getFileInfo(filePath):
    """
    è·å–æ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯
    
    @param filePath æ–‡ä»¶å®Œæ•´è·¯å¾„
    @return æ–‡ä»¶ä¿¡æ¯å­—å…¸
    """
    try:
        fileInfo = {}
        
        # åŸºæœ¬æ–‡ä»¶ä¿¡æ¯
        if os.path.exists(filePath):
            stat = os.stat(filePath)
            fileInfo.update({
                "size": stat.st_size,
                "lastModified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "type": "file"
            })
            
            # æ–‡ä»¶æ ¼å¼
            fileExt = os.path.splitext(filePath)[1].lower()
            fileInfo["format"] = fileExt
            
            # å¦‚æœæ˜¯åœ°ç†æ•°æ®æ–‡ä»¶ï¼Œè·å–å…ƒæ•°æ®
            if fileExt in ['.tif', '.tiff', '.geotiff']:
                try:
                    # ä½¿ç”¨gdalinfoè·å–è¯¦ç»†ä¿¡æ¯
                    cmd = ["gdalinfo", filePath]
                    result = runCommand(cmd)
                    
                    if result["success"]:
                        # è§£æåŸºæœ¬å…ƒæ•°æ®
                        gdalinfo_output = result["stdout"]
                        lines = gdalinfo_output.split('\n')
                        
                        metadata = {}
                        for line in lines:
                            line = line.strip()
                            if line.startswith('Size is'):
                                # Size is 18892, 15028
                                parts = line.replace('Size is ', '').split(',')
                                if len(parts) == 2:
                                    metadata["rasterSize"] = {
                                        "width": int(parts[0].strip()),
                                        "height": int(parts[1].strip())
                                    }
                            elif line.startswith('Pixel Size'):
                                # Pixel Size = (0.0002777778,-0.0002777778)
                                import re
                                match = re.search(r'Pixel Size = \(([^,]+),([^)]+)\)', line)
                                if match:
                                    metadata["pixelSize"] = {
                                        "x": float(match.group(1)),
                                        "y": float(match.group(2))
                                    }
                            elif 'data type' in line.lower():
                                metadata["dataType"] = line
                            elif line.startswith('Band '):
                                if "bandCount" not in metadata:
                                    metadata["bandCount"] = 0
                                metadata["bandCount"] += 1
                        
                        # è·å–åœ°ç†è¾¹ç•Œ
                        bounds = extractGeographicBounds(gdalinfo_output)
                        if bounds:
                            metadata["bounds"] = bounds
                            fileInfo["geoBounds"] = bounds
                        
                        # è·å–åæ ‡ç³»ä¿¡æ¯
                        for line in lines:
                            line = line.strip()
                            if line.startswith('PROJCS[') or line.startswith('GEOGCS['):
                                metadata["srs"] = line[:100] + "..." if len(line) > 100 else line
                                break
                        
                        fileInfo["metadata"] = metadata
                        
                except Exception as e:
                    logMessage(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥ {filePath}: {e}", "WARNING")
        
        return fileInfo
    except Exception as e:
        logMessage(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {filePath}: {e}", "ERROR")
        return {"error": str(e)}

def getDataSourceInfo(filename):
    """
    è·å–æ•°æ®æºè¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ–‡ä»¶å±æ€§å’Œæ¨èé…ç½®
    
    @param filename æ–‡ä»¶å
    @return åŒ…å«è¯¦ç»†ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        logMessage(f"æ”¶åˆ°æ–‡ä»¶ä¿¡æ¯è¯·æ±‚: {filename}", "INFO")
        filePath = os.path.join(config["dataSourceDir"], filename)
        
        if not os.path.exists(filePath):
            logMessage(f"è¯·æ±‚çš„æ–‡ä»¶ä¸å­˜åœ¨: {filename}", "WARNING")
            return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        fileInfo = getFileInfo(filePath)
        
        # æ·»åŠ åˆ‡ç‰‡é…ç½®æ¨è
        if "error" not in fileInfo:
            fileSizeGb = fileInfo["size"] / (1024**3)
            
            # è·å–æ¨èå‚æ•°
            tileType = request.args.get('tileType')
            userMinZoom = request.args.get('minZoom')
            userMaxZoom = request.args.get('maxZoom')
            
            if userMinZoom:
                userMinZoom = int(userMinZoom)
            if userMaxZoom:
                userMaxZoom = int(userMaxZoom)
            
            # ç”Ÿæˆæ¨èé…ç½®
            try:
                import psutil
                cpuCount = psutil.cpu_count() or 4
                memoryTotalGb = psutil.virtual_memory().total / (1024**3)
            except:
                cpuCount = 4
                memoryTotalGb = 8
            
            recommendations = generateSmartRecommendations(
                fileSizeGb, tileType or "map", userMinZoom, userMaxZoom, cpuCount, memoryTotalGb
            )
            
            if recommendations:
                fileInfo["recommendations"] = recommendations
                logMessage(f"ä¸ºæ–‡ä»¶ {filename} ç”Ÿæˆäº†é…ç½®æ¨è", "INFO")
        
        logMessage(f"æ–‡ä»¶ä¿¡æ¯è¯·æ±‚å¤„ç†å®Œæˆ: {filename}", "INFO")
        return jsonify(fileInfo)
    except Exception as e:
        logMessage(f"æ–‡ä»¶ä¿¡æ¯è¯·æ±‚å¤„ç†å¤±è´¥: {filename}, é”™è¯¯: {str(e)}", "ERROR")
        return jsonify({"error": str(e)}), 500

def browseDirectory():
    """
    é€çº§æµè§ˆç›®å½•å’Œæ–‡ä»¶ï¼Œæ”¯æŒåˆ†é¡µå’Œç­›é€‰
    
    @return åŒ…å«ç›®å½•å’Œæ–‡ä»¶ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        # è·å–å‚æ•°
        browseType = request.args.get('type', 'results')
        path = request.args.get('path', '').strip('/')
        
        # ç¡®å®šåŸºç¡€ç›®å½•
        if browseType == 'datasource':
            baseDir = config["dataSourceDir"]
        else:
            baseDir = config["tilesDir"]
            
        # æ„å»ºå®Œæ•´è·¯å¾„
        if path:
            fullPath = os.path.join(baseDir, path)
        else:
            fullPath = baseDir
            
        # å®‰å…¨æ£€æŸ¥
        fullPath = os.path.abspath(fullPath)
        baseDir = os.path.abspath(baseDir)
        if not fullPath.startswith(baseDir):
            return jsonify({"error": "è·¯å¾„ä¸å…è®¸è®¿é—®"}), 403
            
        if not os.path.exists(fullPath):
            return jsonify({"error": "ç›®å½•ä¸å­˜åœ¨"}), 404
            
        if not os.path.isdir(fullPath):
            return jsonify({"error": "è·¯å¾„ä¸æ˜¯ç›®å½•"}), 400
            
        # æ‰«æå½“å‰ç›®å½•
        directories = []
        files = []
        
        try:
            items = os.listdir(fullPath)
            items.sort()
            
            for item in items:
                itemPath = os.path.join(fullPath, item)
                
                if os.path.isdir(itemPath):
                    # ç»Ÿè®¡å­ç›®å½•æ–‡ä»¶æ•°é‡
                    try:
                        subItems = os.listdir(itemPath)
                        subFileCount = len([f for f in subItems if os.path.isfile(os.path.join(itemPath, f))])
                        subDirCount = len([f for f in subItems if os.path.isdir(os.path.join(itemPath, f))])
                    except:
                        subFileCount = 0
                        subDirCount = 0
                    
                    directories.append({
                        "name": item,
                        "type": "directory",
                        "path": os.path.join(path, item) if path else item,
                        "fileCount": subFileCount,
                        "dirCount": subDirCount
                    })
                elif os.path.isfile(itemPath):
                    # æ–‡ä»¶ä¿¡æ¯
                    fileSize = os.path.getsize(itemPath)
                    modTime = os.path.getmtime(itemPath)
                    
                    files.append({
                        "name": item,
                        "type": "file",
                        "size": fileSize,
                        "sizeFormatted": formatFileSize(fileSize),
                        "modifiedTime": modTime,
                        "extension": os.path.splitext(item)[1].lower(),
                        "path": os.path.join(path, item) if path else item
                    })
        
        except PermissionError:
            return jsonify({"error": "æƒé™ä¸è¶³"}), 403
        
        # è®¡ç®—çˆ¶çº§è·¯å¾„
        parentPath = None
        if path:
            pathParts = path.split('/')
            if len(pathParts) > 1:
                parentPath = '/'.join(pathParts[:-1])
            else:
                parentPath = ""
        
        return jsonify({
            "currentPath": path,
            "parentPath": parentPath,
            "baseType": browseType,
            "directories": directories,
            "files": files,
            "totalDirectories": len(directories),
            "totalFiles": len(files)
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def getFileDetails():
    """
    è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬åœ°ç†å±æ€§å’Œå…ƒæ•°æ®
    
    @return åŒ…å«æ–‡ä»¶è¯¦ç»†ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        # è·å–å‚æ•°
        browseType = request.args.get('type', 'results')
        filePath = request.args.get('path', '')
        
        if not filePath:
            return jsonify({"error": "ç¼ºå°‘æ–‡ä»¶è·¯å¾„å‚æ•°"}), 400
        
        # ç¡®å®šåŸºç¡€ç›®å½•
        if browseType == 'datasource':
            baseDir = config["dataSourceDir"]
        else:
            baseDir = config["tilesDir"]
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        fullPath = os.path.join(baseDir, filePath)
        
        # å®‰å…¨æ£€æŸ¥
        fullPath = os.path.abspath(fullPath)
        baseDir = os.path.abspath(baseDir)
        if not fullPath.startswith(baseDir):
            return jsonify({"error": "è·¯å¾„ä¸å…è®¸è®¿é—®"}), 403
        
        if not os.path.exists(fullPath):
            return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        if not os.path.isfile(fullPath):
            return jsonify({"error": "è·¯å¾„ä¸æ˜¯æ–‡ä»¶"}), 400
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        fileInfo = getFileInfo(fullPath)
        return jsonify(fileInfo)
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500


def analyzeTiffGeoContinuity(tifFiles, taskId):
    """
    åˆ†æTIFæ–‡ä»¶çš„åœ°ç†ä½ç½®è¿ç»­æ€§
    
    @param tifFiles TIFæ–‡ä»¶åˆ—è¡¨
    @param taskId ä»»åŠ¡ID
    @return åˆ†æç»“æœå­—å…¸
    """
    try:
        def logMessage(msg):
            with taskLock:
                if taskId in taskStatus:
                    taskStatus[taskId]["message"] = msg
        
        logMessage(f"ğŸ” å¼€å§‹åˆ†æ {len(tifFiles)} ä¸ªTIFæ–‡ä»¶çš„åœ°ç†è¿ç»­æ€§...")
        
        geoInfoList = []
        
        # è·å–æ¯ä¸ªæ–‡ä»¶çš„åœ°ç†ä¿¡æ¯
        for i, tifFile in enumerate(tifFiles):
            try:
                cmd = f"gdalinfo -json '{tifFile}'"
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
                
                if result.returncode == 0:
                    geoData = json.loads(result.stdout)
                    
                    # æå–å…³é”®åœ°ç†ä¿¡æ¯
                    geoTransform = geoData.get('geoTransform', [])
                    size = geoData.get('size', [])
                    
                    if len(geoTransform) >= 6 and len(size) >= 2:
                        # è®¡ç®—è¾¹ç•Œåæ ‡
                        originX, pixelWidth, _, originY, _, pixelHeight = geoTransform
                        width, height = size
                        
                        minX = originX
                        maxX = originX + width * pixelWidth
                        minY = originY + height * pixelHeight
                        maxY = originY
                        
                        geoInfo = {
                            'file': tifFile,
                            'index': i,
                            'minX': minX,
                            'maxX': maxX,
                            'minY': minY,
                            'maxY': maxY,
                            'centerX': (minX + maxX) / 2,
                            'centerY': (minY + maxY) / 2,
                            'width': abs(maxX - minX),
                            'height': abs(maxY - minY),
                            'pixelWidth': abs(pixelWidth),
                            'pixelHeight': abs(pixelHeight),
                            'projection': geoData.get('coordinateSystem', {}).get('wkt', '')
                        }
                        geoInfoList.append(geoInfo)
                        
                        logMessage(f"æ–‡ä»¶ {i+1}/{len(tifFiles)}: {os.path.basename(tifFile)} - èŒƒå›´: ({minX:.2f}, {minY:.2f}) åˆ° ({maxX:.2f}, {maxY:.2f})")
                    
            except Exception as e:
                logMessage(f"âš ï¸ è·å–æ–‡ä»¶ {tifFile} åœ°ç†ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        if len(geoInfoList) < 2:
            return {"continuous": True, "message": "æ–‡ä»¶æ•°é‡ä¸è¶³ï¼Œæ— éœ€æ£€æŸ¥è¿ç»­æ€§"}
        
        # åˆ†æè¿ç»­æ€§
        gaps = []
        overlaps = []
        
        # æŒ‰Xåæ ‡æ’åº
        geoInfoList.sort(key=lambda x: x['centerX'])
        
        for i in range(len(geoInfoList) - 1):
            current = geoInfoList[i]
            next_file = geoInfoList[i + 1]
            
            # æ£€æŸ¥Xæ–¹å‘çš„é—´éš™æˆ–é‡å 
            gap_x = next_file['minX'] - current['maxX']
            if gap_x > current['pixelWidth']:  # æœ‰æ˜æ˜¾é—´éš™
                gaps.append({
                    'type': 'X_gap',
                    'file1': os.path.basename(current['file']),
                    'file2': os.path.basename(next_file['file']),
                    'gap_size': gap_x,
                    'gap_pixels': gap_x / current['pixelWidth']
                })
            elif gap_x < -current['pixelWidth']:  # æœ‰é‡å 
                overlaps.append({
                    'type': 'X_overlap',
                    'file1': os.path.basename(current['file']),
                    'file2': os.path.basename(next_file['file']),
                    'overlap_size': abs(gap_x),
                    'overlap_pixels': abs(gap_x) / current['pixelWidth']
                })
        
        # æŒ‰Yåæ ‡æ’åºæ£€æŸ¥Yæ–¹å‘
        geoInfoList.sort(key=lambda x: x['centerY'])
        
        for i in range(len(geoInfoList) - 1):
            current = geoInfoList[i]
            next_file = geoInfoList[i + 1]
            
            # æ£€æŸ¥Yæ–¹å‘çš„é—´éš™æˆ–é‡å 
            gap_y = next_file['minY'] - current['maxY']
            if gap_y > current['pixelHeight']:  # æœ‰æ˜æ˜¾é—´éš™
                gaps.append({
                    'type': 'Y_gap',
                    'file1': os.path.basename(current['file']),
                    'file2': os.path.basename(next_file['file']),
                    'gap_size': gap_y,
                    'gap_pixels': gap_y / current['pixelHeight']
                })
            elif gap_y < -current['pixelHeight']:  # æœ‰é‡å 
                overlaps.append({
                    'type': 'Y_overlap',
                    'file1': os.path.basename(current['file']),
                    'file2': os.path.basename(next_file['file']),
                    'overlap_size': abs(gap_y),
                    'overlap_pixels': abs(gap_y) / current['pixelHeight']
                })
        
        # ç”ŸæˆæŠ¥å‘Š
        continuous = len(gaps) == 0
        message = f"åœ°ç†è¿ç»­æ€§åˆ†æå®Œæˆ: {len(geoInfoList)} ä¸ªæ–‡ä»¶"
        
        if gaps:
            message += f", å‘ç° {len(gaps)} ä¸ªé—´éš™"
            for gap in gaps[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                message += f"\n  - {gap['file1']} ä¸ {gap['file2']} é—´æœ‰ {gap['gap_pixels']:.1f} åƒç´ é—´éš™"
        
        if overlaps:
            message += f", å‘ç° {len(overlaps)} ä¸ªé‡å "
            for overlap in overlaps[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                message += f"\n  - {overlap['file1']} ä¸ {overlap['file2']} é‡å  {overlap['overlap_pixels']:.1f} åƒç´ "
        
        logMessage(message)
        
        return {
            'continuous': continuous,
            'message': message,
            'gaps': gaps,
            'overlaps': overlaps,
            'geoInfo': geoInfoList
        }
        
    except Exception as e:
        logMessage(f"âŒ åœ°ç†è¿ç»­æ€§åˆ†æå¤±è´¥: {str(e)}")
        return {"continuous": False, "error": str(e)}


def processSingleTerrainFile(fileInfo, outputPath, startZoom, endZoom, maxTriangles, bounds, useCompression, decompressOutput, maxMemory, autoZoom, zoomStrategy, taskId, fileIndex):
    """
    å¤„ç†å•ä¸ªåœ°å½¢æ–‡ä»¶
    
    @param fileInfo æ–‡ä»¶ä¿¡æ¯å­—å…¸
    @param outputPath è¾“å‡ºè·¯å¾„
    @param startZoom èµ·å§‹å±‚çº§
    @param endZoom ç»“æŸå±‚çº§
    @param maxTriangles æœ€å¤§ä¸‰è§’å½¢æ•°
    @param bounds è¾¹ç•Œ
    @param useCompression æ˜¯å¦ä½¿ç”¨å‹ç¼©
    @param decompressOutput æ˜¯å¦è§£å‹è¾“å‡º
    @param maxMemory æœ€å¤§å†…å­˜
    @param autoZoom è‡ªåŠ¨ç¼©æ”¾
    @param zoomStrategy ç¼©æ”¾ç­–ç•¥
    @param taskId ä»»åŠ¡ID
    @param fileIndex æ–‡ä»¶ç´¢å¼•
    @return å¤„ç†ç»“æœ
    """
    try:
        source_path = fileInfo["fullPath"]
        filename = fileInfo["filename"]
        
        logMessage(f"å¼€å§‹å¤„ç†åœ°å½¢æ–‡ä»¶: {filename}")
        
        # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(source_path):
            return {"success": False, "error": f"æºæ–‡ä»¶ä¸å­˜åœ¨: {source_path}"}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(outputPath, exist_ok=True)
        
        # å¤§æ–‡ä»¶é‡‘å­—å¡”ä¼˜åŒ–
        file_size_gb = os.path.getsize(source_path) / (1024**3)
        logMessage(f"æ–‡ä»¶å¤§å°: {file_size_gb:.2f}GB")
        
        if file_size_gb > 5.0:
            logMessage(f"æ£€æµ‹åˆ°å¤§æ–‡ä»¶ï¼Œåˆ›å»ºé‡‘å­—å¡”ä»¥ä¼˜åŒ–å¤„ç†...")
            createTerrainPyramid(source_path)
        
        # æ„å»ºCTBå‘½ä»¤
        ctb_start_zoom = endZoom    # CTBçš„startæ˜¯ç”¨æˆ·çš„endï¼ˆè¯¦ç»†çº§åˆ«ï¼‰
        ctb_end_zoom = startZoom    # CTBçš„endæ˜¯ç”¨æˆ·çš„startï¼ˆç²—ç³™çº§åˆ«ï¼‰
        
        cmd = [
            "ctb-tile",
            "-f", "Mesh"
        ]
        
        if useCompression:
            cmd.append("-C")
        
        # è½¬æ¢å†…å­˜å‚æ•°
        def convertMemoryToBytes(memoryStr):
            """å°†å†…å­˜å­—ç¬¦ä¸²è½¬æ¢ä¸ºå­—èŠ‚æ•°"""
            if isinstance(memoryStr, int):
                return str(memoryStr * 1024 * 1024)  # å‡è®¾è¾“å…¥æ˜¯MB
            
            memoryStr = str(memoryStr).lower()
            
            if 'g' in memoryStr:
                gb = float(memoryStr.replace('g', ''))
                return str(int(gb * 1024 * 1024 * 1024))  # GBè½¬å­—èŠ‚
            elif 'm' in memoryStr:
                mb = float(memoryStr.replace('m', ''))
                return str(int(mb * 1024 * 1024))  # MBè½¬å­—èŠ‚
            elif 'k' in memoryStr:
                kb = float(memoryStr.replace('k', ''))
                return str(int(kb * 1024))  # KBè½¬å­—èŠ‚
            else:
                # å‡è®¾æ˜¯MB
                try:
                    mb = float(memoryStr)
                    return str(int(mb * 1024 * 1024))
                except:
                    return "2147483648"  # é»˜è®¤2GBçš„å­—èŠ‚æ•°
        
        ctb_memory = convertMemoryToBytes(maxMemory)
        
        cmd.extend([
            "-o", outputPath,
            "-s", str(ctb_start_zoom),
            "-e", str(ctb_end_zoom),
            "-m", ctb_memory,
            "-v",  # è¯¦ç»†è¾“å‡º
            source_path
        ])
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()
        env['GDAL_CACHEMAX'] = maxMemory.rstrip('gmGM')
        env['GDAL_NUM_THREADS'] = '1'  # å•ä¸ªæ–‡ä»¶å¤„ç†ä½¿ç”¨å•çº¿ç¨‹
        env['OMP_NUM_THREADS'] = '1'
        
        logMessage(f"æ‰§è¡ŒCTBå‘½ä»¤: {' '.join(cmd)}")
        result = runCommand(cmd, env=env)
        
        if result["success"]:
            # ä½¿ç”¨CTBå•ç‹¬ç”Ÿæˆlayer.json
            layer_cmd = [
                "ctb-tile", "-l", "-f", "Mesh",
                "-o", outputPath,
                "-s", str(ctb_start_zoom),
                "-e", str(ctb_end_zoom),
                "-m", ctb_memory,
                "-v", 
                source_path
            ]
            layer_result = runCommand(layer_cmd, env=env)
            
            if layer_result["success"]:
                logMessage(f"CTBç”Ÿæˆlayer.jsonæˆåŠŸ: {filename}")
                # ä¿®å¤CTBç”Ÿæˆçš„layer.jsonçš„boundså’Œavailableæ•°ç»„
                logMessage(f"ä¿®å¤layer.jsonçš„boundså’Œavailable: {filename}")
                updateCtbLayerJsonBounds(outputPath, bounds)
            else:
                logMessage(f"CTBç”Ÿæˆlayer.jsonå¤±è´¥: {filename} - {layer_result.get('stderr', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
            
            # è§£å‹terrainæ–‡ä»¶
            if decompressOutput:
                logMessage(f"å¼€å§‹è§£å‹terrainæ–‡ä»¶: {filename}")
                decompressTerrainFiles(outputPath)
                logMessage(f"terrainæ–‡ä»¶è§£å‹å®Œæˆ: {filename}")
            
            # ç»Ÿè®¡ç”Ÿæˆçš„terrainæ–‡ä»¶æ•°é‡
            terrain_count = 0
            for root, dirs, files in os.walk(outputPath):
                terrain_count += len([f for f in files if f.endswith('.terrain')])
            
            return {
                "success": True,
                "outputPath": outputPath,
                "terrainFiles": terrain_count,
                "filename": filename
            }
        else:
            return {
                "success": False,
                "error": result.get('stderr', 'æœªçŸ¥é”™è¯¯'),
                "filename": filename
            }
            
    except Exception as e:
        logMessage(f"å¤„ç†åœ°å½¢æ–‡ä»¶å¤±è´¥ {fileInfo.get('filename', 'unknown')}: {e}", "ERROR")
        return {
            "success": False,
            "error": str(e),
            "filename": fileInfo.get("filename", "unknown")
        }

def createTerrainTiles():
    """
    åˆ›å»ºåœ°å½¢ç“¦ç‰‡ï¼Œä½¿ç”¨Cesium Terrain Builderç”Ÿæˆåœ°å½¢æ•°æ®
    æ”¯æŒå•ä¸ªæ–‡ä»¶å’Œæ‰¹é‡æ–‡ä»¶å¤„ç†ï¼Œä»¥åŠåœ°å½¢åˆå¹¶åŠŸèƒ½
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ‰¹é‡å¤„ç†å¤šä¸ªTIFæ–‡ä»¶
    2. æ™ºèƒ½ç¼©æ”¾çº§åˆ«æ¨è
    3. åœ°å½¢ç“¦ç‰‡åˆå¹¶åŠŸèƒ½ï¼ˆNEWï¼‰
    4. ä»»åŠ¡è¿›åº¦ç›‘æ§
    
    åœ°å½¢åˆå¹¶åŠŸèƒ½ï¼š
    - å‚æ•°ï¼šmergeTerrains (boolean) - æ˜¯å¦åœ¨åˆ‡ç‰‡å®Œæˆååˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶å¤¹
    - å½“è®¾ç½®ä¸ºtrueæ—¶ï¼Œç³»ç»Ÿä¼šåœ¨æ‰€æœ‰åœ°å½¢åˆ‡ç‰‡å®Œæˆåè‡ªåŠ¨åˆå¹¶
    - æ™ºèƒ½åˆå¹¶layer.jsonæ–‡ä»¶ï¼ŒåŒ…æ‹¬è¾¹ç•Œä¿¡æ¯
    - ä½¿ç”¨ç¡¬é“¾æ¥èŠ‚çœç£ç›˜ç©ºé—´ï¼Œé¿å…é‡å¤ç“¦ç‰‡
    
    @return åŒ…å«ä»»åŠ¡ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        logMessage("æ”¶åˆ°åœ°å½¢ç“¦ç‰‡åˆ›å»ºè¯·æ±‚", "INFO")
        data = request.get_json()
        
        if data is None:
            error_msg = "è¯·æ±‚æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è§£æJSON"
            logMessage(f"åœ°å½¢ç“¦ç‰‡åˆ›å»ºå¤±è´¥: {error_msg}", "ERROR")
            return jsonify({"error": error_msg}), 400
        
        logMessage(f"åœ°å½¢ç“¦ç‰‡è¯·æ±‚å‚æ•°: {data}", "INFO")
        
        # ç»Ÿä¸€å‚æ•°å¤„ç†
        outputPathArray = data.get('outputPath', [])
        startZoom = data.get('startZoom', 0)
        endZoom = data.get('endZoom', 8)
        
        # åœ°å½¢ç‰¹æ®Šå‚æ•°
        maxTriangles = data.get('maxTriangles', 32768)
        bounds = data.get('bounds')
        useCompression = data.get('compression', True)
        decompressOutput = data.get('decompress', True)
        autoZoom = data.get('autoZoom', False)
        zoomStrategy = data.get('zoomStrategy', 'conservative')
        
        # æ€§èƒ½å‚æ•°
        maxMemory = data.get('maxMemory', '8m')
        threads = data.get('threads', min(4, config["maxThreads"]))
        
        # åœ°å½¢åˆå¹¶å‚æ•°
        mergeTerrains = data.get('mergeTerrains', False)  # æ˜¯å¦åœ¨åˆ‡ç‰‡å®Œæˆååˆå¹¶æˆä¸€ä¸ªæ–‡ä»¶å¤¹
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"terrain{timestamp}"
        
        # å‚æ•°éªŒè¯å’Œé”™è¯¯å¤„ç† - å³ä½¿æœ‰é”™è¯¯ä¹Ÿåˆ›å»ºä»»åŠ¡
        errors = []
        
        if not outputPathArray:
            errors.append("ç¼ºå°‘å‚æ•°: outputPath")
        if endZoom < 8:
            errors.append("åœ°å½¢åˆ‡ç‰‡çš„æœ€å¤§å±‚çº§(endZoom)å¿…é¡»å¤§äºç­‰äº8")
        
        # è·å–æ–‡ä»¶åˆ—è¡¨ - ç»Ÿä¸€æ‰¹é‡å¤„ç†
        tifFiles = []
        
        # ç»Ÿä¸€å‚æ•°ï¼šéƒ½ç”¨ folderPaths å’Œ filePatterns
        folderPaths = data.get('folderPaths')
        filePatterns = data.get('filePatterns')
        
        if not folderPaths:
            errors.append("ç¼ºå°‘å‚æ•°: folderPaths")
        if not filePatterns:
            errors.append("ç¼ºå°‘å‚æ•°: filePatterns")
        
        # å¦‚æœæ²¡æœ‰åŸºç¡€å‚æ•°é”™è¯¯ï¼Œå°è¯•æŸ¥æ‰¾æ–‡ä»¶
        if not errors:
            relativeTifFiles = findTifFilesInFolders(folderPaths, filePatterns)
            if not relativeTifFiles:
                errors.append("æœªæ‰¾åˆ°åŒ¹é…çš„TIFæ–‡ä»¶")
            else:
                for relativePath in relativeTifFiles:
                    fullPath = os.path.join(config["dataSourceDir"], relativePath)
                    if os.path.exists(fullPath):
                        tifFiles.append({
                            "relativePath": relativePath,
                            "fullPath": fullPath,
                            "filename": os.path.basename(relativePath)
                        })
                
                if not tifFiles:
                    errors.append("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„TIFæ–‡ä»¶")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œåˆ›å»ºå¤±è´¥çŠ¶æ€çš„ä»»åŠ¡
        if errors:
            with taskLock:
                taskStatus[taskId] = {
                    "status": "failed",
                    "progress": 0,
                    "message": f"åœ°å½¢ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                    "startTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "processLog": [
                        {
                            "stage": "åˆå§‹åŒ–",
                            "status": "failed",
                            "message": f"ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                            "timestamp": datetime.now().isoformat(),
                            "progress": 0,
                            "errors": errors
                        }
                    ],
                    "currentStage": "åˆå§‹åŒ–å¤±è´¥",
                    "result": {
                        "totalFiles": 0,
                        "completedFiles": 0,
                        "failedFiles": 0,
                        "totalTerrainFiles": 0,
                        "errors": errors
                    }
                }
            
            logMessage(f"åœ°å½¢ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {taskId}, é”™è¯¯: {'; '.join(errors)}", "ERROR")
            return jsonify({
                "success": False,
                "taskId": taskId,
                "message": f"åœ°å½¢ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                "statusUrl": f"/api/tasks/{taskId}",
                "errors": errors
            }), 200  # è¿”å›200ï¼Œå› ä¸ºä»»åŠ¡å·²ç»åˆ›å»º
        
        # æ„å»ºè¾“å‡ºè·¯å¾„
        if isinstance(outputPathArray, str):
            outputPath = os.path.join(config["tilesDir"], outputPathArray)
        elif isinstance(outputPathArray, list):
            outputPath = os.path.join(config["tilesDir"], *outputPathArray)
        else:
            outputPath = os.path.join(config["tilesDir"], str(outputPathArray))
        
        os.makedirs(outputPath, exist_ok=True)
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"terrain{timestamp}"
        
        # å¯åŠ¨åœ°å½¢åˆ‡ç‰‡ä»»åŠ¡
        def runTerrainTask():
            # é‡æ–°è·å–tifFileså˜é‡
            nonlocal tifFiles
            try:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "running",
                        "progress": 0,
                        "message": f"å¼€å§‹åœ°å½¢åˆ‡ç‰‡ï¼Œå…±{len(tifFiles)}ä¸ªæ–‡ä»¶...",
                        "startTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "files": {
                            "total": len(tifFiles),
                            "completed": 0,
                            "failed": 0,
                            "current": None
                        },
                        "processLog": [
                            {
                                "stage": "åˆå§‹åŒ–",
                                "status": "completed",
                                "message": f"ä»»åŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¤„ç†{len(tifFiles)}ä¸ªæ–‡ä»¶",
                                "timestamp": datetime.now().isoformat(),
                                "progress": 0
                            }
                        ],
                        "currentStage": "æ–‡ä»¶å¤„ç†"
                    }
                
                completed_files = []
                failed_files = []
                
                # å…ˆåˆ†æTIFæ–‡ä»¶çš„åœ°ç†è¿ç»­æ€§
                if len(tifFiles) > 1:
                    tifFilesPaths = [fileInfo["fullPath"] for fileInfo in tifFiles]
                    continuityResult = analyzeTiffGeoContinuity(tifFilesPaths, taskId)
                    
                    # è®°å½•åˆ†æç»“æœ
                    def logGeoMessage(msg):
                        with taskLock:
                            taskStatus[taskId]["message"] = msg
                    
                    if continuityResult.get("continuous"):
                        logGeoMessage("âœ… TIFæ–‡ä»¶åœ°ç†ä½ç½®è¿ç»­ï¼Œæ— æ˜æ˜¾é—´éš™")
                    else:
                        logGeoMessage("âš ï¸ å‘ç°TIFæ–‡ä»¶é—´å­˜åœ¨åœ°ç†é—´éš™ï¼Œè¿™å¯èƒ½æ˜¯ç¼éš™çš„åŸå› ")
                        if continuityResult.get("gaps"):
                            logGeoMessage(f"å‘ç° {len(continuityResult['gaps'])} ä¸ªåœ°ç†é—´éš™")
                        if continuityResult.get("overlaps"):
                            logGeoMessage(f"å‘ç° {len(continuityResult['overlaps'])} ä¸ªåœ°ç†é‡å ")
                
                # æ³¨ï¼šå·²ç§»é™¤TIFæ–‡ä»¶æ™ºèƒ½åˆå¹¶é¢„å¤„ç†ï¼Œæ”¹ç”¨åå¤„ç†è¾¹ç•Œå¹³æ»‘
                
                # é¡ºåºå¤„ç†æ¨¡å¼
                logMessage(f"ğŸ“‹ é¡ºåºå¤„ç†æ¨¡å¼ï¼šä¾æ¬¡å¤„ç†{len(tifFiles)}ä¸ªæ–‡ä»¶")
                
                for i, fileInfo in enumerate(tifFiles):
                    try:
                        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«åœæ­¢
                        with taskLock:
                            if taskId in taskStatus and taskStatus[taskId].get("status") == "stopped":
                                logMessage(f"â¹ï¸ åœ°å½¢ç“¦ç‰‡ä»»åŠ¡ {taskId} å·²è¢«åœæ­¢ï¼Œé€€å‡ºå¤„ç†", "INFO")
                                return
                        
                        # æ›´æ–°å½“å‰å¤„ç†æ–‡ä»¶
                        with taskLock:
                            taskStatus[taskId]["files"]["current"] = fileInfo["filename"]
                            taskStatus[taskId]["message"] = f"æ­£åœ¨å¤„ç†æ–‡ä»¶ {i+1}/{len(tifFiles)}: {fileInfo['filename']}"
                        
                        # ç¡®å®šè¾“å‡ºè·¯å¾„
                        if len(tifFiles) > 1:
                            subOutputPath = os.path.join(outputPath, f"file_{i:03d}_{fileInfo['filename'].replace('.tif', '')}")
                        else:
                            subOutputPath = outputPath
                        
                        # å¤„ç†å•ä¸ªæ–‡ä»¶
                        result = processSingleTerrainFile(
                            fileInfo, subOutputPath, startZoom, endZoom,
                            maxTriangles, bounds, useCompression, decompressOutput,
                            maxMemory, autoZoom, zoomStrategy, taskId, i
                        )
                        
                        if result["success"]:
                            completed_files.append({
                                "filename": fileInfo["filename"],
                                "outputPath": result["outputPath"],
                                "terrainFiles": result.get("terrainFiles", 0)
                            })
                            logMessage(f"âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: {fileInfo['filename']}")
                        else:
                            failed_files.append({
                                "filename": fileInfo["filename"],
                                "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                            })
                            logMessage(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {fileInfo['filename']} - {result.get('error')}", "ERROR")
                        
                        # æ›´æ–°è¿›åº¦
                        with taskLock:
                            taskStatus[taskId]["files"]["completed"] = len(completed_files)
                            taskStatus[taskId]["files"]["failed"] = len(failed_files)
                            taskStatus[taskId]["progress"] = int((i + 1) / len(tifFiles) * 100)
                            
                            # æ·»åŠ è¿‡ç¨‹è®°å½•
                            if result["success"]:
                                taskStatus[taskId]["processLog"].append({
                                    "stage": "æ–‡ä»¶å¤„ç†",
                                    "status": "completed",
                                    "message": f"æ–‡ä»¶ {fileInfo['filename']} å¤„ç†æˆåŠŸï¼Œç”Ÿæˆäº† {result.get('terrainFiles', 0)} ä¸ªåœ°å½¢æ–‡ä»¶",
                                    "timestamp": datetime.now().isoformat(),
                                    "progress": int((i + 1) / len(tifFiles) * 100),
                                    "fileInfo": {
                                        "filename": fileInfo["filename"],
                                        "outputPath": result["outputPath"],
                                        "terrainFiles": result.get("terrainFiles", 0)
                                    }
                                })
                            else:
                                taskStatus[taskId]["processLog"].append({
                                    "stage": "æ–‡ä»¶å¤„ç†",
                                    "status": "failed",
                                    "message": f"æ–‡ä»¶ {fileInfo['filename']} å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                                    "timestamp": datetime.now().isoformat(),
                                    "progress": int((i + 1) / len(tifFiles) * 100),
                                    "fileInfo": {
                                        "filename": fileInfo["filename"],
                                        "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                                    }
                                })
                            
                    except Exception as e:
                        failed_files.append({
                            "filename": fileInfo["filename"],
                            "error": str(e)
                        })
                        logMessage(f"é¡ºåºå¤„ç†æ–‡ä»¶å¤±è´¥ {fileInfo['filename']}: {e}", "ERROR")
                
                # ä»»åŠ¡å®Œæˆ
                total_terrain_files = sum(file_info.get("terrainFiles", 0) for file_info in completed_files)
                
                with taskLock:
                    # ä¿ç•™ç°æœ‰çš„è¿‡ç¨‹è®°å½•
                    existing_process_log = taskStatus[taskId].get("processLog", [])
                    
                    # æ·»åŠ æœ€ç»ˆå®Œæˆè®°å½•
                    existing_process_log.append({
                        "stage": "ä»»åŠ¡å®Œæˆ",
                        "status": "completed",
                        "message": f"åœ°å½¢åˆ‡ç‰‡ä»»åŠ¡å®Œæˆ! æˆåŠŸå¤„ç†:{len(completed_files)}ä¸ªæ–‡ä»¶, å¤±è´¥:{len(failed_files)}ä¸ªæ–‡ä»¶, æ€»å…±ç”Ÿæˆ:{total_terrain_files}ä¸ªåœ°å½¢ç“¦ç‰‡",
                        "timestamp": datetime.now().isoformat(),
                        "progress": 100,
                        "summary": {
                            "totalFiles": len(tifFiles),
                            "completedFiles": len(completed_files),
                            "failedFiles": len(failed_files),
                            "totalTerrainFiles": total_terrain_files
                        }
                    })
                    
                    taskStatus[taskId] = {
                        "status": "completed",
                        "progress": 100,
                        "message": f"åœ°å½¢åˆ‡ç‰‡å®Œæˆ! æˆåŠŸ:{len(completed_files)}ä¸ª, å¤±è´¥:{len(failed_files)}ä¸ª, æ€»ç“¦ç‰‡:{total_terrain_files}ä¸ª",
                        "startTime": taskStatus[taskId]["startTime"],
                        "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "processLog": existing_process_log,
                        "currentStage": "å·²å®Œæˆ",
                        "result": {
                            "totalFiles": len(tifFiles),
                            "completedFiles": len(completed_files),
                            "failedFiles": len(failed_files),
                            "totalTerrainFiles": total_terrain_files,
                            "completedDetails": completed_files,
                            "failedDetails": failed_files,
                            "outputPath": outputPath
                        }
                    }
                
                # åœ°å½¢åˆå¹¶å¤„ç†
                if mergeTerrains and len(completed_files) > 1:
                    try:
                        logMessage(f"ğŸ”„ å¼€å§‹åˆå¹¶åœ°å½¢ç“¦ç‰‡...")
                        with taskLock:
                            existing_process_log = taskStatus[taskId]["processLog"]
                            existing_process_log.append({
                                "stage": "åœ°å½¢åˆå¹¶",
                                "status": "running", 
                                "message": "å¼€å§‹åˆå¹¶å¤šä¸ªåœ°å½¢æ–‡ä»¶å¤¹",
                                "timestamp": datetime.now().isoformat(),
                                "progress": 95
                            })
                            taskStatus[taskId]["currentStage"] = "åœ°å½¢åˆå¹¶ä¸­"
                            taskStatus[taskId]["message"] = "æ­£åœ¨åˆå¹¶åœ°å½¢ç“¦ç‰‡..."
                            taskStatus[taskId]["processLog"] = existing_process_log
                        
                        # æ‰§è¡Œåœ°å½¢åˆå¹¶ - ç›´æ¥ä½¿ç”¨è¾“å‡ºè·¯å¾„
                        mergeResult = mergeTerrainTiles(completed_files, outputPath, taskId)
                        
                        if mergeResult["success"]:
                            logMessage(f"âœ… åœ°å½¢åˆå¹¶æˆåŠŸ: {outputPath}")
                            with taskLock:
                                existing_process_log = taskStatus[taskId]["processLog"]
                                existing_process_log.append({
                                    "stage": "åœ°å½¢åˆå¹¶",
                                    "status": "completed",
                                    "message": f"åœ°å½¢åˆå¹¶å®Œæˆï¼Œè¾“å‡ºè·¯å¾„: {outputPath}",
                                    "timestamp": datetime.now().isoformat(),
                                    "progress": 100
                                })
                                taskStatus[taskId]["processLog"] = existing_process_log
                                # æ›´æ–°ç»“æœä¸­çš„è¾“å‡ºè·¯å¾„
                                taskStatus[taskId]["result"]["mergedOutputPath"] = outputPath
                                taskStatus[taskId]["result"]["mergeDetails"] = mergeResult
                        else:
                            logMessage(f"âŒ åœ°å½¢åˆå¹¶å¤±è´¥: {mergeResult.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            with taskLock:
                                existing_process_log = taskStatus[taskId]["processLog"]
                                existing_process_log.append({
                                    "stage": "åœ°å½¢åˆå¹¶",
                                    "status": "failed",
                                    "message": f"åœ°å½¢åˆå¹¶å¤±è´¥: {mergeResult.get('error', 'æœªçŸ¥é”™è¯¯')}",
                                    "timestamp": datetime.now().isoformat(),
                                    "progress": 100
                                })
                                taskStatus[taskId]["processLog"] = existing_process_log
                                taskStatus[taskId]["result"]["mergeError"] = mergeResult.get('error', 'æœªçŸ¥é”™è¯¯')
                    
                    except Exception as me:
                        logMessage(f"âŒ åœ°å½¢åˆå¹¶å¼‚å¸¸: {me}", "ERROR")
                        with taskLock:
                            existing_process_log = taskStatus[taskId]["processLog"]
                            existing_process_log.append({
                                "stage": "åœ°å½¢åˆå¹¶",
                                "status": "failed",
                                "message": f"åœ°å½¢åˆå¹¶å¼‚å¸¸: {str(me)}",
                                "timestamp": datetime.now().isoformat(),
                                "progress": 100
                            })
                            taskStatus[taskId]["processLog"] = existing_process_log
                            taskStatus[taskId]["result"]["mergeError"] = str(me)
                
                logMessage(f"ğŸ‰ åœ°å½¢åˆ‡ç‰‡ä»»åŠ¡å®Œæˆ: {taskId}")
                
            except Exception as e:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "failed",
                        "progress": 0,
                        "message": f"åœ°å½¢åˆ‡ç‰‡å¤±è´¥: {str(e)}",
                        "startTime": taskStatus[taskId]["startTime"],
                        "error": str(e),
                        "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                
                logMessage(f"âŒ åœ°å½¢åˆ‡ç‰‡å¤±è´¥: {taskId} - {e}", "ERROR")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        import threading
        taskThread = threading.Thread(target=runTerrainTask)
        taskThread.daemon = True
        
        # ä¿å­˜çº¿ç¨‹å¯¹è±¡åˆ°taskProcessesä»¥ä¾¿åœæ­¢
        with taskLock:
            taskProcesses[taskId] = taskThread
        
        taskThread.start()
        
        return jsonify({
            "success": True,
            "taskId": taskId,
            "message": f"åœ°å½¢åˆ‡ç‰‡ä»»åŠ¡å·²å¯åŠ¨ï¼Œå°†å¤„ç† {len(tifFiles)} ä¸ªæ–‡ä»¶",
            "statusUrl": f"/api/tasks/{taskId}",
            "parameters": {
                "totalFiles": len(tifFiles),
                "outputPath": outputPathArray,
                "zoomRange": f"{startZoom}-{endZoom}",
                "threads": threads,
                "maxMemory": maxMemory,
                "type": "terrain"
            }
        })
        
    except Exception as e:
        error_msg = f"åœ°å½¢ç“¦ç‰‡åˆ›å»ºå¤±è´¥: {str(e)}"
        logMessage(error_msg, "ERROR")
        return jsonify({"error": error_msg}), 500

def splitLargeFile():
    """
    æ‹†åˆ†å¤§æ–‡ä»¶ä¸ºåˆ†å¹…çš„å°TIFæ–‡ä»¶
    
    @return åŒ…å«æ‹†åˆ†ä»»åŠ¡ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        data = request.get_json()
        logMessage("æ”¶åˆ°æ–‡ä»¶æ‹†åˆ†è¯·æ±‚", "INFO")
        
        # å‚æ•°éªŒè¯
        requiredParams = ['sourceFile', 'outputPath']
        for param in requiredParams:
            if param not in data:
                return jsonify({"error": f"ç¼ºå°‘å‚æ•°: {param}"}), 400
        
        sourceFile = data['sourceFile']
        outputPathArray = data['outputPath']
        
        # æ‹†åˆ†å‚æ•°
        tileSize = data.get('tileSize', 4096)  # é»˜è®¤4096x4096åƒç´ 
        overlap = data.get('overlap', 0)  # é‡å åƒç´ æ•°
        maxFileSize = data.get('maxFileSize', 1.0)  # æœ€å¤§æ–‡ä»¶å¤§å°GB
        namingPattern = data.get('namingPattern', 'tile_{x}_{y}')  # å‘½åæ¨¡å¼
        
        # æ–‡ä»¶è·¯å¾„å¤„ç†
        sourcePath = os.path.join(config["dataSourceDir"], sourceFile)
        if isinstance(outputPathArray, list):
            outputPath = os.path.join(config["dataSourceDir"], *outputPathArray)
        else:
            outputPath = os.path.join(config["dataSourceDir"], outputPathArray)
        
        if not os.path.exists(sourcePath):
            return jsonify({"error": "æºæ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        fileSizeGB = os.path.getsize(sourcePath) / (1024**3)
        if fileSizeGB < maxFileSize:
            return jsonify({
                "message": "æ–‡ä»¶å¤§å°æœªè¶…è¿‡é˜ˆå€¼ï¼Œæ— éœ€æ‹†åˆ†",
                "fileSize": f"{fileSizeGB:.2f}GB",
                "threshold": f"{maxFileSize}GB",
                "skipSplit": True
            })
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(outputPath, exist_ok=True)
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"split{timestamp}"
        
        def runSplitTask():
            try:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "running",
                        "progress": 0,
                        "message": "æ­£åœ¨åˆ†ææ–‡ä»¶ä¿¡æ¯...",
                        "startTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                
                # è·å–æ–‡ä»¶ä¿¡æ¯
                logMessage(f"å¼€å§‹æ‹†åˆ†æ–‡ä»¶: {sourcePath} -> {outputPath}")
                
                # ä½¿ç”¨gdalinfoè·å–æ–‡ä»¶ä¿¡æ¯
                gdalinfoCmd = ["gdalinfo", sourcePath]
                result = subprocess.run(gdalinfoCmd, capture_output=True, text=True, timeout=30)
                
                if result.returncode != 0:
                    raise Exception(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {result.stderr}")
                
                # è§£ææ–‡ä»¶å°ºå¯¸
                import re
                sizeMatch = re.search(r'Size is (\d+), (\d+)', result.stdout)
                if not sizeMatch:
                    raise Exception("æ— æ³•è§£ææ–‡ä»¶å°ºå¯¸")
                
                width = int(sizeMatch.group(1))
                height = int(sizeMatch.group(2))
                
                logMessage(f"æ–‡ä»¶å°ºå¯¸: {width}x{height}")
                
                # è®¡ç®—åˆ†å—æ•°é‡
                tilesX = (width + tileSize - 1) // tileSize
                tilesY = (height + tileSize - 1) // tileSize
                totalTiles = tilesX * tilesY
                
                logMessage(f"è®¡åˆ’æ‹†åˆ†ä¸º {tilesX}x{tilesY} = {totalTiles} ä¸ªåˆ†å—")
                
                with taskLock:
                    taskStatus[taskId]["message"] = f"å¼€å§‹æ‹†åˆ†ä¸º {totalTiles} ä¸ªåˆ†å—"
                    taskStatus[taskId]["progress"] = 10
                
                # ğŸš€ å¹¶è¡Œæ‹†åˆ†æ–‡ä»¶ - æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒ
                splitFiles = []
                
                # å‡†å¤‡æ‹†åˆ†ä»»åŠ¡åˆ—è¡¨
                split_tasks = []
                for y in range(tilesY):
                    for x in range(tilesX):
                        # è®¡ç®—çª—å£åæ ‡
                        xOff = x * tileSize
                        yOff = y * tileSize
                        xSize = min(tileSize + overlap, width - xOff)
                        ySize = min(tileSize + overlap, height - yOff)
                        
                        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                        outputFileName = namingPattern.format(x=x, y=y) + ".tif"
                        outputFilePath = os.path.join(outputPath, outputFileName)
                        
                        split_tasks.append({
                            "x": x, "y": y,
                            "xOff": xOff, "yOff": yOff,
                            "xSize": xSize, "ySize": ySize,
                            "outputPath": outputFilePath,
                            "sourcePath": sourcePath
                        })
                
                logMessage(f"ğŸš€ å¯åŠ¨é«˜é€Ÿå¹¶è¡Œæ‹†åˆ†: {len(split_tasks)} ä¸ªåˆ†å—")
                
                # ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œæ‹†åˆ†
                from concurrent.futures import ProcessPoolExecutor, as_completed
                import multiprocessing as mp
                
                # è®¡ç®—æœ€ä¼˜è¿›ç¨‹æ•°
                max_workers = min(mp.cpu_count() * 2, 12, len(split_tasks))
                
                def process_user_split_task(task):
                    """å¤„ç†ç”¨æˆ·æ‹†åˆ†ä»»åŠ¡"""
                    try:
                        translateCmd = [
                            "gdal_translate",
                            "-srcwin", str(task["xOff"]), str(task["yOff"]), 
                                      str(task["xSize"]), str(task["ySize"]),
                            "-co", "COMPRESS=LZW",
                            "-co", "TILED=YES",
                            "-co", "BLOCKXSIZE=512",
                            "-co", "BLOCKYSIZE=512",
                            "-co", "NUM_THREADS=2",
                            "-co", "BIGTIFF=IF_SAFER",
                            "-q",
                            task["sourcePath"],
                            task["outputPath"]
                        ]
                        
                        result = subprocess.run(translateCmd, capture_output=True, text=True, timeout=300)
                        
                        if result.returncode == 0:
                            return {
                                "success": True,
                                "outputPath": task["outputPath"],
                                "x": task["x"], "y": task["y"]
                            }
                        else:
                            return {
                                "success": False,
                                "error": result.stderr,
                                "x": task["x"], "y": task["y"]
                            }
                    except Exception as e:
                        return {
                            "success": False,
                            "error": str(e),
                            "x": task["x"], "y": task["y"]
                        }
                
                # å¹¶è¡Œæ‰§è¡Œæ‹†åˆ†
                processedTiles = 0
                failed_tiles = 0
                split_start_time = time.time()
                
                with ProcessPoolExecutor(max_workers=max_workers) as executor:
                    # æäº¤æ‰€æœ‰ä»»åŠ¡
                    future_to_task = {executor.submit(process_user_split_task, task): task for task in split_tasks}
                    
                    # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                    for future in as_completed(future_to_task):
                        result = future.result()
                        
                        if result["success"]:
                            splitFiles.append(os.path.relpath(result["outputPath"], config["dataSourceDir"]))
                            processedTiles += 1
                        else:
                            failed_tiles += 1
                            logMessage(f"åˆ†å—æ‹†åˆ†å¤±è´¥ ({result['x']},{result['y']}): {result['error']}", "WARNING")
                        
                        # æ›´æ–°è¿›åº¦
                        progress = 10 + int((processedTiles / totalTiles) * 80)
                        with taskLock:
                            taskStatus[taskId]["progress"] = progress
                            taskStatus[taskId]["message"] = f"é«˜é€Ÿæ‹†åˆ†è¿›åº¦: {processedTiles}/{totalTiles}"
                        
                        # æ¯20ä¸ªåˆ†å—æŠ¥å‘Šä¸€æ¬¡æ€§èƒ½
                        if processedTiles % 20 == 0:
                            elapsed = time.time() - split_start_time
                            speed = processedTiles / elapsed if elapsed > 0 else 0
                            logMessage(f"âš¡ æ‹†åˆ†é€Ÿåº¦: {speed:.1f}å—/ç§’, å·²å®Œæˆ: {processedTiles}/{totalTiles}")
                
                # æ‹†åˆ†å®Œæˆç»Ÿè®¡
                total_split_time = time.time() - split_start_time
                final_speed = processedTiles / total_split_time if total_split_time > 0 else 0
                
                logMessage(f"ğŸ‰ å¹¶è¡Œæ‹†åˆ†å®Œæˆ! è€—æ—¶: {total_split_time:.1f}ç§’, "
                          f"å¹³å‡é€Ÿåº¦: {final_speed:.1f}å—/ç§’, æˆåŠŸ: {processedTiles}, å¤±è´¥: {failed_tiles}")
                
                if failed_tiles > 0:
                    logMessage(f"âš ï¸  {failed_tiles} ä¸ªåˆ†å—å¤±è´¥ï¼Œç»§ç»­å¤„ç†æˆåŠŸçš„åˆ†å—", "WARNING")
                
                # ä»»åŠ¡å®Œæˆ
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "completed",
                        "progress": 100,
                        "message": f"æ–‡ä»¶æ‹†åˆ†å®Œæˆï¼ç”Ÿæˆ {len(splitFiles)} ä¸ªåˆ†å—",
                        "result": {
                            "sourceFile": sourceFile,
                            "outputPath": outputPath,
                            "splitFiles": splitFiles,
                            "totalFiles": len(splitFiles),
                            "tileSize": tileSize,
                            "overlap": overlap,
                            "originalSize": f"{fileSizeGB:.2f}GB",
                            "tilesX": tilesX,
                            "tilesY": tilesY
                        },
                        "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                
                logMessage(f"âœ… æ–‡ä»¶æ‹†åˆ†ä»»åŠ¡å®Œæˆ: {taskId}")
                
            except Exception as e:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "failed",
                        "progress": 0,
                        "message": f"æ–‡ä»¶æ‹†åˆ†å¤±è´¥: {str(e)}",
                        "error": str(e),
                        "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                
                logMessage(f"âŒ æ–‡ä»¶æ‹†åˆ†å¤±è´¥: {taskId} - {e}", "ERROR")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        taskThread = threading.Thread(target=runSplitTask)
        taskThread.daemon = True
        taskThread.start()
        
        return jsonify({
            "message": "æ–‡ä»¶æ‹†åˆ†ä»»åŠ¡å·²å¯åŠ¨",
            "taskId": taskId,
            "statusUrl": f"/api/tasks/{taskId}",
            "sourceFile": sourceFile,
            "outputPath": outputPath,
            "fileSize": f"{fileSizeGB:.2f}GB",
            "splitConfig": {
                "tileSize": tileSize,
                "overlap": overlap,
                "maxFileSize": maxFileSize,
                "namingPattern": namingPattern
            }
        })
        
    except Exception as e:
        logMessage(f"æ–‡ä»¶æ‹†åˆ†APIå¼‚å¸¸: {e}", "ERROR")
        return jsonify({"error": str(e)}), 500

def performInternalFileSplit(sourcePath, splitTileSize, taskId):
    """
    å†…éƒ¨æ–‡ä»¶æ‹†åˆ†åŠŸèƒ½
    
    @param sourcePath æºæ–‡ä»¶è·¯å¾„
    @param splitTileSize æ‹†åˆ†å—å¤§å°
    @param taskId ä»»åŠ¡ID
    @return æ‹†åˆ†ç»“æœ
    """
    try:
        # ä½¿ç”¨gdalinfoè·å–æ–‡ä»¶ä¿¡æ¯
        gdalinfoCmd = ["gdalinfo", sourcePath]
        result = subprocess.run(gdalinfoCmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode != 0:
            return {"success": False, "error": f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {result.stderr}"}
        
        # è§£ææ–‡ä»¶å°ºå¯¸
        import re
        sizeMatch = re.search(r'Size is (\d+), (\d+)', result.stdout)
        if not sizeMatch:
            return {"success": False, "error": "æ— æ³•è§£ææ–‡ä»¶å°ºå¯¸"}
        
        width = int(sizeMatch.group(1))
        height = int(sizeMatch.group(2))
        
        # è®¡ç®—åˆ†å—æ•°é‡
        tilesX = (width + splitTileSize - 1) // splitTileSize
        tilesY = (height + splitTileSize - 1) // splitTileSize
        totalTiles = tilesX * tilesY
        
        # åˆ›å»ºåˆ†å¹…ç›®å½•ï¼ˆåœ¨datasourceç›®å½•ä¸‹ï¼‰
        import tempfile
        splitTempDir = os.path.join(config["dataSourceDir"], f"split_{taskId}_{int(time.time())}")
        os.makedirs(splitTempDir, exist_ok=True)
        
        logMessage(f"å¼€å§‹æ‹†åˆ†æ–‡ä»¶: {width}x{height} -> {tilesX}x{tilesY} = {totalTiles} ä¸ªåˆ†å—")
        
        # ğŸš€ å¹¶è¡Œæ‹†åˆ†æ–‡ä»¶ - å¤§å¹…æå‡é€Ÿåº¦
        splitFiles = []
        
        # å‡†å¤‡æ‰€æœ‰åˆ†å—ä»»åŠ¡ï¼ˆæ·»åŠ é‡å åŒºåŸŸç¡®ä¿è¿ç»­æ€§ï¼‰
        overlap = 50  # é‡å åƒç´ æ•°ï¼Œç¡®ä¿è¾¹ç•Œè¿ç»­
        split_tasks = []
        for y in range(tilesY):
            for x in range(tilesX):
                # è®¡ç®—çª—å£åæ ‡ï¼ˆæ·»åŠ é‡å åŒºåŸŸï¼‰
                xOff = max(0, x * splitTileSize - overlap)
                yOff = max(0, y * splitTileSize - overlap)
                xSize = min(splitTileSize + 2 * overlap, width - xOff)
                ySize = min(splitTileSize + 2 * overlap, height - yOff)
                
                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                outputFileName = f"tile_{x}_{y}.tif"
                outputFilePath = os.path.join(splitTempDir, outputFileName)
                
                split_tasks.append({
                    "x": x, "y": y,
                    "xOff": xOff, "yOff": yOff,
                    "xSize": xSize, "ySize": ySize,
                    "outputPath": outputFilePath,
                    "sourcePath": sourcePath
                })
        
        logMessage(f"ğŸš€ å¯åŠ¨å¹¶è¡Œæ‹†åˆ†: {len(split_tasks)} ä¸ªåˆ†å—, é¢„è®¡æå‡ 4-8å€é€Ÿåº¦")
        
        # ğŸ”¥ ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æ‹†åˆ†ä»»åŠ¡ (Dockerå®¹å™¨å†…æ›´ç¨³å®š)
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import multiprocessing as mp
        
        # è®¡ç®—æœ€ä¼˜çº¿ç¨‹æ•° (æ‹†åˆ†æ˜¯IOå¯†é›†å‹ï¼Œé€‚åˆå¤šçº¿ç¨‹)
        max_workers = min(mp.cpu_count() * 2, 16, len(split_tasks))
        
        def process_split_task(task):
            """å¤„ç†å•ä¸ªæ‹†åˆ†ä»»åŠ¡"""
            try:
                # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨gdal_translateè£å‰ªï¼Œä¿æŒåŸåæ ‡ç³»
                temp_split_file = task["outputPath"].replace(".tif", "_temp.tif")
                
                # è£å‰ªå‘½ä»¤
                translateCmd = [
                    "gdal_translate",
                    "-srcwin", str(task["xOff"]), str(task["yOff"]), 
                              str(task["xSize"]), str(task["ySize"]),
                    "-co", "COMPRESS=LZW",
                    "-co", "TILED=YES",
                    "-co", "BLOCKXSIZE=512",
                    "-co", "BLOCKYSIZE=512",
                    "-co", "NUM_THREADS=1",
                    "-co", "BIGTIFF=IF_SAFER",
                    "-q",
                    task["sourcePath"],
                    temp_split_file
                ]
                
                logMessage(f"å¼€å§‹æ‹†åˆ†åˆ†å— ({task['x']},{task['y']}): {task['xSize']}x{task['ySize']}")
                
                # æ‰§è¡Œè£å‰ª
                result = subprocess.run(translateCmd, capture_output=True, text=True, timeout=600)
                
                if result.returncode != 0:
                    logMessage(f"åˆ†å—è£å‰ªå¤±è´¥ ({task['x']},{task['y']}): {result.stderr}", "ERROR")
                    return {
                        "success": False,
                        "error": f"è£å‰ªå¤±è´¥: {result.stderr}",
                        "x": task["x"], "y": task["y"]
                    }
                
                # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨gdalwarpé‡æŠ•å½±åˆ°WGS84åœ°ç†åæ ‡ç³»ï¼ˆé€‚é…indexedTilesæ¥å£ï¼‰
                warpCmd = [
                    "gdalwarp",
                    "-t_srs", "EPSG:4326",
                    "-r", "near",
                    "-co", "COMPRESS=LZW",
                    "-co", "TILED=YES",
                    "-co", "BLOCKXSIZE=512",
                    "-co", "BLOCKYSIZE=512",
                    "-co", "NUM_THREADS=1",
                    "-co", "BIGTIFF=IF_SAFER",
                    "-q",
                    temp_split_file,
                    task["outputPath"]
                ]
                
                # æ‰§è¡Œé‡æŠ•å½±
                result2 = subprocess.run(warpCmd, capture_output=True, text=True, timeout=600)
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_split_file):
                    os.remove(temp_split_file)
                
                if result2.returncode == 0:
                    return {
                        "success": True,
                        "outputPath": task["outputPath"],
                        "x": task["x"], "y": task["y"]
                    }
                else:
                    logMessage(f"åˆ†å—é‡æŠ•å½±å¤±è´¥ ({task['x']},{task['y']}): {result2.stderr}", "ERROR")
                    return {
                        "success": False,
                        "error": f"é‡æŠ•å½±å¤±è´¥: {result2.stderr}",
                        "x": task["x"], "y": task["y"]
                    }
            except Exception as e:
                logMessage(f"åˆ†å—æ‹†åˆ†å¼‚å¸¸ ({task['x']},{task['y']}): {str(e)}", "ERROR")
                return {
                    "success": False,
                    "error": str(e),
                    "x": task["x"], "y": task["y"]
                }
        
        # æ‰§è¡Œå¹¶è¡Œæ‹†åˆ†
        processedTiles = 0
        failed_tiles = 0
        start_time = time.time()
        
        logMessage(f"å¯åŠ¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œå¹¶è¡Œæ‹†åˆ†...")
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {executor.submit(process_split_task, task): task for task in split_tasks}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_task):
                result = future.result()
                
                if result["success"]:
                    splitFiles.append(result["outputPath"])
                    processedTiles += 1
                else:
                    failed_tiles += 1
                    logMessage(f"åˆ†å—å¤±è´¥ ({result['x']},{result['y']}): {result['error']}", "WARNING")
                
                # å®æ—¶è¿›åº¦å’Œé€Ÿåº¦ç»Ÿè®¡
                if processedTiles % 20 == 0 or processedTiles == len(split_tasks):
                    elapsed = time.time() - start_time
                    speed = processedTiles / elapsed if elapsed > 0 else 0
                    
                    progress_percent = int((processedTiles / len(split_tasks)) * 100)
                    logMessage(f"âš¡ æ‹†åˆ†è¿›åº¦: {processedTiles}/{len(split_tasks)} ({progress_percent}%) "
                             f"| é€Ÿåº¦: {speed:.1f}å—/ç§’ | å¤±è´¥: {failed_tiles}")
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        final_speed = processedTiles / total_time if total_time > 0 else 0
        
        logMessage(f"ğŸ‰ å¹¶è¡Œæ‹†åˆ†å®Œæˆ! æ€»æ—¶é—´: {total_time:.1f}ç§’, "
                  f"å¹³å‡é€Ÿåº¦: {final_speed:.1f}å—/ç§’, æˆåŠŸ: {processedTiles}, å¤±è´¥: {failed_tiles}")
        
        if failed_tiles > 0:
            logMessage(f"âš ï¸  {failed_tiles} ä¸ªåˆ†å—æ‹†åˆ†å¤±è´¥ï¼Œä½†ç»§ç»­å¤„ç†æˆåŠŸçš„åˆ†å—", "WARNING")
        
        return {
            "success": True,
            "splitFiles": splitFiles,
            "splitTempDir": splitTempDir,
            "totalFiles": len(splitFiles),
            "tilesX": tilesX,
            "tilesY": tilesY
        }
        
    except Exception as e:
        return {"success": False, "error": str(e)}

def processIndexedTilesInternal(folderPaths, filePatterns, outputPath, minZoom, maxZoom, tileSize, processes, maxMemory, resampling, generateShpIndex, enableIncrementalUpdate, transparencyThreshold, skipNodataTiles, taskId):
    """
    å†…éƒ¨å¤„ç†ç´¢å¼•ç“¦ç‰‡çš„åŠŸèƒ½ï¼Œç›´æ¥å¤ç”¨createIndexedTilesçš„æ ¸å¿ƒé€»è¾‘
    
    @param folderPaths æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨
    @param filePatterns æ–‡ä»¶æ¨¡å¼åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @param minZoom æœ€å°ç¼©æ”¾çº§åˆ«
    @param maxZoom æœ€å¤§ç¼©æ”¾çº§åˆ«
    @param tileSize ç“¦ç‰‡å¤§å°
    @param processes è¿›ç¨‹æ•°
    @param maxMemory æœ€å¤§å†…å­˜
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param taskId ä»»åŠ¡ID
    @return å¤„ç†ç»“æœ
    """
    try:
        # è·å–TIFæ–‡ä»¶åˆ—è¡¨
        relativeTifFiles = findTifFilesInFolders(folderPaths, filePatterns)
        if not relativeTifFiles:
            return {"success": False, "error": "æœªæ‰¾åˆ°åŒ¹é…çš„TIFæ–‡ä»¶"}
        
        tifFiles = []
        for relativePath in relativeTifFiles:
            fullPath = os.path.join(config["dataSourceDir"], relativePath)
            if os.path.exists(fullPath):
                tifFiles.append(fullPath)
        
        if not tifFiles:
            return {"success": False, "error": "æ‰€æœ‰TIFæ–‡ä»¶è·¯å¾„æ— æ•ˆ"}
        
        # åˆ›å»ºç“¦ç‰‡ç½‘æ ¼ç´¢å¼•
        indexResult = createTileGridIndex(tifFiles, outputPath, minZoom, maxZoom, tileSize)
        
        if not indexResult["success"]:
            return {"success": False, "error": f"ç“¦ç‰‡ç´¢å¼•åˆ›å»ºå¤±è´¥: {indexResult['error']}"}
        
        tileIndex = indexResult["tileIndex"]
        totalTiles = len(tileIndex)
        
        # æ€»æ˜¯ç”ŸæˆGeoJSONç´¢å¼•æ–‡ä»¶ï¼ŒShapefileç´¢å¼•æ˜¯å¯é€‰çš„
        shpResult = generateShapefileIndex(tileIndex, outputPath, generateShpIndex)
        if shpResult["success"]:
            if shpResult.get("reused", False):
                logMessage(f"ğŸ”„ å¤ç”¨ç°æœ‰ç´¢å¼•æ–‡ä»¶")
            else:
                logMessage(f"âœ… ç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ: {shpResult.get('geojsonFile', 'N/A')}")
                if generateShpIndex and shpResult.get('shpFile'):
                    logMessage(f"âœ… SHPç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ: {shpResult['shpFile']}")
            
            if shpResult.get("warning"):
                logMessage(f"âš ï¸ {shpResult['warning']}", "WARNING")
        else:
            logMessage(f"âš ï¸ ç´¢å¼•ç”Ÿæˆå¤±è´¥: {shpResult['error']}", "WARNING")
        
        # ç”Ÿæˆå…ƒæ•°æ®
        metadata = {
            "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "sourceFiles": [os.path.relpath(f, config["dataSourceDir"]) for f in tifFiles],
            "totalSourceFiles": len(tifFiles),
            "zoomLevels": f"{minZoom}-{maxZoom}",
            "tileSize": tileSize,
            "totalTiles": totalTiles,
            "processedTiles": 0,
            "failedTiles": 0,
            "successRate": "0%",
            "tileIndex": tileIndex,
            "method": "å†…éƒ¨æ™ºèƒ½åˆ‡ç‰‡",
            "resampling": resampling,
            "generateShpIndex": generateShpIndex,
            "enableIncrementalUpdate": enableIncrementalUpdate,
            "transparencyThreshold": transparencyThreshold
        }
        
        import json
        metadataFile = os.path.join(outputPath, "tile_metadata.json")
        with open(metadataFile, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        # é«˜æ€§èƒ½å¤„ç†ç“¦ç‰‡
        tile_count = len(tileIndex)
        
        # æ™ºèƒ½è®¡ç®—å·¥ä½œè¿›ç¨‹æ•°
        import psutil
        cpu_count = psutil.cpu_count() or 4
        memory_gb = psutil.virtual_memory().total / (1024**3)
        
        # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„è¿›ç¨‹æ•°
        if processes and processes > 0:
            max_workers = processes
        else:
            if tile_count < 100:
                max_workers = min(4, cpu_count)
            elif tile_count < 1000:
                max_workers = min(cpu_count, 32)
            else:
                max_workers = min(cpu_count * 2, int(memory_gb / 2), 32)
        
        batch_size = calculateOptimalBatchSize(tile_count, max_workers, target_speed=1000)
        
        # è°ƒç”¨é«˜æ€§èƒ½å¤„ç†å‡½æ•°
        hp_result = processHighPerformanceTiles(
            tileIndex, 
            outputPath, 
            resampling, 
            max_workers=max_workers,
            batch_size=batch_size,
            user_processes=processes,
            taskId=taskId  # ä¼ é€’ä»»åŠ¡IDä»¥ä¾¿å®æ—¶æ›´æ–°çŠ¶æ€
        )
        
        if hp_result["success"]:
            processedTiles = hp_result["processed_tiles"]
            failedTiles = hp_result["failed_tiles"]
            
            # æ›´æ–°å…ƒæ•°æ®æ–‡ä»¶
            metadata["processedTiles"] = processedTiles
            metadata["failedTiles"] = failedTiles
            metadata["successRate"] = f"{processedTiles/totalTiles*100:.1f}%" if totalTiles > 0 else "0%"
            metadata["completedAt"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            with open(metadataFile, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            # å¦‚æœå¯ç”¨äº†è·³è¿‡é€æ˜ç“¦ç‰‡ï¼Œåˆ™è‡ªåŠ¨æ¸…ç†é€æ˜ç“¦ç‰‡
            if skipNodataTiles:
                try:
                    logMessage("å¼€å§‹æ¸…ç†é€æ˜ç“¦ç‰‡...")
                    cleanupResult = deleteNodataTilesInternal(
                        os.path.relpath(outputPath, config["tilesDir"]), 
                        includeDetails=False
                    )
                    if cleanupResult.get("success"):
                        deletedCount = cleanupResult.get("deletedTiles", 0)
                        logMessage(f"é€æ˜ç“¦ç‰‡æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deletedCount} ä¸ªé€æ˜ç“¦ç‰‡")
                        metadata["deletedNodataTiles"] = deletedCount
                        metadata["skipNodataTilesEnabled"] = True
                    else:
                        logMessage(f"é€æ˜ç“¦ç‰‡æ¸…ç†å¤±è´¥: {cleanupResult.get('error', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
                except Exception as e:
                    logMessage(f"é€æ˜ç“¦ç‰‡æ¸…ç†å¼‚å¸¸: {e}", "WARNING")
            
            return {
                "success": True,
                "processedTiles": processedTiles,
                "failedTiles": failedTiles,
                "totalTiles": totalTiles
            }
        else:
            return {
                "success": False,
                "error": hp_result.get("error", "ç“¦ç‰‡å¤„ç†å¤±è´¥")
            }
            
    except Exception as e:
        return {"success": False, "error": str(e)}

def createIndexedTiles():
    """
    åˆ›å»ºç´¢å¼•ç“¦ç‰‡ï¼Œæ”¯æŒå¤šæ–‡ä»¶å¤„ç†å’Œç½‘æ ¼ç´¢å¼•
    
    @return åŒ…å«ä»»åŠ¡ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        data = request.get_json()
        
        # åŸºæœ¬å‚æ•°
        folderPaths = data.get('folderPaths', [])
        filePatterns = data.get('filePatterns', [])
        outputPathArray = data.get('outputPath', [])
        minZoom = data.get('minZoom', 0)
        maxZoom = data.get('maxZoom', 12)
        tileSize = data.get('tileSize', 256)
        processes = data.get('processes', 4)
        maxMemory = data.get('maxMemory', '8g')
        resampling = data.get('resampling', 'near')
        generateShpIndex = data.get('generateShpIndex', True)
        enableIncrementalUpdate = data.get('enableIncrementalUpdate', False)

        skipNodataTiles = data.get('skipNodataTiles', False)
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"indexedTiles{timestamp}"
        
        # å‚æ•°éªŒè¯å’Œé”™è¯¯å¤„ç† - å³ä½¿æœ‰é”™è¯¯ä¹Ÿåˆ›å»ºä»»åŠ¡
        errors = []
        
        if not folderPaths:
            errors.append("ç¼ºå°‘å‚æ•°: folderPaths")
        if not outputPathArray:
            errors.append("ç¼ºå°‘å‚æ•°: outputPath")
        
        # è·å–TIFæ–‡ä»¶åˆ—è¡¨
        tifFiles = []
        if not errors:
            relativeTifFiles = findTifFilesInFolders(folderPaths, filePatterns)
            if not relativeTifFiles:
                errors.append("æœªæ‰¾åˆ°åŒ¹é…çš„TIFæ–‡ä»¶")
            else:
                for relativePath in relativeTifFiles:
                    fullPath = os.path.join(config["dataSourceDir"], relativePath)
                    if os.path.exists(fullPath):
                        tifFiles.append(fullPath)
                
                if not tifFiles:
                    errors.append("æ‰€æœ‰TIFæ–‡ä»¶è·¯å¾„æ— æ•ˆ")
        
        # å¦‚æœæœ‰é”™è¯¯ï¼Œåˆ›å»ºå¤±è´¥çŠ¶æ€çš„ä»»åŠ¡
        if errors:
            with taskLock:
                taskStatus[taskId] = {
                    "status": "failed",
                    "progress": 0,
                    "message": f"ç´¢å¼•ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                    "startTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "processLog": [
                        {
                            "stage": "åˆå§‹åŒ–",
                            "status": "failed",
                            "message": f"ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                            "timestamp": datetime.now().isoformat(),
                            "progress": 0,
                            "errors": errors
                        }
                    ],
                    "currentStage": "åˆå§‹åŒ–å¤±è´¥",
                    "stats": {
                        "totalTiles": 0,
                        "processedTiles": 0,
                        "failedTiles": 0,
                        "successRate": "0%"
                    }
                }
            
            logMessage(f"ç´¢å¼•ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {taskId}, é”™è¯¯: {'; '.join(errors)}", "ERROR")
            return jsonify({
                "success": False,
                "taskId": taskId,
                "message": f"ç´¢å¼•ç“¦ç‰‡ä»»åŠ¡åˆ›å»ºå¤±è´¥: {'; '.join(errors)}",
                "statusUrl": f"/api/tasks/{taskId}",
                "errors": errors
            }), 200  # è¿”å›200ï¼Œå› ä¸ºä»»åŠ¡å·²ç»åˆ›å»º
        
        # æ„å»ºè¾“å‡ºè·¯å¾„
        if isinstance(outputPathArray, str):
            outputPath = os.path.join(config["tilesDir"], outputPathArray)
        elif isinstance(outputPathArray, list):
            outputPath = os.path.join(config["tilesDir"], *outputPathArray)
        else:
            outputPath = os.path.join(config["tilesDir"], str(outputPathArray))
        
        os.makedirs(outputPath, exist_ok=True)
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"indexedTiles{timestamp}"
        
        # å¯åŠ¨ç´¢å¼•ç“¦ç‰‡ç”Ÿæˆä»»åŠ¡
        def runIndexedTileTask():
            """
            æ‰§è¡Œç´¢å¼•ç“¦ç‰‡ç”Ÿæˆä»»åŠ¡çš„å†…éƒ¨å‡½æ•°
            å¤„ç†å¤šæ–‡ä»¶è¾¹ç•Œè®¡ç®—ã€ç½‘æ ¼ç´¢å¼•åˆ›å»ºå’Œç“¦ç‰‡ç”Ÿæˆæµç¨‹
            """
            try:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "running",
                        "progress": 0,
                        "message": f"æ­£åœ¨è¿›è¡Œç“¦ç‰‡ç´¢å¼•åˆ†æï¼Œå¤„ç† {len(tifFiles)} ä¸ªæ–‡ä»¶...",
                        "startTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "stats": {
                            "totalTiles": 0,
                            "processedTiles": 0,
                            "failedTiles": 0,
                            "remainingTiles": 0,
                            "currentSpeed": 0,
                            "averageSpeed": 0,
                            "estimatedTimeRemaining": "è®¡ç®—ä¸­...",
                            "estimatedTimeRemainingSeconds": 0,
                            "batchesCompleted": 0,
                            "totalBatches": 0,
                            "successRate": "0%"
                        },
                        "processLog": [
                            {
                                "stage": "åˆå§‹åŒ–",
                                "status": "completed",
                                "message": f"ç´¢å¼•ç“¦ç‰‡ä»»åŠ¡åˆå§‹åŒ–å®Œæˆï¼Œå‡†å¤‡å¤„ç†{len(tifFiles)}ä¸ªæ–‡ä»¶",
                                "timestamp": datetime.now().isoformat(),
                                "progress": 0,
                                "fileCount": len(tifFiles)
                            }
                        ],
                        "currentStage": "ç´¢å¼•åˆ†æ"
                    }
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨å¢é‡æ›´æ–°ï¼ˆå¤ç”¨ç°æœ‰æ–‡ä»¶ï¼‰
                if enableIncrementalUpdate:
                    metadataFile = os.path.join(outputPath, "tile_metadata.json")
                    if os.path.exists(metadataFile):
                        try:
                            import json
                            with open(metadataFile, 'r', encoding='utf-8') as f:
                                existingMetadata = json.load(f)
                            
                            # æ£€æŸ¥é…ç½®æ˜¯å¦åŒ¹é…
                            existingSourceFiles = set(existingMetadata.get("sourceFiles", []))
                            currentSourceFiles = set([os.path.relpath(f, config["dataSourceDir"]) for f in tifFiles])
                            existingZoomLevels = existingMetadata.get("zoomLevels", "")
                            currentZoomLevels = f"{minZoom}-{maxZoom}"
                            existingTileSize = existingMetadata.get("tileSize", 0)
                            existingResampling = existingMetadata.get("resampling", "near")
                            if (existingSourceFiles == currentSourceFiles and 
                                existingZoomLevels == currentZoomLevels and 
                                existingTileSize == tileSize and
                                existingResampling == resampling):
                                
                                # éªŒè¯ç“¦ç‰‡æ–‡ä»¶å®Œæ•´æ€§
                                if verifyTilesIntegrity(outputPath, existingMetadata):
                                    logMessage(f"ğŸ”„ æ£€æµ‹åˆ°ç›¸åŒé…ç½®çš„ç°æœ‰ç“¦ç‰‡ä¸”æ–‡ä»¶å®Œæ•´ï¼Œå¯ç”¨å¢é‡æ›´æ–°æ¨¡å¼")
                                    
                                    # å¤ç”¨ç°æœ‰ç»“æœ
                                    processedTiles = existingMetadata.get("processedTiles", 0)
                                    failedTiles = existingMetadata.get("failedTiles", 0)
                                    totalTiles = existingMetadata.get("totalTiles", 0)
                                    
                                    with taskLock:
                                        taskStatus[taskId] = {
                                            "status": "completed",
                                            "progress": 100,
                                            "message": f"å¤ç”¨ç°æœ‰ç“¦ç‰‡å®Œæˆï¼{processedTiles}/{totalTiles} ä¸ªç“¦ç‰‡",
                                            "result": {
                                                "outputPath": outputPath,
                                                "outputPathArray": outputPathArray,
                                                "metadataFile": metadataFile,
                                                "sourceFiles": [os.path.relpath(f, config["dataSourceDir"]) for f in tifFiles],
                                                "totalSourceFiles": len(tifFiles),
                                                "totalTiles": totalTiles,
                                                "processedTiles": processedTiles,
                                                "failedTiles": failedTiles,
                                                "successRate": f"{processedTiles/totalTiles*100:.1f}%" if totalTiles > 0 else "0%",
                                                "zoomLevels": f"{minZoom}-{maxZoom}",
                                                "tileSize": tileSize,
                                                "method": "ç“¦ç‰‡ç´¢å¼•ç²¾ç¡®åˆ‡ç‰‡ï¼ˆå¤ç”¨ç°æœ‰ï¼‰"
                                            },
                                            "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                                        }
                                    
                                    logMessage(f"âœ… ç“¦ç‰‡å¤ç”¨ä»»åŠ¡å®Œæˆ: {taskId}")
                                    return
                                else:
                                    logMessage(f"âš ï¸ ç“¦ç‰‡æ–‡ä»¶ä¸å®Œæ•´æˆ–æŸåï¼Œå°†é‡æ–°ç”Ÿæˆ")
                            else:
                                logMessage(f"âš ï¸ ç°æœ‰é…ç½®ä¸å½“å‰ä¸åŒ¹é…ï¼Œå°†é‡æ–°ç”Ÿæˆç“¦ç‰‡")
                        except Exception as e:
                            logMessage(f"âš ï¸ è¯»å–ç°æœ‰å…ƒæ•°æ®å¤±è´¥ï¼Œå°†é‡æ–°ç”Ÿæˆç“¦ç‰‡: {e}", "WARNING")
                    else:
                        logMessage(f"â„¹ï¸ æœªæ‰¾åˆ°ç°æœ‰å…ƒæ•°æ®æ–‡ä»¶ï¼Œå°†ç”Ÿæˆæ–°ç“¦ç‰‡")
                
                # åˆ›å»ºç“¦ç‰‡ç½‘æ ¼ç´¢å¼•
                # è®¡ç®—æ‰€æœ‰æ–‡ä»¶çš„æ€»ä½“åœ°ç†è¾¹ç•Œ
                totalBounds = None
                for filePath in tifFiles:
                    fileBounds = getFileGeographicBounds(filePath)
                    if fileBounds and all(key in fileBounds for key in ['west', 'east', 'north', 'south']):
                        # è½¬æ¢å­—å…¸æ ¼å¼ä¸ºåˆ—è¡¨æ ¼å¼ [west, south, east, north]
                        boundsArray = [
                            fileBounds['west'], 
                            fileBounds['south'], 
                            fileBounds['east'], 
                            fileBounds['north']
                        ]
                        
                        if totalBounds is None:
                            totalBounds = boundsArray
                        else:
                            totalBounds = [
                                min(totalBounds[0], boundsArray[0]),  # west
                                min(totalBounds[1], boundsArray[1]),  # south
                                max(totalBounds[2], boundsArray[2]),  # east
                                max(totalBounds[3], boundsArray[3])   # north
                            ]
                
                if totalBounds is None:
                    raise Exception("æ— æ³•è·å–æ–‡ä»¶åœ°ç†è¾¹ç•Œ")
                
                indexResult = createTileGridIndex(tifFiles, outputPath, minZoom, maxZoom, tileSize)
                
                if not indexResult["success"]:
                    raise Exception(f"ç“¦ç‰‡ç´¢å¼•åˆ›å»ºå¤±è´¥: {indexResult['error']}")
                
                tileIndex = indexResult["tileIndex"]
                totalTiles = len(tileIndex)
                
                with taskLock:
                    taskStatus[taskId]["progress"] = 10
                    taskStatus[taskId]["message"] = f"ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå¼€å§‹ç”Ÿæˆshapefileç´¢å¼•"
                    taskStatus[taskId]["currentStage"] = "ç´¢å¼•æ–‡ä»¶ç”Ÿæˆ"
                    taskStatus[taskId]["processLog"].append({
                        "stage": "ç´¢å¼•åˆ†æ",
                        "status": "completed",
                        "message": f"ç“¦ç‰‡ç´¢å¼•åˆ›å»ºå®Œæˆï¼Œå…±è®¡ç®—å‡º{totalTiles}ä¸ªç“¦ç‰‡éœ€è¦ç”Ÿæˆ",
                        "timestamp": datetime.now().isoformat(),
                        "progress": 10,
                        "tileCount": totalTiles,
                        "bounds": totalBounds
                    })
                
                # æ­¥éª¤2ï¼šç«‹å³ç”Ÿæˆç“¦ç‰‡ç´¢å¼•æ–‡ä»¶ï¼ˆshapefileå’Œå…ƒæ•°æ®jsonï¼‰
                logMessage(f"ğŸ’¾ æ­¥éª¤2ï¼šç”Ÿæˆç“¦ç‰‡ç´¢å¼•æ–‡ä»¶")
                
                # ç”Ÿæˆå…ƒæ•°æ®jsonï¼ˆè®°å½•ç“¦ç‰‡è®¡åˆ’ï¼‰
                metadata = {
                    "generatedAt": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "sourceFiles": [os.path.relpath(f, config["dataSourceDir"]) for f in tifFiles],
                    "totalSourceFiles": len(tifFiles),
                    "zoomLevels": f"{minZoom}-{maxZoom}",
                    "tileSize": tileSize,
                    "totalTiles": totalTiles,
                    "processedTiles": 0,  # åˆå§‹ä¸º0ï¼Œç“¦ç‰‡å¤„ç†æ—¶ä¼šæ›´æ–°
                    "failedTiles": 0,
                    "successRate": "0%",
                    "tileIndex": tileIndex,
                    "method": "ç“¦ç‰‡ç´¢å¼•ç²¾ç¡®åˆ‡ç‰‡",
                    "resampling": resampling,

                }
                
                import json
                metadataFile = os.path.join(outputPath, "tile_metadata.json")
                with open(metadataFile, 'w', encoding='utf-8') as f:
                    json.dump(metadata, f, indent=2, ensure_ascii=False)
                
                logMessage(f"âœ… ç“¦ç‰‡å…ƒæ•°æ®å·²ç”Ÿæˆ: {metadataFile}")
                
                # ç”Ÿæˆshapefileç´¢å¼•
                if generateShpIndex:
                    shpResult = generateShapefileIndex(tileIndex, outputPath)
                    if shpResult["success"]:
                        if shpResult.get("reused", False):
                            logMessage(f"ğŸ”„ å¤ç”¨ç°æœ‰SHPç´¢å¼•æ–‡ä»¶: {shpResult['shpFile']}")
                        else:
                            logMessage(f"âœ… SHPç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆ: {shpResult['shpFile']}")
                        
                        if shpResult.get("warning"):
                            logMessage(f"âš ï¸ {shpResult['warning']}", "WARNING")
                    else:
                        logMessage(f"âš ï¸ SHPç´¢å¼•ç”Ÿæˆå¤±è´¥: {shpResult['error']}", "WARNING")
                
                with taskLock:
                    taskStatus[taskId]["progress"] = 15
                    taskStatus[taskId]["message"] = f"ç´¢å¼•æ–‡ä»¶å·²ç”Ÿæˆï¼Œå¼€å§‹å¤„ç† {totalTiles} ä¸ªç“¦ç‰‡"
                    taskStatus[taskId]["stats"]["totalTiles"] = totalTiles
                    taskStatus[taskId]["stats"]["remainingTiles"] = totalTiles
                
                # æ­¥éª¤3ï¼šé«˜æ€§èƒ½å¹¶è¡Œå¤„ç†ç“¦ç‰‡
                logMessage(f"ğŸš€ æ­¥éª¤3ï¼šå¯åŠ¨é«˜æ€§èƒ½ç“¦ç‰‡å¤„ç†ï¼ˆç›®æ ‡1000ç“¦ç‰‡/ç§’ï¼‰")
                
                # æ™ºèƒ½è®¡ç®—æœ€ä¼˜å‚æ•°
                tile_count = len(tileIndex)
                
                # æ™ºèƒ½è®¡ç®—å·¥ä½œè¿›ç¨‹æ•°
                import psutil
                cpu_count = psutil.cpu_count() or 4
                memory_gb = psutil.virtual_memory().total / (1024**3)
                
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„è¿›ç¨‹æ•°
                if processes and processes > 0:
                    # ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†è¿›ç¨‹æ•°ï¼Œä¼˜å…ˆä½¿ç”¨
                    max_workers = processes
                    logMessage(f"ğŸ¯ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„è¿›ç¨‹æ•°: {max_workers} (ç”¨æˆ·è¾“å…¥: {processes})")
                else:
                    # ç”¨æˆ·æœªæŒ‡å®šï¼Œä½¿ç”¨ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—
                    if tile_count < 100:
                        max_workers = min(4, cpu_count)
                    elif tile_count < 1000:
                        max_workers = min(cpu_count, 32)
                    else:
                        # å¤§é‡ç“¦ç‰‡æ—¶çš„è‡ªåŠ¨é™åˆ¶
                        max_workers = min(cpu_count * 2, int(memory_gb / 2), 32)
                    logMessage(f"ğŸ¤– ç³»ç»Ÿè‡ªåŠ¨è®¡ç®—è¿›ç¨‹æ•°: {max_workers} (ç“¦ç‰‡:{tile_count}, CPU:{cpu_count}æ ¸, å†…å­˜:{memory_gb:.1f}GB)")
                
                # ä½¿ç”¨æ™ºèƒ½æ‰¹é‡å¤§å°è®¡ç®—
                batch_size = calculateOptimalBatchSize(tile_count, max_workers, target_speed=1000)
                
                logMessage(f"ğŸ§  æœ€ç»ˆå‚æ•°: {tile_count}ç“¦ç‰‡, {max_workers}è¿›ç¨‹, æ‰¹é‡{batch_size}")
                
                with taskLock:
                    taskStatus[taskId]["progress"] = 15
                    taskStatus[taskId]["message"] = f"å¯åŠ¨é«˜æ€§èƒ½å¤„ç†: {max_workers}è¿›ç¨‹, æ‰¹é‡{batch_size}"
                
                # è°ƒç”¨é«˜æ€§èƒ½å¤„ç†å‡½æ•°ï¼Œä¼ é€’ç”¨æˆ·åŸå§‹è¿›ç¨‹æ•°
                hp_result = processHighPerformanceTiles(
                    tileIndex, 
                    outputPath, 
                    resampling, 
                    max_workers=max_workers,
                    batch_size=batch_size,
                    user_processes=processes,  # ä¼ é€’ç”¨æˆ·åŸå§‹è¾“å…¥
                    taskId=taskId  # ä¼ é€’ä»»åŠ¡IDä»¥ä¾¿å®æ—¶æ›´æ–°çŠ¶æ€
                )
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨æè‡´ä¼˜åŒ–æ¨¡å¼
                # è§£æç”¨æˆ·å†…å­˜å‚æ•°
                user_memory_gb = None
                if maxMemory:
                    try:
                        if isinstance(maxMemory, str):
                            if maxMemory.lower().endswith('g'):
                                user_memory_gb = float(maxMemory[:-1])
                            else:
                                user_memory_gb = float(maxMemory)
                        else:
                            user_memory_gb = float(maxMemory)
                    except:
                        user_memory_gb = None
                
                # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å†…å­˜ï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿå†…å­˜
                effective_memory_gb = user_memory_gb if user_memory_gb is not None else memory_gb
                
                if tile_count > 5000 and effective_memory_gb > 64 and cpu_count >= 16:
                    logMessage("ğŸš€ æ£€æµ‹åˆ°å¤§è§„æ¨¡ä»»åŠ¡ + é«˜é…ç½®ç¡¬ä»¶ï¼Œå¯ç”¨æè‡´ä¼˜åŒ–æ¨¡å¼")
                    
                    with taskLock:
                        taskStatus[taskId]["message"] = "å¯ç”¨æè‡´ä¼˜åŒ–æ¨¡å¼ - ç›®æ ‡1000ç“¦ç‰‡/ç§’"
                    
                    # ä½¿ç”¨æè‡´ä¼˜åŒ–å¤„ç†
                    ultra_result = processUltraHighPerformanceTiles(
                        tileIndex,
                        outputPath,
                        resampling,
                        max_workers=max_workers,
                        enable_memory_cache=True,
                        enable_async_io=True,
                        user_processes=processes,  # ä¼ é€’ç”¨æˆ·åŸå§‹è¾“å…¥
                        user_memory_gb=user_memory_gb  # ä¼ é€’ç”¨æˆ·å†…å­˜å‚æ•°
                    )
                    
                    logMessage(f"ğŸ‰ æè‡´ä¼˜åŒ–å®Œæˆ! æœ€ç»ˆé€Ÿåº¦: {ultra_result.get('final_speed', 0):.1f}ç“¦ç‰‡/ç§’")
                    logMessage(f"ğŸš€ æ€§èƒ½æå‡: {ultra_result.get('improvement_factor', 1):.1f}å€")
                    
                    result = ultra_result
                else:
                    # ä½¿ç”¨æ ‡å‡†é«˜æ€§èƒ½å¤„ç†
                    result = hp_result
                
                if result["success"]:
                    processedTiles = result["processed_tiles"]
                    failedTiles = result["failed_tiles"]
                    average_speed = result["average_speed"]
                    
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«åœæ­¢
                    with taskLock:
                        current_status = taskStatus.get(taskId, {}).get("status", "running")
                    
                    if current_status == "stopped":
                        # ä»»åŠ¡è¢«åœæ­¢ï¼Œè®¾ç½®æ­£ç¡®çš„çŠ¶æ€
                        with taskLock:
                            taskStatus[taskId]["progress"] = int((processedTiles / totalTiles) * 100) if totalTiles > 0 else 0
                            taskStatus[taskId]["message"] = f"ä»»åŠ¡å·²åœæ­¢ - å·²å¤„ç† {processedTiles}/{totalTiles} ä¸ªç“¦ç‰‡"
                            taskStatus[taskId]["endTime"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            taskStatus[taskId]["stats"]["processedTiles"] = processedTiles
                            taskStatus[taskId]["stats"]["failedTiles"] = failedTiles
                            taskStatus[taskId]["stats"]["remainingTiles"] = totalTiles - processedTiles
                        
                        logMessage(f"âœ… ä»»åŠ¡åœæ­¢å®Œæˆ: {taskId} - å·²å¤„ç† {processedTiles}/{totalTiles} ä¸ªç“¦ç‰‡")
                        return  # ç›´æ¥è¿”å›ï¼Œä¸è¿›å…¥åç»­å¤„ç†
                    
                    logMessage(f"âœ… é«˜æ€§èƒ½å¤„ç†å®Œæˆ! å¹³å‡é€Ÿåº¦: {average_speed:.1f}ç“¦ç‰‡/ç§’")
                    
                    with taskLock:
                        taskStatus[taskId]["progress"] = 90
                        taskStatus[taskId]["message"] = f"é«˜æ€§èƒ½å¤„ç†å®Œæˆ: {processedTiles}æˆåŠŸ, {failedTiles}å¤±è´¥, é€Ÿåº¦{average_speed:.1f}/ç§’"
                        # è®°å½•æ€§èƒ½ç»Ÿè®¡
                        performance_stats = result.get("stats", {})
                        performance_stats.update({
                            "method": "é«˜æ€§èƒ½å¹¶è¡Œå¤„ç†",
                            "target_speed": 1000,
                            "actual_speed": average_speed,
                            "efficiency": min(average_speed / 1000 * 100, 100),  # æ•ˆç‡ç™¾åˆ†æ¯”
                            "max_workers": max_workers,
                            "batch_size": batch_size,
                            "batches_processed": result.get("batches_processed", 0),
                            "total_time": result.get("total_time", 0)
                        })
                        taskStatus[taskId]["performance_stats"] = performance_stats
                else:
                    processedTiles = result.get("processed_tiles", 0)
                    failedTiles = result.get("failed_tiles", 0)
                    error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                    
                    logMessage(f"âŒ é«˜æ€§èƒ½å¤„ç†å¤±è´¥: {error_msg}", "ERROR")
                    
                    # å¦‚æœé«˜æ€§èƒ½å¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ–¹æ³•
                    logMessage(f"ğŸ”„ å›é€€åˆ°ä¼ ç»Ÿå•ç“¦ç‰‡å¤„ç†æ–¹æ³•")
                    
                    remaining_tiles = [tile for i, tile in enumerate(tileIndex) if i >= processedTiles]
                    
                    for tileInfo in remaining_tiles:
                        try:
                            result = processSingleTileFromIndex(tileInfo, outputPath, resampling)
                            
                            if result["success"]:
                                processedTiles += 1
                            else:
                                failedTiles += 1
                                logMessage(f"ç“¦ç‰‡å¤„ç†å¤±è´¥ {tileInfo['z']}/{tileInfo['x']}/{tileInfo['y']}: {result.get('error')}", "WARNING")
                            
                            # æ›´æ–°è¿›åº¦
                            progress = 15 + int((processedTiles + failedTiles) / totalTiles * 75)
                            with taskLock:
                                taskStatus[taskId]["progress"] = progress
                                taskStatus[taskId]["message"] = f"å›é€€å¤„ç† {processedTiles + failedTiles}/{totalTiles} ä¸ªç“¦ç‰‡"
                        
                        except Exception as e:
                            failedTiles += 1
                            logMessage(f"ç“¦ç‰‡å¤„ç†å¼‚å¸¸: {e}", "ERROR")
                
                # æ­¥éª¤4ï¼šæ›´æ–°å…ƒæ•°æ®æ–‡ä»¶ä¸­çš„å¤„ç†ç»“æœ
                logMessage(f"ğŸ’¾ æ­¥éª¤4ï¼šæ›´æ–°ç“¦ç‰‡å¤„ç†ç»“æœ")
                
                # è¯»å–å·²æœ‰çš„å…ƒæ•°æ®æ–‡ä»¶å¹¶æ›´æ–°å¤„ç†ç»“æœ
                try:
                    import json
                    metadataFile = os.path.join(outputPath, "tile_metadata.json")
                    with open(metadataFile, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                    
                    # æ›´æ–°å¤„ç†ç»“æœ
                    metadata["processedTiles"] = processedTiles
                    metadata["failedTiles"] = failedTiles
                    metadata["successRate"] = f"{processedTiles/totalTiles*100:.1f}%" if totalTiles > 0 else "0%"
                    metadata["completedAt"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    
                    # å†™å›æ–‡ä»¶
                    with open(metadataFile, 'w', encoding='utf-8') as f:
                        json.dump(metadata, f, indent=2, ensure_ascii=False)
                    
                    logMessage(f"âœ… ç“¦ç‰‡å…ƒæ•°æ®å·²æ›´æ–°: æˆåŠŸ{processedTiles}, å¤±è´¥{failedTiles}")
                except Exception as e:
                    logMessage(f"âš ï¸ æ›´æ–°å…ƒæ•°æ®å¤±è´¥: {e}", "WARNING")
                
                # å¦‚æœå¯ç”¨äº†skipNodataTilesï¼Œåœ¨åˆ‡å›¾å®Œæˆååˆ é™¤é€æ˜ç“¦ç‰‡
                deletedNodataTiles = 0
                if skipNodataTiles and processedTiles > 0:
                    try:
                        logMessage(f"ğŸ§¹ å¼€å§‹åˆ é™¤é€æ˜ç“¦ç‰‡ï¼ˆskipNodataTiles=Trueï¼‰...")
                        
                        # æ„å»ºç›¸å¯¹è·¯å¾„
                        if isinstance(outputPathArray, str):
                            relativeOutputPath = outputPathArray
                        elif isinstance(outputPathArray, list):
                            relativeOutputPath = "/".join(outputPathArray)
                        else:
                            relativeOutputPath = str(outputPathArray)
                        
                        # è°ƒç”¨å†…éƒ¨åˆ é™¤å‡½æ•°ï¼Œç›´æ¥ä¼ é€’ç›¸å¯¹è·¯å¾„
                        deleteResult = deleteNodataTilesInternal(relativeOutputPath, False)
                        
                        if deleteResult.get("success", False):
                            deletedNodataTiles = deleteResult.get("deleted_count", 0)
                            logMessage(f"âœ… é€æ˜ç“¦ç‰‡åˆ é™¤å®Œæˆ: åˆ é™¤äº† {deletedNodataTiles} ä¸ªé€æ˜ç“¦ç‰‡")
                        else:
                            logMessage(f"âš ï¸ é€æ˜ç“¦ç‰‡åˆ é™¤å¤±è´¥: {deleteResult.get('error', 'æœªçŸ¥é”™è¯¯')}", "WARNING")
                    except Exception as e:
                        logMessage(f"âš ï¸ åˆ é™¤é€æ˜ç“¦ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {e}", "WARNING")
                
                # ä»»åŠ¡å®Œæˆ
                if processedTiles > 0:
                    with taskLock:
                        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
                        total_processing_time = (datetime.now() - datetime.strptime(taskStatus[taskId]["startTime"], "%Y-%m-%d %H:%M:%S")).total_seconds()
                        final_speed = processedTiles / total_processing_time if total_processing_time > 0 else 0
                        
                        taskStatus[taskId] = {
                            "status": "completed",
                            "progress": 100,
                            "message": f"ç“¦ç‰‡ç´¢å¼•åˆ‡ç‰‡å®Œæˆï¼æˆåŠŸå¤„ç† {processedTiles}/{totalTiles} ä¸ªç“¦ç‰‡" + (f"ï¼Œåˆ é™¤äº† {deletedNodataTiles} ä¸ªé€æ˜ç“¦ç‰‡" if deletedNodataTiles > 0 else ""),
                            "result": {
                                "outputPath": outputPath,
                                "outputPathArray": outputPathArray,
                                "metadataFile": metadataFile,
                                "sourceFiles": [os.path.relpath(f, config["dataSourceDir"]) for f in tifFiles],
                                "totalSourceFiles": len(tifFiles),
                                "totalTiles": totalTiles,
                                "processedTiles": processedTiles,
                                "failedTiles": failedTiles,
                                "deletedNodataTiles": deletedNodataTiles,
                                "skipNodataTiles": skipNodataTiles,
                                "successRate": f"{processedTiles/totalTiles*100:.1f}%",
                                "zoomLevels": f"{minZoom}-{maxZoom}",
                                "tileSize": tileSize,
                                "method": "ç“¦ç‰‡ç´¢å¼•ç²¾ç¡®åˆ‡ç‰‡"
                            },
                            "stats": {
                                "totalTiles": totalTiles,
                                "processedTiles": processedTiles,
                                "failedTiles": failedTiles,
                                "deletedNodataTiles": deletedNodataTiles,
                                "remainingTiles": 0,
                                "averageSpeed": round(final_speed, 1),
                                "totalProcessingTime": f"{total_processing_time:.1f}ç§’",
                                "successRate": f"{processedTiles/totalTiles*100:.1f}%" if totalTiles > 0 else "0%",
                                "estimatedTimeRemaining": "å·²å®Œæˆ",
                                "estimatedTimeRemainingSeconds": 0
                            },
                            "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                    
                    logMessage(f"âœ… ç“¦ç‰‡ç´¢å¼•åˆ‡ç‰‡ä»»åŠ¡å®Œæˆ: {taskId}")
                else:
                    raise Exception("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ç“¦ç‰‡")
            
            except Exception as e:
                with taskLock:
                    taskStatus[taskId] = {
                        "status": "failed",
                        "progress": 0,
                        "message": f"ç“¦ç‰‡ç´¢å¼•åˆ‡ç‰‡å¤±è´¥: {str(e)}",
                        "error": str(e),
                        "endTime": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                
                logMessage(f"âŒ ç“¦ç‰‡ç´¢å¼•åˆ‡ç‰‡å¤±è´¥: {taskId} - {e}", "ERROR")
        
        # å¯åŠ¨åå°ä»»åŠ¡
        import threading
        taskThread = threading.Thread(target=runIndexedTileTask)
        taskThread.daemon = True
        
        # ä¿å­˜çº¿ç¨‹å¯¹è±¡åˆ°taskProcessesä»¥ä¾¿åœæ­¢
        with taskLock:
            taskProcesses[taskId] = taskThread
        
        taskThread.start()
        
        return jsonify({
            "taskId": taskId,
            "message": f"ç“¦ç‰‡ç´¢å¼•åˆ‡ç‰‡ä»»åŠ¡å·²å¯åŠ¨ï¼Œå°†å¤„ç† {len(tifFiles)} ä¸ªæ–‡ä»¶",
            "statusUrl": f"/api/tasks/{taskId}",
            "method": "ç“¦ç‰‡ç´¢å¼•ç²¾ç¡®åˆ‡ç‰‡",
            "indexInfo": {
                "totalFiles": len(tifFiles),
                "zoomLevels": f"{minZoom}-{maxZoom}",
                "tileSize": tileSize,
                "generateShpIndex": generateShpIndex,
                "enableIncrementalUpdate": enableIncrementalUpdate,
                "skipNodataTiles": skipNodataTiles
            },
            "processingInfo": {
                "processes": processes,
                "maxMemory": maxMemory,
                "resampling": resampling,
                "outputPathArray": outputPathArray
            }
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def getTaskStatus(taskId):
    """
    è·å–ä»»åŠ¡çŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…æ‹¬è¿›åº¦å’Œç»“æœ
    
    @param taskId ä»»åŠ¡ID
    @return åŒ…å«ä»»åŠ¡çŠ¶æ€çš„JSONå“åº”
    """
    try:
        logMessage(f"æ”¶åˆ°ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢è¯·æ±‚: {taskId}", "INFO")
        with taskLock:
            if taskId in taskStatus:
                taskInfo = dict(taskStatus[taskId])
                taskInfo["taskId"] = taskId
                logMessage(f"ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢æˆåŠŸ: {taskId}, çŠ¶æ€: {taskInfo.get('status', 'unknown')}", "INFO")
                return jsonify(taskInfo)
            else:
                logMessage(f"ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å¤±è´¥: ä»»åŠ¡ä¸å­˜åœ¨ {taskId}", "WARNING")
                return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logMessage(f"ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å¼‚å¸¸: {taskId}, é”™è¯¯: {str(e)}", "ERROR")
        return jsonify({"error": str(e)}), 500

def listTasks():
    """
    åˆ—å‡ºæ‰€æœ‰ä»»åŠ¡ï¼Œæ”¯æŒçŠ¶æ€ç­›é€‰å’Œåˆ†é¡µï¼Œé™åˆ¶è¿”å›æœ€è¿‘50æ¡
    
    @return åŒ…å«ä»»åŠ¡åˆ—è¡¨çš„JSONå“åº”
    """
    with taskLock:
        # æŒ‰ä»»åŠ¡IDä¸­çš„æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€è¿‘çš„50æ¡ä»»åŠ¡
        def extractTimestamp(taskId):
            try:
                # ä»»åŠ¡IDæ ¼å¼é€šå¸¸æ˜¯: taskType + timestamp
                import re
                match = re.search(r'\d+$', taskId)
                return int(match.group()) if match else 0
            except:
                return 0
        
        # æ’åºå¹¶é™åˆ¶ä¸ºæœ€è¿‘50æ¡
        sortedTaskIds = sorted(taskStatus.keys(), 
                              key=extractTimestamp, 
                              reverse=True)[:50]
        
        tasksWithIds = {}
        for taskId in sortedTaskIds:
            if taskId in taskStatus:
                taskInfo = taskStatus[taskId]
                # åˆ›å»ºç²¾ç®€ç‰ˆä»»åŠ¡ä¿¡æ¯ï¼Œç§»é™¤processLogå’Œå¤§å‹resultå‡å°‘æ•°æ®é‡
                result = taskInfo.get("result")
                simplifiedResult = None
                if result and isinstance(result, dict):
                    # åªä¿ç•™åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ï¼Œç§»é™¤è¯¦ç»†åˆ—è¡¨
                    simplifiedResult = {
                        "completedFiles": result.get("completedFiles", 0),
                        "failedFiles": result.get("failedFiles", 0),
                        "totalFiles": result.get("totalFiles", 0),
                        "totalTerrainFiles": result.get("totalTerrainFiles", 0),
                        "outputPath": result.get("outputPath"),
                        "mergedOutputPath": result.get("mergedOutputPath")
                        # ä¸åŒ…å«completedDetailsã€failedDetailsç­‰å¤§å‹æ•°ç»„
                    }
                
                taskInfoWithId = {
                    "taskId": taskId,
                    "status": taskInfo.get("status"),
                    "progress": taskInfo.get("progress"),
                    "message": taskInfo.get("message"),
                    "startTime": taskInfo.get("startTime"),
                    "endTime": taskInfo.get("endTime"),
                    "currentStage": taskInfo.get("currentStage"),
                    "result": simplifiedResult,
                    "stats": taskInfo.get("stats"),
                    "files": taskInfo.get("files")
                    # æ•…æ„ä¸åŒ…å«processLogï¼Œå‡å°‘æ•°æ®ä¼ è¾“é‡
                }
                tasksWithIds[taskId] = taskInfoWithId
        
        return jsonify({
            "tasks": tasksWithIds,
            "count": len(tasksWithIds)  # è¿”å›å®é™…è¿”å›çš„ä»»åŠ¡æ•°é‡
        })

def cleanupTasks():
    """
    æ¸…ç†å·²å®Œæˆå’Œå¤±è´¥çš„ä»»åŠ¡ï¼Œé‡Šæ”¾ç³»ç»Ÿèµ„æº
    
    @return åŒ…å«æ¸…ç†ç»“æœçš„JSONå“åº”
    """
    try:
        cleanupTasksByCount()
        
        with taskLock:
            return jsonify({
                "success": True,
                "message": "ä»»åŠ¡æ¸…ç†å®Œæˆ",
                "remainingTasks": len(taskStatus)
            })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def stopTask(taskId):
    """
    åœæ­¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
    
    @param taskId ä»»åŠ¡ID
    @return åŒ…å«æ“ä½œç»“æœçš„JSONå“åº”
    """
    try:
        logMessage(f"æ”¶åˆ°åœæ­¢ä»»åŠ¡è¯·æ±‚: {taskId}", "INFO")
        success = stopTaskProcess(taskId)
        
        if success:
            with taskLock:
                if taskId in taskStatus:
                    taskStatus[taskId]["status"] = "stopped"
                    taskStatus[taskId]["message"] = "ä»»åŠ¡å·²åœæ­¢"
                    taskStatus[taskId]["endTime"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            logMessage(f"ä»»åŠ¡åœæ­¢æˆåŠŸ: {taskId}", "INFO")
            return jsonify({
                "success": True,
                "message": "ä»»åŠ¡å·²åœæ­¢",
                "taskId": taskId
            })
        else:
            logMessage(f"ä»»åŠ¡åœæ­¢å¤±è´¥: ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æ³•åœæ­¢ {taskId}", "WARNING")
            return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ— æ³•åœæ­¢"}), 404
    except Exception as e:
        logMessage(f"åœæ­¢ä»»åŠ¡å¼‚å¸¸: {taskId}, é”™è¯¯: {str(e)}", "ERROR")
        return jsonify({"error": str(e)}), 500

def deleteTask(taskId):
    """
    åˆ é™¤æŒ‡å®šä»»åŠ¡å’Œç›¸å…³æ•°æ®
    
    @param taskId ä»»åŠ¡ID
    @return åŒ…å«æ“ä½œç»“æœçš„JSONå“åº”
    """
    try:
        logMessage(f"æ”¶åˆ°åˆ é™¤ä»»åŠ¡è¯·æ±‚: {taskId}", "INFO")
        with taskLock:
            if taskId in taskStatus:
                # å¯¹äºæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ï¼Œå…ˆæ ‡è®°ä¸ºåœæ­¢çŠ¶æ€
                if taskStatus[taskId].get("status") == "running":
                    taskStopFlags[taskId] = True
                    logMessage(f"æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ {taskId} å·²æ ‡è®°ä¸ºåœæ­¢", "INFO")
                
                # å°è¯•éé˜»å¡æ–¹å¼åœæ­¢è¿›ç¨‹
                try:
                    if taskId in taskProcesses:
                        process_or_thread = taskProcesses[taskId]
                        if hasattr(process_or_thread, 'terminate'):
                            process_or_thread.terminate()
                        del taskProcesses[taskId]
                        logMessage(f"ä»»åŠ¡è¿›ç¨‹å·²ç»ˆæ­¢: {taskId}", "INFO")
                except Exception as e:
                    logMessage(f"ç»ˆæ­¢ä»»åŠ¡è¿›ç¨‹æ—¶å‡ºé”™: {taskId}, é”™è¯¯: {str(e)}", "WARNING")
                
                # åˆ é™¤ä»»åŠ¡çŠ¶æ€
                del taskStatus[taskId]
                logMessage(f"ä»»åŠ¡åˆ é™¤æˆåŠŸ: {taskId}", "INFO")
                
                return jsonify({
                    "success": True,
                    "message": "ä»»åŠ¡å·²åˆ é™¤",
                    "taskId": taskId
                })
            else:
                logMessage(f"åˆ é™¤ä»»åŠ¡å¤±è´¥: ä»»åŠ¡ä¸å­˜åœ¨ {taskId}", "WARNING")
                return jsonify({"error": "ä»»åŠ¡ä¸å­˜åœ¨"}), 404
    except Exception as e:
        logMessage(f"åˆ é™¤ä»»åŠ¡å¼‚å¸¸: {taskId}, é”™è¯¯: {str(e)}", "ERROR")
        return jsonify({"error": str(e)}), 500

def getCacheInfo():
    """
    è·å–ç“¦ç‰‡ç¼“å­˜ä¿¡æ¯
    
    @return åŒ…å«ç¼“å­˜çŠ¶æ€çš„JSONå“åº”
    """
    try:
        tilesDir = config["tilesDir"]
        cache_info = []
        
        if not os.path.exists(tilesDir):
            return jsonify({"cacheDirectories": [], "totalDirectories": 0})
        
        # éå†ç“¦ç‰‡è¾“å‡ºç›®å½•
        for item in os.listdir(tilesDir):
            itemPath = os.path.join(tilesDir, item)
            if os.path.isdir(itemPath):
                metadataFile = os.path.join(itemPath, "tile_metadata.json")
                
                cache_item = {
                    "directory": item,
                    "path": itemPath,
                    "hasMetadata": False,
                    "hasShpIndex": False,
                    "hasGeoJsonIndex": False
                }
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å…ƒæ•°æ®æ–‡ä»¶
                if os.path.exists(metadataFile):
                    try:
                        with open(metadataFile, 'r', encoding='utf-8') as f:
                            metadata = json.load(f)
                        
                        cache_item.update({
                            "hasMetadata": True,
                            "generatedAt": metadata.get("generatedAt", ""),
                            "completedAt": metadata.get("completedAt", ""),
                            "sourceFiles": metadata.get("sourceFiles", []),
                            "totalSourceFiles": metadata.get("totalSourceFiles", 0),
                            "zoomLevels": metadata.get("zoomLevels", ""),
                            "tileSize": metadata.get("tileSize", 256),
                            "totalTiles": metadata.get("totalTiles", 0),
                            "processedTiles": metadata.get("processedTiles", 0),
                            "failedTiles": metadata.get("failedTiles", 0),
                            "successRate": metadata.get("successRate", "0%"),
                            "method": metadata.get("method", ""),
                            "resampling": metadata.get("resampling", "near"),
                            "transparencyThreshold": metadata.get("transparencyThreshold", 0.1)
                        })
                    except Exception as e:
                        cache_item["metadataError"] = str(e)
                
                # æ£€æŸ¥ç´¢å¼•æ–‡ä»¶
                shpFile = os.path.join(itemPath, "tile_index.shp")
                geojsonFile = os.path.join(itemPath, "tile_index.geojson")
                
                cache_item["hasShpIndex"] = os.path.exists(shpFile)
                cache_item["hasGeoJsonIndex"] = os.path.exists(geojsonFile)
                
                # æ£€æŸ¥ç“¦ç‰‡æ–‡ä»¶æ•°é‡ï¼ˆå¿«é€Ÿç»Ÿè®¡ï¼‰
                try:
                    tile_count = 0
                    for root, dirs, files in os.walk(itemPath):
                        tile_count += len([f for f in files if f.endswith(('.png', '.jpg', '.jpeg'))])
                    cache_item["actualTileFiles"] = tile_count
                except:
                    cache_item["actualTileFiles"] = 0
                
                cache_info.append(cache_item)
        
        # æŒ‰ç”Ÿæˆæ—¶é—´æ’åº
        cache_info.sort(key=lambda x: x.get("generatedAt", ""), reverse=True)
        
        return jsonify({
            "cacheDirectories": cache_info,
            "totalDirectories": len(cache_info),
            "tilesBaseDir": tilesDir
        })
        
    except Exception as e:
        logMessage(f"è·å–ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}", "ERROR")
        return jsonify({"error": str(e)}), 500

def recommendConfig():
    """
    æ ¹æ®æ–‡ä»¶ç‰¹å¾æ¨èæœ€ä½³é…ç½®å‚æ•°
    
    @return åŒ…å«æ¨èé…ç½®çš„JSONå“åº”
    """
    try:
        data = request.get_json()
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        sourceFile = data.get('sourceFile')
        if not sourceFile:
            return jsonify({"error": "ç¼ºå°‘å‚æ•°: sourceFile"}), 400
        
        filePath = os.path.join(config["dataSourceDir"], sourceFile)
        if not os.path.exists(filePath):
            return jsonify({"error": "æºæ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        # è·å–æ–‡ä»¶å¤§å°
        fileSizeGb = os.path.getsize(filePath) / (1024**3)
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        try:
            import psutil
            cpuCount = psutil.cpu_count() or 4
            memoryTotalGb = psutil.virtual_memory().total / (1024**3)
        except:
            cpuCount = 4
            memoryTotalGb = 8
        
        # è·å–ç”¨æˆ·è¾“å…¥
        tileType = data.get('tileType', 'map')
        userMinZoom = data.get('minZoom')
        userMaxZoom = data.get('maxZoom')
        
        # ç”Ÿæˆæ¨èé…ç½®
        recommendations = generateSmartRecommendations(
            fileSizeGb, tileType, userMinZoom, userMaxZoom, cpuCount, memoryTotalGb
        )
        
        return jsonify({
            "success": True,
            "fileSize": fileSizeGb,
            "systemInfo": {
                "cpuCount": cpuCount,
                "memoryTotalGb": memoryTotalGb
            },
            "recommendations": recommendations
        })
    
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def systemInfo():
    """
    è·å–ç³»ç»Ÿä¿¡æ¯ï¼ŒåŒ…æ‹¬ç¡¬ä»¶é…ç½®å’Œè¿è¡ŒçŠ¶æ€
    
    @return åŒ…å«ç³»ç»Ÿä¿¡æ¯çš„JSONå“åº”
    """
    try:
        logMessage("æ”¶åˆ°ç³»ç»Ÿä¿¡æ¯æŸ¥è¯¢è¯·æ±‚", "INFO")
        systemInfo = {
            "timestamp": datetime.now().isoformat(),
            "config": {
                "dataSourceDir": config["dataSourceDir"],
                "tilesDir": config["tilesDir"],
                "maxThreads": config["maxThreads"],
                "supportedFormats": config["supportedFormats"]
            }
        }
        
        # ç³»ç»Ÿèµ„æºä¿¡æ¯
        try:
            import psutil
            systemInfo["system"] = {
                "cpuCount": psutil.cpu_count(),
                "memoryTotal": psutil.virtual_memory().total,
                "memoryAvailable": psutil.virtual_memory().available,
                "diskUsage": psutil.disk_usage('/').percent
            }
        except:
            systemInfo["system"] = {
                "cpuCount": 4,
                "memoryTotal": 8589934592,
                "memoryAvailable": 4294967296,
                "diskUsage": 50
            }
        
        # ä»»åŠ¡ç»Ÿè®¡
        with taskLock:
            systemInfo["tasks"] = {
                "total": len(taskStatus),
                "running": len([t for t in taskStatus.values() if t.get("status") == "running"]),
                "completed": len([t for t in taskStatus.values() if t.get("status") == "completed"]),
                "failed": len([t for t in taskStatus.values() if t.get("status") == "failed"])
            }
        
        return jsonify(systemInfo)
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# getCacheInfoå‡½æ•°å¯ä»¥é€šè¿‡å…¶ä»–æ–‡ä»¶ä¸­çš„è·¯ç”±è°ƒç”¨

def listApiRoutes():
    """
    è·å–æ‰€æœ‰APIè·¯ç”±åˆ—è¡¨åŠå…¶è¯´æ˜
    
    @return åŒ…å«APIè·¯ç”±ä¿¡æ¯çš„JSONå“åº”
    """
    try:
        # è¿™é‡Œå¯ä»¥å®ç°è·¯ç”±åˆ—è¡¨åŠŸèƒ½
        routes = [
            {"path": "/api/health", "methods": ["GET"], "description": "å¥åº·æ£€æŸ¥", "category": "ç³»ç»Ÿç›‘æ§", "logic": "è¿”å›æœåŠ¡å¥åº·çŠ¶æ€ã€æ—¶é—´æˆ³å’Œç‰ˆæœ¬ä¿¡æ¯"},
            {"path": "/api/dataSources", "methods": ["GET"], "description": "è·å–æ•°æ®æºåˆ—è¡¨", "category": "æ•°æ®æºç®¡ç†", "logic": "æµè§ˆæ ¹ç›®å½•æˆ–æŒ‡å®šå­ç›®å½•çš„TIFæ–‡ä»¶ï¼Œæ”¯æŒåœ°ç†èŒƒå›´ç­›é€‰"},
            {"path": "/api/dataSources/<path:subpath>", "methods": ["GET"], "description": "è·å–å­ç›®å½•æ•°æ®æº", "category": "æ•°æ®æºç®¡ç†", "logic": "æµè§ˆæŒ‡å®šå­ç›®å½•çš„TIFæ–‡ä»¶ï¼Œæ”¯æŒåœ°ç†èŒƒå›´ç­›é€‰"},
            {"path": "/api/dataSources/info/<filename>", "methods": ["GET"], "description": "è·å–æ•°æ®æºä¿¡æ¯", "category": "æ•°æ®æºç®¡ç†", "logic": "è·å–TIFæ–‡ä»¶çš„å…ƒæ•°æ®ã€åœ°ç†ä¿¡æ¯å’Œæ™ºèƒ½åˆ‡ç‰‡é…ç½®æ¨è"},
            {"path": "/api/tile/terrain", "methods": ["POST"], "description": "åˆ›å»ºåœ°å½¢ç“¦ç‰‡ï¼ˆæ”¯æŒåˆå¹¶ï¼‰", "category": "ç“¦ç‰‡ç”Ÿæˆ", "logic": "ä½¿ç”¨CTBç”Ÿæˆåœ°å½¢ç“¦ç‰‡ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†ã€æ™ºèƒ½ç¼©æ”¾å’Œåœ°å½¢åˆå¹¶ã€‚å‚æ•°mergeTerrains=trueå¯è‡ªåŠ¨åˆå¹¶å¤šä¸ªåœ°å½¢æ–‡ä»¶å¤¹"},
            {"path": "/api/tile/indexedTiles", "methods": ["POST"], "description": "åˆ›å»ºç´¢å¼•ç“¦ç‰‡", "category": "ç“¦ç‰‡ç”Ÿæˆ", "logic": "åŸºäºç©ºé—´ç´¢å¼•çš„é«˜æ€§èƒ½ç“¦ç‰‡ç”Ÿæˆï¼Œæ”¯æŒå¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†"},
            {"path": "/api/tile/convert", "methods": ["POST"], "description": "ç“¦ç‰‡æ ¼å¼è½¬æ¢", "category": "ç“¦ç‰‡ç”Ÿæˆ", "logic": "z/x_y.png â†” z/x/y.pngæ ¼å¼è½¬æ¢ï¼Œæ”¯æŒæ‰¹é‡å¤„ç†"},

            {"path": "/api/tasks", "methods": ["GET"], "description": "è·å–ä»»åŠ¡åˆ—è¡¨", "category": "ä»»åŠ¡ç®¡ç†", "logic": "è¿”å›æ‰€æœ‰ä»»åŠ¡çš„çŠ¶æ€ã€è¿›åº¦å’ŒåŸºæœ¬ä¿¡æ¯"},
            {"path": "/api/tasks/<taskId>", "methods": ["GET"], "description": "è·å–ä»»åŠ¡çŠ¶æ€", "category": "ä»»åŠ¡ç®¡ç†", "logic": "è·å–æŒ‡å®šä»»åŠ¡çš„è¯¦ç»†çŠ¶æ€ã€è¿›åº¦å’Œç»“æœä¿¡æ¯"},
            {"path": "/api/tasks/cleanup", "methods": ["POST"], "description": "æ¸…ç†ä»»åŠ¡", "category": "ä»»åŠ¡ç®¡ç†", "logic": "æ¸…ç†å·²å®Œæˆã€å¤±è´¥æˆ–å–æ¶ˆçš„ä»»åŠ¡è®°å½•"},
            {"path": "/api/tasks/<taskId>/stop", "methods": ["POST"], "description": "åœæ­¢ä»»åŠ¡", "category": "ä»»åŠ¡ç®¡ç†", "logic": "åœæ­¢æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡å¹¶é‡Šæ”¾èµ„æº"},
            {"path": "/api/tasks/<taskId>", "methods": ["DELETE"], "description": "åˆ é™¤ä»»åŠ¡", "category": "ä»»åŠ¡ç®¡ç†", "logic": "åˆ é™¤ä»»åŠ¡è®°å½•å’Œç›¸å…³æ•°æ®"},
            {"path": "/api/config/recommend", "methods": ["POST"], "description": "æ¨èé…ç½®", "category": "é…ç½®ç®¡ç†", "logic": "æ ¹æ®æ–‡ä»¶ç‰¹å¾å’Œç³»ç»Ÿèµ„æºæ¨èæœ€ä¼˜åˆ‡ç‰‡é…ç½®"},
            {"path": "/api/system/info", "methods": ["GET"], "description": "ç³»ç»Ÿä¿¡æ¯", "category": "ç³»ç»Ÿç›‘æ§", "logic": "è¿”å›ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µã€ä»»åŠ¡ç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡"},
            {"path": "/api/container/update", "methods": ["POST"], "description": "æ›´æ–°Dockerå®¹å™¨ä¿¡æ¯", "category": "ç³»ç»Ÿç›‘æ§", "logic": "æ›´æ–°å®¹å™¨æ—¶é—´åŒæ­¥ã€é…ç½®ç­‰ç³»ç»Ÿä¿¡æ¯"},
            {"path": "/api/workspace/createFolder", "methods": ["POST"], "description": "åˆ›å»ºå·¥ä½œç©ºé—´æ–‡ä»¶å¤¹", "category": "å·¥ä½œç©ºé—´ç®¡ç†", "logic": "åœ¨ç“¦ç‰‡è¾“å‡ºç›®å½•ä¸­åˆ›å»ºæ–°æ–‡ä»¶å¤¹"},
            {"path": "/api/workspace/folder/<path:folderPath>", "methods": ["DELETE"], "description": "åˆ é™¤å·¥ä½œç©ºé—´æ–‡ä»¶å¤¹", "category": "å·¥ä½œç©ºé—´ç®¡ç†", "logic": "åˆ é™¤æŒ‡å®šçš„å·¥ä½œç©ºé—´æ–‡ä»¶å¤¹åŠå…¶å†…å®¹"},
            {"path": "/api/workspace/folder/<path:folderPath>/rename", "methods": ["PUT"], "description": "é‡å‘½åå·¥ä½œç©ºé—´æ–‡ä»¶å¤¹", "category": "å·¥ä½œç©ºé—´ç®¡ç†", "logic": "é‡å‘½åæŒ‡å®šçš„å·¥ä½œç©ºé—´æ–‡ä»¶å¤¹"},
            {"path": "/api/workspace/info", "methods": ["GET"], "description": "è·å–å·¥ä½œç©ºé—´ä¿¡æ¯", "category": "å·¥ä½œç©ºé—´ç®¡ç†", "logic": "è·å–å·¥ä½œç©ºé—´ç»Ÿè®¡ä¿¡æ¯ï¼šæ€»å¤§å°ã€æ–‡ä»¶æ•°ã€ç›®å½•æ•°ç­‰"},
            {"path": "/api/tiles/nodata/scan", "methods": ["POST"], "description": "æ‰«æåŒ…å«é€æ˜ï¼ˆnodataï¼‰å€¼çš„PNGç“¦ç‰‡", "category": "ç“¦ç‰‡ç®¡ç†", "logic": "æ‰«ææŒ‡å®šç›®å½•ä¸­åŒ…å«é€æ˜æˆ–nodataå€¼çš„PNGç“¦ç‰‡"},
            {"path": "/api/tiles/nodata/delete", "methods": ["POST"], "description": "åˆ é™¤åŒ…å«é€æ˜ï¼ˆnodataï¼‰å€¼çš„PNGç“¦ç‰‡", "category": "ç“¦ç‰‡ç®¡ç†", "logic": "åˆ é™¤æ‰«æåˆ°çš„é€æ˜æˆ–nodataç“¦ç‰‡æ–‡ä»¶"},
            {"path": "/api/terrain/layer", "methods": ["POST"], "description": "æ›´æ–°åœ°å½¢ç“¦ç‰‡çš„layer.jsonæ–‡ä»¶", "category": "åœ°å½¢å¤„ç†", "logic": "ä¿®å¤å’Œæ›´æ–°åœ°å½¢ç“¦ç‰‡çš„layer.jsonå…ƒæ•°æ®æ–‡ä»¶"},
            {"path": "/api/terrain/decompress", "methods": ["POST"], "description": "è§£å‹åœ°å½¢ç“¦ç‰‡", "category": "åœ°å½¢å¤„ç†", "logic": "è§£å‹ç¼©åœ°å½¢ç“¦ç‰‡æ–‡ä»¶ï¼ˆ.terrain.gz â†’ .terrainï¼‰"},
            {"path": "/api/routes", "methods": ["GET"], "description": "APIè·¯ç”±åˆ—è¡¨", "category": "APIæ–‡æ¡£", "logic": "è¿”å›æ‰€æœ‰å¯ç”¨APIæ¥å£çš„è¯¦ç»†ä¿¡æ¯å’Œç»Ÿè®¡æ•°æ®"}
        ]
        
        return jsonify({
            "success": True,
            "routes": routes,
            "total": len(routes),
            "categories": list(set(route["category"] for route in routes)),
            "stats": {
                "totalRoutes": len(routes),
                "byCategory": {category: len([r for r in routes if r["category"] == category]) for category in set(route["category"] for route in routes)},
                "byMethod": {method: len([r for r in routes if method in r["methods"]]) for method in set(method for route in routes for method in route["methods"])}
            }
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500 

def extractGeographicBounds(gdalinfoOutput: str) -> dict:
    """ä»gdalinfoè¾“å‡ºä¸­æå–åœ°ç†è¾¹ç•Œï¼Œæ™ºèƒ½è¯†åˆ«åæ ‡ç³»ç±»å‹"""
    try:
        lines = gdalinfoOutput.split('\n')
        bounds = {}
        
        # é¦–å…ˆè¯†åˆ«åæ ‡ç³»ç±»å‹
        coordinateSystemType = None
        for line in lines:
            line = line.strip()
            if line.startswith('PROJCS['):
                coordinateSystemType = 'projected'
                logMessage("æ£€æµ‹åˆ°æŠ•å½±åæ ‡ç³»ï¼Œå°†è§£æåº¦åˆ†ç§’æ ¼å¼åæ ‡")
                break
            elif line.startswith('GEOGCS[') or line.startswith('GEOGCRS['):
                coordinateSystemType = 'geographic'
                logMessage("æ£€æµ‹åˆ°åœ°ç†åæ ‡ç³»ï¼Œå°†ç›´æ¥ä½¿ç”¨åè¿›åˆ¶åº¦åæ ‡")
                break
        
        if coordinateSystemType is None:
            logMessage("æœªæ£€æµ‹åˆ°åæ ‡ç³»ä¿¡æ¯", "WARNING")
            return None
        
        def parseDmsCoordinate(coordStr):
            """è§£æåº¦åˆ†ç§’æ ¼å¼åæ ‡ ä¾‹ï¼š104d45'56.25"E æˆ– 54d 6'46.97"N"""
            try:
                import re
                # åŒ¹é…åº¦åˆ†ç§’æ ¼å¼ï¼šæ•°å­—dæ•°å­—'æ•°å­—.æ•°å­—"æ–¹å‘
                pattern = r'(\d+)d\s*(\d+)\'(\d+\.?\d*)"([EWNS])'
                match = re.search(pattern, coordStr)
                if match:
                    degrees = float(match.group(1))
                    minutes = float(match.group(2))
                    seconds = float(match.group(3))
                    direction = match.group(4)
                    
                    # è½¬æ¢ä¸ºåè¿›åˆ¶åº¦
                    decimalDegrees = degrees + minutes/60 + seconds/3600
                    
                    # æ ¹æ®æ–¹å‘è°ƒæ•´ç¬¦å·
                    if direction in ['W', 'S']:
                        decimalDegrees = -decimalDegrees
                        
                    return decimalDegrees
                return None
            except:
                return None
        
        def parseDecimalCoordinate(coordStr):
            """è§£æåè¿›åˆ¶åæ ‡ ä¾‹ï¼š-122.456, 37.789"""
            try:
                import re
                # æå–æµ®ç‚¹æ•°ï¼ˆå¯èƒ½æœ‰è´Ÿå·ï¼‰
                pattern = r'(-?\d+\.?\d*)'
                numbers = re.findall(pattern, coordStr)
                if len(numbers) >= 2:
                    return float(numbers[0]), float(numbers[1])  # lon, lat
                return None, None
            except:
                return None, None
        
        # æŸ¥æ‰¾Corner Coordinateséƒ¨åˆ†
        cornerSection = False
        for line in lines:
            line = line.strip()
            
            if line.startswith('Corner Coordinates:'):
                cornerSection = True
                continue
                
            if cornerSection and line.startswith('Upper Left'):
                # è§£æ: Upper Left  (12914800.299, 5087648.603) (116d 0'56.25"E, 41d41'58.41"N)
                parts = line.split(')')
                
                if coordinateSystemType == 'projected':
                    # æŠ•å½±åæ ‡ç³»ï¼šä½¿ç”¨ç¬¬äºŒä¸ªæ‹¬å·å†…çš„åº¦åˆ†ç§’æ ¼å¼
                    if len(parts) >= 2:
                        coordSection = parts[1].strip().replace('(', '').replace(')', '')
                        
                        # åˆ†ç¦»ç»åº¦å’Œçº¬åº¦
                        if ',' in coordSection:
                            lonStr, latStr = coordSection.split(',', 1)
                            lon = parseDmsCoordinate(lonStr.strip())
                            lat = parseDmsCoordinate(latStr.strip())
                            
                            if lon is not None and lat is not None:
                                bounds['upperLeftLon'] = lon
                                bounds['upperLeftLat'] = lat
                                
                elif coordinateSystemType == 'geographic':
                    # åœ°ç†åæ ‡ç³»ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæ‹¬å·å†…çš„åè¿›åˆ¶åº¦
                    if len(parts) >= 1:
                        coordSection = parts[0].split('(')[1].strip() if '(' in parts[0] else parts[0].strip()
                        lon, lat = parseDecimalCoordinate(coordSection)
                        
                        if lon is not None and lat is not None:
                            bounds['upperLeftLon'] = lon
                            bounds['upperLeftLat'] = lat
                            
            elif cornerSection and line.startswith('Lower Right'):
                parts = line.split(')')
                
                if coordinateSystemType == 'projected':
                    # æŠ•å½±åæ ‡ç³»ï¼šä½¿ç”¨ç¬¬äºŒä¸ªæ‹¬å·å†…çš„åº¦åˆ†ç§’æ ¼å¼
                    if len(parts) >= 2:
                        coordSection = parts[1].strip().replace('(', '').replace(')', '')
                        
                        if ',' in coordSection:
                            lonStr, latStr = coordSection.split(',', 1)
                            lon = parseDmsCoordinate(lonStr.strip())
                            lat = parseDmsCoordinate(latStr.strip())
                            
                            if lon is not None and lat is not None:
                                bounds['lowerRightLon'] = lon
                                bounds['lowerRightLat'] = lat
                                
                elif coordinateSystemType == 'geographic':
                    # åœ°ç†åæ ‡ç³»ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªæ‹¬å·å†…çš„åè¿›åˆ¶åº¦
                    if len(parts) >= 1:
                        coordSection = parts[0].split('(')[1].strip() if '(' in parts[0] else parts[0].strip()
                        lon, lat = parseDecimalCoordinate(coordSection)
                        
                        if lon is not None and lat is not None:
                            bounds['lowerRightLon'] = lon
                            bounds['lowerRightLat'] = lat
        
        # è®¡ç®—å®Œæ•´è¾¹ç•Œ
        if 'upperLeftLon' in bounds and 'lowerRightLon' in bounds:
            west = bounds['upperLeftLon']
            east = bounds['lowerRightLon'] 
            north = bounds['upperLeftLat']
            south = bounds['lowerRightLat']
            
            # è®¡ç®—å®½åº¦å’Œé«˜åº¦ï¼ˆåº¦ï¼‰
            widthDegrees = east - west
            heightDegrees = north - south
            
            # ç¡®ä¿å®½åº¦å’Œé«˜åº¦ä¸ºæ­£å€¼
            if widthDegrees < 0:
                widthDegrees += 360  # å¤„ç†è·¨è¶Š180åº¦ç»çº¿çš„æƒ…å†µ
            if heightDegrees < 0:
                heightDegrees = abs(heightDegrees)
            
            bounds.update({
                'west': west,
                'east': east, 
                'north': north,
                'south': south,
                'widthDegrees': widthDegrees,
                'heightDegrees': heightDegrees
            })
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logMessage(f"åæ ‡ç³»ç±»å‹: {coordinateSystemType}")
            logMessage(f"è§£æåœ°ç†è¾¹ç•Œ: è¥¿ç»{west:.2f}Â°, ä¸œç»{east:.2f}Â°, åŒ—çº¬{north:.2f}Â°, å—çº¬{south:.2f}Â°")
            logMessage(f"è¾¹ç•Œå°ºå¯¸: å®½åº¦{widthDegrees:.2f}Â°, é«˜åº¦{heightDegrees:.2f}Â°")
            
        return bounds if bounds else None
        
    except Exception as e:
        logMessage(f"æå–åœ°ç†è¾¹ç•Œå¤±è´¥: {e}", "ERROR")
        return None

def getFileGeographicBounds(filePath: str) -> dict:
    """
    è·å–æ–‡ä»¶çš„åœ°ç†è¾¹ç•Œä¿¡æ¯
    
    Args:
        filePath: æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: åœ°ç†è¾¹ç•Œä¿¡æ¯æˆ–None
    """
    try:
        # ä½¿ç”¨gdalinfoè·å–æ–‡ä»¶ä¿¡æ¯
        cmd = ["gdalinfo", filePath]
        result = runCommand(cmd)
        
        if not result["success"]:
            logMessage(f"è·å–æ–‡ä»¶åœ°ç†ä¿¡æ¯å¤±è´¥: {filePath}, é”™è¯¯: {result.get('stderr', '')}", "WARNING")
            return None
        
        # è§£æåœ°ç†è¾¹ç•Œ
        bounds = extractGeographicBounds(result["stdout"])
        return bounds
        
    except Exception as e:
        logMessage(f"è·å–æ–‡ä»¶åœ°ç†è¾¹ç•Œå¤±è´¥: {filePath}, é”™è¯¯: {e}", "ERROR")
        return None 

def findTifFilesInFolders(folderPaths: list, filePatterns: list = None) -> list:
    """
    åœ¨å¤šä¸ªæ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾TIFæ–‡ä»¶
    
    Args:
        folderPaths: æ–‡ä»¶å¤¹è·¯å¾„åˆ—è¡¨ï¼ˆç›¸å¯¹äºdataSourceDirï¼‰
        filePatterns: æ–‡ä»¶åŒ¹é…æ¨¡å¼åˆ—è¡¨ï¼Œæ”¯æŒé€šé…ç¬¦å’Œtxtæ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        åŒ¹é…çš„TIFæ–‡ä»¶åˆ—è¡¨ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
    """
    try:
        foundFiles = []
        
        # å¤„ç†æ ¹è·¯å¾„çš„æƒ…å†µ
        if not folderPaths or folderPaths == [""]:
            searchPaths = [config["dataSourceDir"]]
            relativeBases = [""]
        else:
            searchPaths = []
            relativeBases = []
            for folderPath in folderPaths:
                fullPath = os.path.join(config["dataSourceDir"], folderPath) if folderPath else config["dataSourceDir"]
                if os.path.exists(fullPath):
                    searchPaths.append(fullPath)
                    relativeBases.append(folderPath)
                else:
                    logMessage(f"è­¦å‘Šï¼šæ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folderPath}", "WARNING")
        
        # é»˜è®¤åŒ¹é…æ¨¡å¼
        if not filePatterns:
            filePatterns = ["*.tif", "*.tiff"]
        
        # åˆ†ç¦»txtæ–‡ä»¶å’Œé€šé…ç¬¦æ¨¡å¼
        txtFiles = [p for p in filePatterns if p.lower().endswith('.txt')]
        globPatterns = [p for p in filePatterns if not p.lower().endswith('.txt')]
        
        # å¤„ç†txtæ–‡ä»¶åˆ—è¡¨
        for txtFile in txtFiles:
            logMessage(f"ğŸ“‹ å¤„ç†txtæ–‡ä»¶åˆ—è¡¨: {txtFile}")
            
            # txtæ–‡ä»¶æŸ¥æ‰¾ï¼šåŸºç¡€è·¯å¾„ + filePatternsä¸­çš„txtæ–‡ä»¶å
            txtFilePath = os.path.join(config["dataSourceDir"], txtFile)
            
            if not os.path.exists(txtFilePath):
                logMessage(f"âŒ æœªæ‰¾åˆ°txtæ–‡ä»¶: {txtFilePath}", "WARNING")
                continue
            
            logMessage(f"âœ… æ‰¾åˆ°txtæ–‡ä»¶: {txtFilePath}")
            
            # è¯»å–txtæ–‡ä»¶å†…å®¹
            try:
                with open(txtFilePath, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for lineNum, line in enumerate(lines, 1):
                    line = line.strip()
                    
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if not line or line.startswith('#'):
                        continue
                    
                    # txtæ–‡ä»¶ä¸­çš„æ–‡ä»¶æŸ¥æ‰¾ï¼šåŸºç¡€è·¯å¾„ + folderPaths + æ–‡ä»¶å
                    if os.path.isabs(line):
                        # ç»å¯¹è·¯å¾„ï¼šè½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                        try:
                            relativePath = os.path.relpath(line, config["dataSourceDir"])
                            if relativePath.startswith('..'):
                                logMessage(f"âš ï¸ txtæ–‡ä»¶ç¬¬{lineNum}è¡Œè·¯å¾„è¶…å‡ºæ•°æ®æºç›®å½•: {line}", "WARNING")
                                continue
                            
                            # éªŒè¯ç»å¯¹è·¯å¾„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                            if os.path.exists(line) and line.lower().endswith(('.tif', '.tiff')):
                                if relativePath not in foundFiles:
                                    foundFiles.append(relativePath)
                                    logMessage(f"ğŸ“„ ä»txtæ·»åŠ (ç»å¯¹è·¯å¾„): {relativePath}")
                            else:
                                logMessage(f"âš ï¸ txtæ–‡ä»¶ç¬¬{lineNum}è¡Œç»å¯¹è·¯å¾„æ–‡ä»¶ä¸å­˜åœ¨æˆ–éTIFæ ¼å¼: {line}", "WARNING")
                        except:
                            logMessage(f"âš ï¸ txtæ–‡ä»¶ç¬¬{lineNum}è¡Œç»å¯¹è·¯å¾„è½¬æ¢å¤±è´¥: {line}", "WARNING")
                            continue
                    else:
                        # ç›¸å¯¹è·¯å¾„ï¼šåœ¨folderPathsæŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­æœç´¢
                        fileFound = False
                        
                        # åœ¨æ¯ä¸ªfolderPathsæŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾
                        for searchPath, relativeBase in zip(searchPaths, relativeBases):
                            if relativeBase:  # å¦‚æœæœ‰æŒ‡å®šæ–‡ä»¶å¤¹
                                candidatePath = os.path.join(relativeBase, line)
                            else:  # æ ¹ç›®å½•
                                candidatePath = line
                            
                            fullPath = os.path.join(config["dataSourceDir"], candidatePath)
                            
                            if os.path.exists(fullPath) and fullPath.lower().endswith(('.tif', '.tiff')):
                                if candidatePath not in foundFiles:
                                    foundFiles.append(candidatePath)
                                    logMessage(f"ğŸ“„ ä»txtæ·»åŠ (æ–‡ä»¶å¤¹'{relativeBase}'): {candidatePath}")
                                fileFound = True
                                break  # æ‰¾åˆ°å°±åœæ­¢ï¼Œé¿å…é‡å¤æ·»åŠ 
                        
                        # å¦‚æœåœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­éƒ½æ²¡æ‰¾åˆ°ï¼Œæç¤ºé”™è¯¯
                        if not fileFound:
                            searched_folders = [relativeBase or "æ ¹ç›®å½•" for relativeBase in relativeBases]
                            logMessage(f"âš ï¸ txtæ–‡ä»¶ç¬¬{lineNum}è¡Œæ–‡ä»¶æœªæ‰¾åˆ°: {line} (å·²åœ¨æ–‡ä»¶å¤¹ {searched_folders} ä¸­æœç´¢)", "WARNING")
                
            except Exception as e:
                logMessage(f"âŒ è¯»å–txtæ–‡ä»¶å¤±è´¥ {txtFilePath}: {e}", "ERROR")
        
        # å¤„ç†é€šé…ç¬¦æ¨¡å¼
        for searchPath, relativeBase in zip(searchPaths, relativeBases):
            logMessage(f"ğŸ” åœ¨è·¯å¾„ä¸­æœç´¢TIFæ–‡ä»¶: {searchPath}")
            
            for pattern in globPatterns:
                # æ„å»ºå®Œæ•´çš„æœç´¢æ¨¡å¼
                searchPattern = os.path.join(searchPath, pattern)
                logMessage(f"ğŸ¯ ä½¿ç”¨æ¨¡å¼: {searchPattern}")
                
                # ä½¿ç”¨globæŸ¥æ‰¾æ–‡ä»¶
                matches = glob.glob(searchPattern)
                logMessage(f"ğŸ“Š globç»“æœ: {len(matches)}ä¸ªæ–‡ä»¶")
                
                for match in matches:
                    if match.lower().endswith(('.tif', '.tiff')):
                        # è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„
                        if relativeBase:
                            relativePath = os.path.join(relativeBase, os.path.basename(match))
                        else:
                            relativePath = os.path.basename(match)
                        
                        if relativePath not in foundFiles:
                            foundFiles.append(relativePath)
                            logMessage(f"ğŸŒŸ æ·»åŠ æ–‡ä»¶: {relativePath}")
        
        logMessage(f"âœ… æ€»å…±æ‰¾åˆ° {len(foundFiles)} ä¸ªTIFæ–‡ä»¶")
        return foundFiles
        
    except Exception as e:
        logMessage(f"âŒ æŸ¥æ‰¾TIFæ–‡ä»¶å¤±è´¥: {e}", "ERROR")
        return []

def convertSinglePathToRelative(filePath: str) -> str:
    """å°†ç»å¯¹è·¯å¾„è½¬æ¢ä¸ºç›¸å¯¹è·¯å¾„"""
    try:
        if os.path.isabs(filePath):
            return os.path.relpath(filePath, config["dataSourceDir"])
        return filePath
    except:
        return filePath

def processUltraHighPerformanceTiles(tileIndex, outputPath, resampling="near", 
                                   max_workers=None, enable_memory_cache=True, enable_async_io=True, user_processes=None, user_memory_gb=None):
    """
    æè‡´é«˜æ€§èƒ½ç“¦ç‰‡å¤„ç† - ç›®æ ‡: 1000-2000ç“¦ç‰‡/ç§’
    å€Ÿé‰´120GBå†…å­˜ç¼“å­˜ + 86æ ¸å¿ƒå¹¶è¡Œ + å¼‚æ­¥I/Oçš„æè‡´ä¼˜åŒ–æ–¹æ¡ˆ
    
    @param tileIndex ç“¦ç‰‡ç´¢å¼•åˆ—è¡¨
    @param outputPath è¾“å‡ºè·¯å¾„
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param max_workers æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°
    @param enable_memory_cache å¯ç”¨å†…å­˜ç¼“å­˜
    @param enable_async_io å¯ç”¨å¼‚æ­¥I/O
    @param user_processes ç”¨æˆ·æŒ‡å®šçš„è¿›ç¨‹æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    @return å¤„ç†ç»“æœç»Ÿè®¡
    """
    import multiprocessing as mp
    import asyncio
    import concurrent.futures
    import time
    import threading
    from collections import defaultdict
    import queue
    
    total_tiles = len(tileIndex)
    cpu_count = mp.cpu_count()
    system_memory_gb = psutil.virtual_memory().total / (1024**3)
    
    # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„å†…å­˜ï¼Œå¦åˆ™ä½¿ç”¨ç³»ç»Ÿå†…å­˜
    effective_memory_gb = user_memory_gb if user_memory_gb is not None else system_memory_gb
    
    logMessage(f"ğŸš€ å¯åŠ¨æè‡´é«˜æ€§èƒ½ç“¦ç‰‡å¤„ç†")
    logMessage(f"ğŸ“Š ç³»ç»Ÿé…ç½®: {cpu_count}æ ¸CPU, {system_memory_gb:.1f}GBå†…å­˜")
    if user_memory_gb is not None:
        logMessage(f"ğŸ’¾ ä½¿ç”¨ç”¨æˆ·æŒ‡å®šå†…å­˜: {user_memory_gb:.1f}GB (ç³»ç»Ÿå†…å­˜: {system_memory_gb:.1f}GB)")
    else:
        logMessage(f"ğŸ’¾ ä½¿ç”¨ç³»ç»Ÿå†…å­˜: {system_memory_gb:.1f}GB")
    logMessage(f"ğŸ¯ å¤„ç†ç›®æ ‡: {total_tiles}ç“¦ç‰‡, ç›®æ ‡é€Ÿåº¦: 1000ç“¦ç‰‡/ç§’")
    
    # æè‡´å‚æ•°è®¡ç®—
    if max_workers is None:
        if user_processes and user_processes > 0:
            # ç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†è¿›ç¨‹æ•°ï¼Œä¼˜å…ˆä½¿ç”¨ç”¨æˆ·çš„å€¼
            max_workers = user_processes
            logMessage(f"ğŸ¯ æè‡´æ¨¡å¼ä½¿ç”¨ç”¨æˆ·æŒ‡å®šè¿›ç¨‹æ•°: {max_workers}")
        else:
            # 86æ ¸å¿ƒç­–ç•¥ï¼šå……åˆ†åˆ©ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
            max_workers = min(cpu_count * 3, 128)  # æœ€å¤š128ä¸ªå·¥ä½œè¿›ç¨‹
            logMessage(f"ğŸ¤– æè‡´æ¨¡å¼è‡ªåŠ¨è®¡ç®—è¿›ç¨‹æ•°: {max_workers}")
    
    # è¶…çº§æ‰¹é‡å¤§å°è®¡ç®— - å€Ÿé‰´ä½ çš„4000å€æå‡ç­–ç•¥
    ultra_batch_size = calculateUltraBatchSize(total_tiles, max_workers, effective_memory_gb)
    
    logMessage(f"ğŸ§  æè‡´å‚æ•°: {max_workers}è¿›ç¨‹, è¶…çº§æ‰¹é‡{ultra_batch_size}")
    
    # å†…å­˜ç¼“å­˜ç­–ç•¥ - 120GBå†…å­˜ç¼“å­˜TIFæ–‡ä»¶
    memory_cache = {}
    if enable_memory_cache and effective_memory_gb > 32:
        logMessage("ğŸ’¾ å¯åŠ¨å†…å­˜ç¼“å­˜ç­–ç•¥ - é¢„åŠ è½½TIFåˆ°å†…å­˜")
        memory_cache = preloadTifFilesToMemory(tileIndex, effective_memory_gb)
        logMessage(f"âœ… å†…å­˜ç¼“å­˜å®Œæˆ: {len(memory_cache)}ä¸ªæ–‡ä»¶å·²ç¼“å­˜")
    
    # å¼‚æ­¥I/Oæ¶æ„ - è¯»å†™åˆ†ç¦»
    async_executor = None
    if enable_async_io:
        async_executor = concurrent.futures.ThreadPoolExecutor(max_workers=16, thread_name_prefix="AsyncIO")
        logMessage("âš¡ å¯åŠ¨å¼‚æ­¥I/Oæ¶æ„ - è¯»å†™åˆ†ç¦»ä¼˜åŒ–")
    
    start_time = time.time()
    
    # åˆ›å»ºç»“æœç»Ÿè®¡
    stats = {
        "processed": 0,
        "failed": 0,
        "start_time": start_time,
        "batches_completed": 0,
        "current_speed": 0.0,
        "average_speed": 0.0,
        "peak_speed": 0.0,
        "memory_cache_enabled": enable_memory_cache,
        "async_io_enabled": enable_async_io
    }
    
    # å°†ç“¦ç‰‡åˆ†æˆè¶…çº§æ‰¹æ¬¡
    tile_ultra_batches = []
    for i in range(0, total_tiles, ultra_batch_size):
        batch = tileIndex[i:i + ultra_batch_size]
        tile_ultra_batches.append(batch)
    
    logMessage(f"ğŸ“¦ è¶…çº§æ‰¹é‡åˆ†ç»„: {len(tile_ultra_batches)}ä¸ªè¶…çº§æ‰¹æ¬¡")
    
    try:
        # å¤šçº§å¹¶è¡Œå¤„ç†æ¶æ„
        with concurrent.futures.ProcessPoolExecutor(max_workers=max_workers) as executor:
            
            # æäº¤æ‰€æœ‰æ‰¹æ¬¡ä»»åŠ¡ - æè‡´å¹¶è¡Œ
            future_to_batch = {}
            for batch_idx, tile_batch in enumerate(tile_ultra_batches):
                future = executor.submit(
                    processUltraTileBatch,
                    tile_batch,
                    outputPath,
                    resampling,
                    transparencyThreshold,
                    batch_idx,
                    memory_cache,
                    enable_async_io
                )
                future_to_batch[future] = batch_idx
            
            # å®æ—¶æ€§èƒ½ç›‘æ§
            completed_batches = 0
            last_update_time = start_time
            
            for future in concurrent.futures.as_completed(future_to_batch):
                batch_idx = future_to_batch[future]
                
                try:
                    result = future.result()
                    stats["processed"] += result["processed"]
                    stats["failed"] += result["failed"]
                    completed_batches += 1
                    
                    # å®æ—¶é€Ÿåº¦è®¡ç®—
                    current_time = time.time()
                    elapsed = current_time - start_time
                    current_speed = stats["processed"] / elapsed if elapsed > 0 else 0
                    
                    # æ›´æ–°å³°å€¼é€Ÿåº¦
                    if current_speed > stats["peak_speed"]:
                        stats["peak_speed"] = current_speed
                    
                    stats["current_speed"] = current_speed
                    stats["average_speed"] = current_speed
                    stats["batches_completed"] = completed_batches
                    
                    # æ¯ç§’æ›´æ–°ä¸€æ¬¡æ—¥å¿—
                    if current_time - last_update_time >= 1.0:
                        efficiency = (current_speed / 1000) * 100  # ç›¸å¯¹äº1000ç“¦ç‰‡/ç§’çš„æ•ˆç‡
                        logMessage(f"âš¡ å®æ—¶æ€§èƒ½: {current_speed:.1f}ç“¦ç‰‡/ç§’ "
                                 f"| æ•ˆç‡: {efficiency:.1f}% | å·²å®Œæˆ: {stats['processed']}/{total_tiles}")
                        last_update_time = current_time
                    
                except Exception as e:
                    logMessage(f"âŒ æ‰¹æ¬¡{batch_idx}å¤„ç†å¤±è´¥: {e}", "ERROR")
                    stats["failed"] += len(tile_ultra_batches[batch_idx])
        
        # æœ€ç»ˆç»Ÿè®¡
        total_time = time.time() - start_time
        final_speed = stats["processed"] / total_time if total_time > 0 else 0
        
        logMessage(f"ğŸ‰ æè‡´æ€§èƒ½å¤„ç†å®Œæˆ!")
        logMessage(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: {stats['processed']}æˆåŠŸ, {stats['failed']}å¤±è´¥")
        logMessage(f"âš¡ æ€§èƒ½æŒ‡æ ‡: å¹³å‡{final_speed:.1f}ç“¦ç‰‡/ç§’, å³°å€¼{stats['peak_speed']:.1f}ç“¦ç‰‡/ç§’")
        logMessage(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        
        # è®¡ç®—æ€§èƒ½æå‡å€æ•°
        baseline_speed = 25  # åŸºå‡†é€Ÿåº¦
        improvement_factor = final_speed / baseline_speed
        logMessage(f"ğŸš€ æ€§èƒ½æå‡: {improvement_factor:.1f}å€ (ç›¸å¯¹åŸºå‡†{baseline_speed}ç“¦ç‰‡/ç§’)")
        
        stats["final_speed"] = final_speed
        stats["total_time"] = total_time
        stats["improvement_factor"] = improvement_factor
        
    finally:
        # æ¸…ç†èµ„æº
        if async_executor:
            async_executor.shutdown(wait=True)
        
        # æ¸…ç†å†…å­˜ç¼“å­˜
        if memory_cache:
            logMessage("ğŸ§¹ æ¸…ç†å†…å­˜ç¼“å­˜")
            memory_cache.clear()
    
    return stats

def calculateUltraBatchSize(total_tiles, max_workers, memory_gb):
    """
    è®¡ç®—è¶…çº§æ‰¹é‡å¤§å° - å€Ÿé‰´æè‡´ä¼˜åŒ–æ–¹æ¡ˆ
    ç›®æ ‡: æœ€å¤§åŒ–å¹¶è¡Œæ•ˆç‡ï¼Œå‡å°‘è¿›ç¨‹åˆ›å»ºå¼€é”€
    
    @param total_tiles æ€»ç“¦ç‰‡æ•°
    @param max_workers å·¥ä½œè¿›ç¨‹æ•°  
    @param memory_gb å†…å­˜å¤§å°GB
    @return è¶…çº§æ‰¹é‡å¤§å°
    """
    # åŸºç¡€æ‰¹é‡è®¡ç®—ï¼šæ¯ä¸ªè¿›ç¨‹å¤„ç†çš„ç“¦ç‰‡æ•°
    base_batch = max(50, total_tiles // (max_workers * 4))
    
    # æ ¹æ®å†…å­˜è°ƒæ•´æ‰¹é‡å¤§å°
    if memory_gb >= 64:
        # å¤§å†…å­˜ï¼šä½¿ç”¨è¶…çº§æ‰¹é‡
        memory_factor = min(4.0, memory_gb / 32)
        ultra_batch = int(base_batch * memory_factor)
    elif memory_gb >= 32:
        # ä¸­ç­‰å†…å­˜ï¼šé€‚ä¸­æ‰¹é‡
        ultra_batch = int(base_batch * 2)
    else:
        # å°å†…å­˜ï¼šä¿å®ˆæ‰¹é‡
        ultra_batch = base_batch
    
    # é™åˆ¶åœ¨åˆç†èŒƒå›´
    ultra_batch = max(20, min(ultra_batch, 500))
    
    logMessage(f"ğŸ§  è¶…çº§æ‰¹é‡è®¡ç®—: åŸºç¡€{base_batch} â†’ è¶…çº§{ultra_batch} (å†…å­˜å› å­: {memory_gb/32:.1f})")
    
    return ultra_batch

def preloadTifFilesToMemory(tileIndex, memory_gb):
    """
    é¢„åŠ è½½TIFæ–‡ä»¶åˆ°å†…å­˜ - 120GBå†…å­˜ç¼“å­˜ç­–ç•¥
    å®ç°ç”¨å†…å­˜æ¢é€Ÿåº¦çš„æè‡´ä¼˜åŒ–
    
    @param tileIndex ç“¦ç‰‡ç´¢å¼•
    @param memory_gb å¯ç”¨å†…å­˜GB
    @return å†…å­˜ç¼“å­˜å­—å…¸
    """
    memory_cache = {}
    
    # è®¡ç®—å¯ç”¨ç¼“å­˜å†…å­˜ (ä¿ç•™25%ç»™ç³»ç»Ÿ)
    available_memory_gb = memory_gb * 0.75
    
    if available_memory_gb < 8:
        logMessage("âš ï¸  å†…å­˜ä¸è¶³ï¼Œè·³è¿‡TIFé¢„åŠ è½½", "WARNING")
        return memory_cache
    
    logMessage(f"ğŸ’¾ å¼€å§‹é¢„åŠ è½½TIFæ–‡ä»¶ï¼Œå¯ç”¨å†…å­˜: {available_memory_gb:.1f}GB")
    
    # æ”¶é›†æ‰€æœ‰æºæ–‡ä»¶
    source_files = set()
    for tile_info in tileIndex:
        source_files_list = tile_info.get("sourceFiles", [])
        if source_files_list:
            for source_file in source_files_list:
                source_files.add(source_file["file"])
    
    source_files = list(source_files)
    total_files = len(source_files)
    
    logMessage(f"ğŸ“ å‘ç° {total_files} ä¸ªå”¯ä¸€TIFæ–‡ä»¶éœ€è¦é¢„åŠ è½½")
    
    # ä¼°ç®—æ–‡ä»¶å¤§å°å¹¶é€‰æ‹©æ€§åŠ è½½
    loaded_files = 0
    used_memory_gb = 0
    
    for file_path in source_files:
        try:
            # è·å–æ–‡ä»¶å¤§å°
            file_size_gb = os.path.getsize(file_path) / (1024**3)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿå†…å­˜
            if used_memory_gb + file_size_gb > available_memory_gb:
                logMessage(f"âš ï¸  å†…å­˜é™åˆ¶è¾¾åˆ°ï¼Œåœæ­¢é¢„åŠ è½½. å·²åŠ è½½: {loaded_files}/{total_files}")
                break
            
            # è¯»å–æ–‡ä»¶åˆ°å†…å­˜
            with open(file_path, 'rb') as f:
                file_data = f.read()
                memory_cache[file_path] = file_data
                
                used_memory_gb += file_size_gb
                loaded_files += 1
                
                if loaded_files % 10 == 0:
                    logMessage(f"ğŸ’¾ é¢„åŠ è½½è¿›åº¦: {loaded_files}/{total_files}, "
                             f"å†…å­˜ä½¿ç”¨: {used_memory_gb:.1f}GB/{available_memory_gb:.1f}GB")
            
        except Exception as e:
            logMessage(f"âŒ é¢„åŠ è½½æ–‡ä»¶å¤±è´¥: {file_path} - {e}", "WARNING")
            continue
    
    cache_efficiency = (loaded_files / total_files) * 100 if total_files > 0 else 0
    logMessage(f"âœ… TIFé¢„åŠ è½½å®Œæˆ: {loaded_files}/{total_files} ({cache_efficiency:.1f}%)")
    logMessage(f"ğŸ’¾ ç¼“å­˜ç»Ÿè®¡: {used_memory_gb:.1f}GBå†…å­˜, {len(memory_cache)}ä¸ªæ–‡ä»¶")
    
    return memory_cache

def processUltraTileBatch(tile_batch, outputPath, resampling, transparencyThreshold, 
                         batch_idx, memory_cache=None, enable_async_io=True):
    """
    è¶…çº§æ‰¹é‡ç“¦ç‰‡å¤„ç† - åœ¨å­è¿›ç¨‹ä¸­è¿è¡Œ
    ç»“åˆå†…å­˜ç¼“å­˜ã€å¼‚æ­¥I/Oã€å‘é‡åŒ–å¤„ç†çš„æè‡´ä¼˜åŒ–
    
    @param tile_batch ç“¦ç‰‡æ‰¹æ¬¡
    @param outputPath è¾“å‡ºè·¯å¾„
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param transparencyThreshold é€æ˜åº¦é˜ˆå€¼
    @param batch_idx æ‰¹æ¬¡ç´¢å¼•
    @param memory_cache å†…å­˜ç¼“å­˜
    @param enable_async_io å¯ç”¨å¼‚æ­¥I/O
    @return æ‰¹æ¬¡å¤„ç†ç»“æœ
    """
    import tempfile
    import concurrent.futures
    
    processed = 0
    failed = 0
    batch_start_time = time.time()
    
    # ä¸ºæ‰¹æ¬¡åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
    with tempfile.TemporaryDirectory(prefix=f"ultra_batch_{batch_idx}_") as temp_dir:
        
        if enable_async_io:
            # å¼‚æ­¥I/Oå¤„ç†
            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as io_executor:
                
                # é¢„å¤„ç†ï¼šå¼‚æ­¥å‡†å¤‡æ‰€æœ‰è¾“å…¥æ•°æ®
                prep_futures = []
                for tile_info in tile_batch:
                    future = io_executor.submit(
                        prepareTileDataAsync, 
                        tile_info, 
                        memory_cache, 
                        temp_dir
                    )
                    prep_futures.append((future, tile_info))
                
                # å¤„ç†å‡†å¤‡å¥½çš„ç“¦ç‰‡æ•°æ®
                for future, tile_info in prep_futures:
                    try:
                        prepared_data = future.result()
                        
                        if prepared_data["success"]:
                            # ä½¿ç”¨ä¼˜åŒ–çš„å‘é‡åŒ–å¤„ç†
                            result = processSingleTileVectorized(
                                tile_info,
                                outputPath,
                                resampling,

                                prepared_data,
                                temp_dir
                            )
                            
                            if result["success"]:
                                processed += 1
                            else:
                                failed += 1
                        else:
                            failed += 1
                            
                    except Exception as e:
                        failed += 1
        else:
            # ä¼ ç»ŸåŒæ­¥å¤„ç†ï¼ˆä½†ä½¿ç”¨ä¼˜åŒ–ç®—æ³•ï¼‰
            for tile_info in tile_batch:
                try:
                    result = processSingleTileOptimized(
                        tile_info,
                        outputPath,
                        resampling,
                        transparencyThreshold,
                        temp_dir
                    )
                    
                    if result["success"]:
                        processed += 1
                    else:
                        failed += 1
                        
                except Exception as e:
                    failed += 1
    
    # æ‰¹æ¬¡æ€§èƒ½ç»Ÿè®¡
    batch_time = time.time() - batch_start_time
    batch_speed = processed / batch_time if batch_time > 0 else 0
    
    return {
        "processed": processed,
        "failed": failed,
        "batch_idx": batch_idx,
        "batch_time": batch_time,
        "batch_speed": batch_speed
    }

def prepareTileDataAsync(tile_info, memory_cache, temp_dir):
    """
    å¼‚æ­¥å‡†å¤‡ç“¦ç‰‡æ•°æ® - è¯»å†™åˆ†ç¦»ä¼˜åŒ–
    
    @param tile_info ç“¦ç‰‡ä¿¡æ¯
    @param memory_cache å†…å­˜ç¼“å­˜
    @param temp_dir ä¸´æ—¶ç›®å½•
    @return å‡†å¤‡ç»“æœ
    """
    try:
        source_files = tile_info.get("sourceFiles", [])
        if not source_files:
            return {
                "success": False,
                "error": "æ²¡æœ‰æºæ–‡ä»¶"
            }
            
        prepared_files = []
        
        for source_file in source_files:
            file_path = source_file["file"]
            
            if memory_cache and file_path in memory_cache:
                # ä»å†…å­˜ç¼“å­˜è¯»å–
                file_data = memory_cache[file_path]
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶
                temp_file = os.path.join(temp_dir, f"cached_{os.path.basename(file_path)}")
                with open(temp_file, 'wb') as f:
                    f.write(file_data)
                
                prepared_files.append({
                    "file": temp_file,
                    "source": "memory_cache"
                })
            else:
                # ç›´æ¥ä½¿ç”¨åŸæ–‡ä»¶
                prepared_files.append({
                    "file": file_path,
                    "source": "disk"
                })
        
        return {
            "success": True,
            "prepared_files": prepared_files,
            "tile_info": tile_info
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

def processSingleTileVectorized(tile_info, tiles_dir, resampling, transparency_threshold, 
                               prepared_data, temp_dir):
    """
    å‘é‡åŒ–å•ç“¦ç‰‡å¤„ç† - ç®—æ³•çº§ä¼˜åŒ–
    å€Ÿé‰´numpyå‘é‡åŒ–å¤„ç†æå‡æ€§èƒ½
    
    @param tile_info ç“¦ç‰‡ä¿¡æ¯
    @param tiles_dir è¾“å‡ºç›®å½•
    @param resampling é‡é‡‡æ ·æ–¹æ³•
    @param transparency_threshold é€æ˜åº¦é˜ˆå€¼
    @param prepared_data é¢„å¤„ç†æ•°æ®
    @param temp_dir ä¸´æ—¶ç›®å½•
    @return å¤„ç†ç»“æœ
    """
    try:
        zoom, tileX, tileY = tile_info["z"], tile_info["x"], tile_info["y"]
        tileBounds = tile_info["bounds"]
        prepared_files = prepared_data["prepared_files"]
        
        # åˆ›å»ºç“¦ç‰‡ç›®å½•
        tileDir = os.path.join(tiles_dir, str(zoom), str(tileX))
        os.makedirs(tileDir, exist_ok=True)
        
        # ç“¦ç‰‡æ–‡ä»¶è·¯å¾„
        tileFile = os.path.join(tileDir, f"{tileY}.png")
        
        # å¦‚æœç“¦ç‰‡å·²å­˜åœ¨ï¼Œè·³è¿‡
        if os.path.exists(tileFile) and os.path.getsize(tileFile) > 0:
            return {
                "success": True,
                "tileFile": tileFile,
                "skipped": True,
                "method": "å‘é‡åŒ–å¤„ç†(è·³è¿‡)"
            }
        
        # å‡†å¤‡æºæ–‡ä»¶åˆ—è¡¨
        sourceFileList = [pf["file"] for pf in prepared_files]
        tempTileFile = os.path.join(temp_dir, f"vec_tile_{zoom}_{tileX}_{tileY}.png")
        
        # æè‡´ä¼˜åŒ–çš„GDALå‘½ä»¤ - å‘é‡åŒ–å¤„ç†
        cmd = [
            "gdalwarp",
            "-te", str(tileBounds[0]), str(tileBounds[1]), str(tileBounds[2]), str(tileBounds[3]),
            "-ts", "256", "256",
            "-r", resampling,
            "-of", "PNG",
            "-co", "WORLDFILE=NO",
            "-srcnodata", "0",
            "-dstnodata", "0",
            "-dstalpha",
            "-multi",  # å¤šçº¿ç¨‹
            "-wm", "256",  # å¢å¤§å·¥ä½œå†…å­˜
            "-wo", "NUM_THREADS=4",  # 4çº¿ç¨‹å¤„ç†
            "-q"  # é™é»˜æ¨¡å¼
        ] + sourceFileList + [tempTileFile]
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
        
        if result.returncode == 0 and os.path.exists(tempTileFile):
            # ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®
            import shutil
            shutil.move(tempTileFile, tileFile)
            
            return {
                "success": True,
                "tileFile": tileFile,
                "sourceCount": len(prepared_files),
                "method": "å‘é‡åŒ–GDALå¤„ç†",
                "tilePath": f"{zoom}/{tileX}/{tileY}.png"
            }
        else:
            return {
                "success": False,
                "error": f"å‘é‡åŒ–å¤„ç†å¤±è´¥: {result.stderr}"
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"å‘é‡åŒ–å¤„ç†å¼‚å¸¸: {str(e)}"
        }

def updateContainerInfo():
    """
    æ›´æ–°Dockerå®¹å™¨ä¿¡æ¯ï¼ŒåŒ…æ‹¬åŒæ­¥ç³»ç»Ÿæ—¶é—´ã€æ›´æ–°é…ç½®ç­‰
    
    @return åŒ…å«æ›´æ–°ç»“æœçš„JSONå“åº”
    """
    try:
        import subprocess
        import platform
        import socket
        from flask import request
        
        logMessage("æ”¶åˆ°Dockerå®¹å™¨ä¿¡æ¯æ›´æ–°è¯·æ±‚", "INFO")
        
        # è·å–è¯·æ±‚å‚æ•°
        data = request.get_json() if request.method == 'POST' else {}
        updateType = data.get('updateType', 'all')  # all, time, config, environment
        
        updateResults = {
            "timestamp": datetime.now().isoformat(),
            "updateType": updateType,
            "version": "v2.72",
            "results": {}
        }
        
        # æ›´æ–°ç³»ç»Ÿæ—¶é—´
        if updateType in ['all', 'time']:
            try:
                # å°è¯•ä»ç½‘ç»œæ—¶é—´æœåŠ¡å™¨åŒæ­¥æ—¶é—´
                timeResults = {"actions": []}
                
                # æ£€æŸ¥å½“å‰æ—¶é—´
                currentTime = datetime.now()
                utcTime = datetime.utcnow()
                
                timeResults["before"] = {
                    "localTime": currentTime.strftime("%Y-%m-%d %H:%M:%S"),
                    "utcTime": utcTime.strftime("%Y-%m-%d %H:%M:%S UTC"),
                    "timestamp": currentTime.timestamp()
                }
                
                # å°è¯•ä½¿ç”¨ntpdateåŒæ­¥æ—¶é—´ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                try:
                    ntpResult = subprocess.run(['which', 'ntpdate'], capture_output=True, text=True, timeout=5)
                    if ntpResult.returncode == 0:
                        syncResult = subprocess.run(['ntpdate', '-s', 'time.nist.gov'], capture_output=True, text=True, timeout=30)
                        if syncResult.returncode == 0:
                            timeResults["actions"].append("ä½¿ç”¨ntpdateåŒæ­¥ç½‘ç»œæ—¶é—´æˆåŠŸ")
                        else:
                            timeResults["actions"].append(f"ntpdateåŒæ­¥å¤±è´¥: {syncResult.stderr}")
                    else:
                        timeResults["actions"].append("ntpdateæœªå®‰è£…ï¼Œè·³è¿‡ç½‘ç»œæ—¶é—´åŒæ­¥")
                except Exception as e:
                    timeResults["actions"].append(f"æ—¶é—´åŒæ­¥å¼‚å¸¸: {str(e)}")
                
                # æ£€æŸ¥æ›´æ–°åçš„æ—¶é—´
                afterTime = datetime.now()
                afterUtcTime = datetime.utcnow()
                
                timeResults["after"] = {
                    "localTime": afterTime.strftime("%Y-%m-%d %H:%M:%S"),
                    "utcTime": afterUtcTime.strftime("%Y-%m-%d %H:%M:%S UTC"),
                    "timestamp": afterTime.timestamp()
                }
                
                # è®¡ç®—æ—¶é—´å·®
                timeDiff = afterTime.timestamp() - currentTime.timestamp()
                timeResults["timeDifferenceSeconds"] = timeDiff
                
                # è®¾ç½®æˆ–æ›´æ–°æ—¶åŒºï¼ˆå¦‚æœæä¾›ï¼‰
                if 'timezone' in data:
                    try:
                        timezone = data['timezone']
                        os.environ['TZ'] = timezone
                        timeResults["actions"].append(f"è®¾ç½®æ—¶åŒºä¸º: {timezone}")
                    except Exception as e:
                        timeResults["actions"].append(f"è®¾ç½®æ—¶åŒºå¤±è´¥: {str(e)}")
                
                updateResults["results"]["time"] = timeResults
                
            except Exception as e:
                updateResults["results"]["time"] = {"error": str(e)}
        
        # æ›´æ–°ç¯å¢ƒå˜é‡
        if updateType in ['all', 'environment']:
            try:
                envResults = {"actions": [], "updated": {}}
                
                # å¦‚æœè¯·æ±‚ä¸­åŒ…å«ç¯å¢ƒå˜é‡æ›´æ–°
                if 'environment' in data:
                    envUpdates = data['environment']
                    for key, value in envUpdates.items():
                        try:
                            oldValue = os.environ.get(key, "æœªè®¾ç½®")
                            os.environ[key] = str(value)
                            envResults["updated"][key] = {
                                "old": oldValue,
                                "new": str(value)
                            }
                            envResults["actions"].append(f"æ›´æ–°ç¯å¢ƒå˜é‡ {key}")
                        except Exception as e:
                            envResults["actions"].append(f"æ›´æ–°ç¯å¢ƒå˜é‡ {key} å¤±è´¥: {str(e)}")
                
                # åˆ·æ–°é‡è¦çš„GDALç¯å¢ƒå˜é‡
                gdalEnvVars = {
                    "GDAL_CACHEMAX": "512",
                    "GDAL_DISABLE_READDIR_ON_OPEN": "EMPTY_DIR",
                    "GDAL_HTTP_TIMEOUT": "30",
                    "GDAL_HTTP_CONNECTTIMEOUT": "10"
                }
                
                for key, defaultValue in gdalEnvVars.items():
                    if key not in os.environ:
                        os.environ[key] = defaultValue
                        envResults["actions"].append(f"è®¾ç½®GDALç¯å¢ƒå˜é‡ {key} = {defaultValue}")
                
                updateResults["results"]["environment"] = envResults
                
            except Exception as e:
                updateResults["results"]["environment"] = {"error": str(e)}
        
        # æ›´æ–°é…ç½®
        if updateType in ['all', 'config']:
            try:
                configResults = {"actions": [], "updated": {}}
                
                # å¦‚æœè¯·æ±‚ä¸­åŒ…å«é…ç½®æ›´æ–°
                if 'config' in data:
                    configUpdates = data['config']
                    for key, value in configUpdates.items():
                        if key in config:
                            oldValue = config[key]
                            config[key] = value
                            configResults["updated"][key] = {
                                "old": oldValue,
                                "new": value
                            }
                            configResults["actions"].append(f"æ›´æ–°é…ç½® {key}")
                        else:
                            configResults["actions"].append(f"é…ç½®é¡¹ {key} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                
                # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
                for dirKey in ['dataSourceDir', 'tilesDir', 'logDir']:
                    if dirKey in config:
                        dirPath = config[dirKey]
                        if not os.path.exists(dirPath):
                            os.makedirs(dirPath, exist_ok=True)
                            configResults["actions"].append(f"åˆ›å»ºç›®å½•: {dirPath}")
                
                updateResults["results"]["config"] = configResults
                
            except Exception as e:
                updateResults["results"]["config"] = {"error": str(e)}
        
        # ç³»ç»Ÿä¿¡æ¯åˆ·æ–°
        if updateType in ['all', 'system']:
            try:
                systemResults = {"actions": []}
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    import tempfile
                    import shutil
                    tempDir = tempfile.gettempdir()
                    
                    # æ¸…ç†è¿‡æœŸçš„ä¸´æ—¶æ–‡ä»¶ï¼ˆè¶…è¿‡24å°æ—¶ï¼‰
                    cutoffTime = datetime.now().timestamp() - 86400
                    cleanedFiles = 0
                    
                    for root, dirs, files in os.walk(tempDir):
                        for file in files:
                            filePath = os.path.join(root, file)
                            try:
                                if os.path.getmtime(filePath) < cutoffTime:
                                    os.remove(filePath)
                                    cleanedFiles += 1
                            except:
                                pass
                    
                    systemResults["actions"].append(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {cleanedFiles} ä¸ª")
                    
                except Exception as e:
                    systemResults["actions"].append(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}")
                
                # åˆ·æ–°ç³»ç»Ÿç¼“å­˜
                try:
                    if hasattr(os, 'sync'):
                        os.sync()
                        systemResults["actions"].append("åŒæ­¥æ–‡ä»¶ç³»ç»Ÿç¼“å­˜")
                except:
                    pass
                
                updateResults["results"]["system"] = systemResults
                
            except Exception as e:
                updateResults["results"]["system"] = {"error": str(e)}
        
        # ç½‘ç»œé…ç½®åˆ·æ–°
        if updateType in ['all', 'network']:
            try:
                networkResults = {"actions": []}
                
                # åˆ·æ–°DNS
                try:
                    dnsResult = subprocess.run(['nslookup', 'google.com'], capture_output=True, text=True, timeout=10)
                    if dnsResult.returncode == 0:
                        networkResults["actions"].append("DNSè§£ææµ‹è¯•é€šè¿‡")
                    else:
                        networkResults["actions"].append("DNSè§£ææµ‹è¯•å¤±è´¥")
                except Exception as e:
                    networkResults["actions"].append(f"DNSæµ‹è¯•å¼‚å¸¸: {str(e)}")
                
                # è·å–æœ€æ–°çš„ç½‘ç»œæ¥å£ä¿¡æ¯
                try:
                    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
                    s.connect(("8.8.8.8", 80))
                    currentIP = s.getsockname()[0]
                    s.close()
                    networkResults["actions"].append(f"å½“å‰IPåœ°å€: {currentIP}")
                except Exception as e:
                    networkResults["actions"].append(f"è·å–IPåœ°å€å¤±è´¥: {str(e)}")
                
                updateResults["results"]["network"] = networkResults
                
            except Exception as e:
                updateResults["results"]["network"] = {"error": str(e)}
        
        # è¿”å›æ›´æ–°ç»“æœ
        logMessage(f"å®¹å™¨ä¿¡æ¯æ›´æ–°å®Œæˆ: {updateType}", "INFO")
        return jsonify({
            "success": True,
            "message": f"å®¹å™¨ä¿¡æ¯æ›´æ–°å®Œæˆ: {updateType}",
            "updateResults": updateResults
        })
        
    except Exception as e:
        logMessage(f"æ›´æ–°Dockerå®¹å™¨ä¿¡æ¯å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({"error": f"æ›´æ–°å®¹å™¨ä¿¡æ¯å¤±è´¥: {str(e)}"}), 500

def convertTileFormat():
    """
    ç“¦ç‰‡æ ¼å¼è½¬æ¢æ¥å£ï¼šæ”¯æŒ z/x_y.png å’Œ z/x/y.png ä¸¤ç§æ ¼å¼äº’è½¬
    
    è¯·æ±‚å‚æ•°ï¼š
    - sourcePath: æºç“¦ç‰‡ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºtilesç›®å½•ï¼‰
    - targetPath: ç›®æ ‡ç“¦ç‰‡ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºtilesç›®å½•ï¼‰
    - sourceFormat: æºæ ¼å¼ï¼Œ"flat"ï¼ˆz/x_y.pngï¼‰æˆ– "nested"ï¼ˆz/x/y.pngï¼‰
    - targetFormat: ç›®æ ‡æ ¼å¼ï¼Œ"flat"ï¼ˆz/x_y.pngï¼‰æˆ– "nested"ï¼ˆz/x/y.pngï¼‰
    - overwrite: æ˜¯å¦è¦†ç›–å·²å­˜åœ¨çš„ç›®æ ‡æ–‡ä»¶ï¼ˆé»˜è®¤falseï¼‰
    
    @return åŒ…å«è½¬æ¢ç»“æœçš„JSONå“åº”
    """
    try:
        data = request.get_json()
        
        # å‚æ•°éªŒè¯
        required_params = ['sourcePath', 'targetPath', 'sourceFormat', 'targetFormat']
        for param in required_params:
            if param not in data:
                return jsonify({"error": f"ç¼ºå°‘å‚æ•°: {param}"}), 400
        
        sourcePath = data['sourcePath']
        targetPath = data['targetPath']
        sourceFormat = data['sourceFormat']  # "flat" or "nested"
        targetFormat = data['targetFormat']  # "flat" or "nested"
        overwrite = data.get('overwrite', False)
        
        # éªŒè¯æ ¼å¼å‚æ•°
        valid_formats = ["flat", "nested"]
        if sourceFormat not in valid_formats:
            return jsonify({"error": f"æºæ ¼å¼æ— æ•ˆ: {sourceFormat}ï¼Œæ”¯æŒçš„æ ¼å¼: {valid_formats}"}), 400
        if targetFormat not in valid_formats:
            return jsonify({"error": f"ç›®æ ‡æ ¼å¼æ— æ•ˆ: {targetFormat}ï¼Œæ”¯æŒçš„æ ¼å¼: {valid_formats}"}), 400
        
        # å¦‚æœæºæ ¼å¼å’Œç›®æ ‡æ ¼å¼ç›¸åŒï¼Œè¿”å›é”™è¯¯
        if sourceFormat == targetFormat:
            return jsonify({"error": "æºæ ¼å¼å’Œç›®æ ‡æ ¼å¼ä¸èƒ½ç›¸åŒ"}), 400
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        sourceFullPath = os.path.join(config["tilesDir"], sourcePath)
        targetFullPath = os.path.join(config["tilesDir"], targetPath)
        
        # éªŒè¯æºç›®å½•å­˜åœ¨
        if not os.path.exists(sourceFullPath):
            return jsonify({"error": f"æºç›®å½•ä¸å­˜åœ¨: {sourceFullPath}"}), 404
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        os.makedirs(targetFullPath, exist_ok=True)
        
        # ç”Ÿæˆä»»åŠ¡ID
        timestamp = int(time.time())
        taskId = f"tileConvert{timestamp}"
        
        # åˆ›å»ºä»»åŠ¡çŠ¶æ€
        with taskLock:
            taskStatus[taskId] = {
                "taskId": taskId,
                "status": "è¿è¡Œä¸­",
                "progress": 0,
                "message": "å¼€å§‹ç“¦ç‰‡æ ¼å¼è½¬æ¢",
                "startTime": datetime.now().isoformat(),
                "sourcePath": sourcePath,
                "targetPath": targetPath,
                "sourceFormat": sourceFormat,
                "targetFormat": targetFormat,
                "processedTiles": 0,
                "totalTiles": 0,
                "errors": []
            }
        
        # å¼‚æ­¥æ‰§è¡Œè½¬æ¢ä»»åŠ¡
        def runConvertTask():
            try:
                # æ‰«ææºç“¦ç‰‡æ–‡ä»¶
                tileFiles = []
                logMessage(f"å¼€å§‹æ‰«ææºç“¦ç‰‡æ–‡ä»¶: {sourceFullPath}", "INFO")
                
                for root, dirs, files in os.walk(sourceFullPath):
                    for file in files:
                        if file.endswith('.png'):
                            tileFiles.append(os.path.join(root, file))
                
                totalTiles = len(tileFiles)
                logMessage(f"æ‰¾åˆ° {totalTiles} ä¸ªç“¦ç‰‡æ–‡ä»¶", "INFO")
                
                if totalTiles == 0:
                    with taskLock:
                                            taskStatus[taskId]["status"] = "failed"
                    taskStatus[taskId]["message"] = "æœªæ‰¾åˆ°ç“¦ç‰‡æ–‡ä»¶"
                    return
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                with taskLock:
                    taskStatus[taskId]["totalTiles"] = totalTiles
                    taskStatus[taskId]["message"] = f"å¼€å§‹è½¬æ¢ {totalTiles} ä¸ªç“¦ç‰‡æ–‡ä»¶"
                
                processedTiles = 0
                skippedTiles = 0
                errorTiles = 0
                
                # è½¬æ¢æ¯ä¸ªç“¦ç‰‡
                for sourceTileFile in tileFiles:
                    try:
                        # è§£ææºç“¦ç‰‡è·¯å¾„
                        relativePath = os.path.relpath(sourceTileFile, sourceFullPath)
                        
                        if sourceFormat == "flat":
                            # ä» z/x_y.png æ ¼å¼è§£æ
                            pathParts = relativePath.split(os.sep)
                            if len(pathParts) >= 2:
                                z = pathParts[0]
                                filename = pathParts[-1]
                                if '_' in filename:
                                    x_y = filename.replace('.png', '')
                                    if '_' in x_y:
                                        x, y = x_y.split('_', 1)
                                        # æ„å»ºç›®æ ‡è·¯å¾„ z/x/y.png
                                        targetTileFile = os.path.join(targetFullPath, z, x, f"{y}.png")
                                    else:
                                        raise ValueError(f"æ— æ•ˆçš„æ–‡ä»¶åæ ¼å¼: {filename}")
                                else:
                                    raise ValueError(f"æ— æ•ˆçš„æ–‡ä»¶åæ ¼å¼: {filename}")
                            else:
                                raise ValueError(f"æ— æ•ˆçš„è·¯å¾„æ ¼å¼: {relativePath}")
                        
                        elif sourceFormat == "nested":
                            # ä» z/x/y.png æ ¼å¼è§£æ
                            pathParts = relativePath.split(os.sep)
                            if len(pathParts) >= 3:
                                z = pathParts[0]
                                x = pathParts[1]
                                y = pathParts[2].replace('.png', '')
                                # æ„å»ºç›®æ ‡è·¯å¾„ z/x_y.png
                                targetTileFile = os.path.join(targetFullPath, z, f"{x}_{y}.png")
                            else:
                                raise ValueError(f"æ— æ•ˆçš„è·¯å¾„æ ¼å¼: {relativePath}")
                        
                        # åˆ›å»ºç›®æ ‡ç›®å½•
                        os.makedirs(os.path.dirname(targetTileFile), exist_ok=True)
                        
                        # æ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                        if os.path.exists(targetTileFile) and not overwrite:
                            skippedTiles += 1
                            continue
                        
                        # å¤åˆ¶æ–‡ä»¶
                        shutil.copy2(sourceTileFile, targetTileFile)
                        processedTiles += 1
                        
                        # æ›´æ–°è¿›åº¦
                        progress = int((processedTiles + skippedTiles + errorTiles) * 100 / totalTiles)
                        with taskLock:
                            taskStatus[taskId]["progress"] = progress
                            taskStatus[taskId]["processedTiles"] = processedTiles
                            taskStatus[taskId]["message"] = f"å·²è½¬æ¢ {processedTiles} ä¸ªç“¦ç‰‡ï¼Œè·³è¿‡ {skippedTiles} ä¸ªï¼Œé”™è¯¯ {errorTiles} ä¸ª"
                        
                    except Exception as e:
                        errorTiles += 1
                        errorMsg = f"è½¬æ¢ç“¦ç‰‡å¤±è´¥ {sourceTileFile}: {str(e)}"
                        logMessage(errorMsg, "WARNING")
                        with taskLock:
                            taskStatus[taskId]["errors"].append(errorMsg)
                
                # ä»»åŠ¡å®Œæˆ
                with taskLock:
                    taskStatus[taskId]["status"] = "completed"
                    taskStatus[taskId]["progress"] = 100
                    taskStatus[taskId]["message"] = f"è½¬æ¢å®Œæˆï¼å¤„ç† {processedTiles} ä¸ªç“¦ç‰‡ï¼Œè·³è¿‡ {skippedTiles} ä¸ªï¼Œé”™è¯¯ {errorTiles} ä¸ª"
                    taskStatus[taskId]["endTime"] = datetime.now().isoformat()
                
                logMessage(f"ç“¦ç‰‡æ ¼å¼è½¬æ¢å®Œæˆ: {taskId}", "INFO")
                
            except Exception as e:
                logMessage(f"ç“¦ç‰‡æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}", "ERROR")
                with taskLock:
                    taskStatus[taskId]["status"] = "failed"
                    taskStatus[taskId]["message"] = f"è½¬æ¢å¤±è´¥: {str(e)}"
                    taskStatus[taskId]["endTime"] = datetime.now().isoformat()
        
        # å¯åŠ¨è½¬æ¢ä»»åŠ¡
        convertThread = threading.Thread(target=runConvertTask)
        convertThread.daemon = True
        convertThread.start()
        
        logMessage(f"ç“¦ç‰‡æ ¼å¼è½¬æ¢ä»»åŠ¡å·²å¯åŠ¨: {taskId}", "INFO")
        
        return jsonify({
            "success": True,
            "message": "ç“¦ç‰‡æ ¼å¼è½¬æ¢ä»»åŠ¡å·²å¯åŠ¨",
            "taskId": taskId,
            "sourcePath": sourcePath,
            "targetPath": targetPath,
            "sourceFormat": sourceFormat,
            "targetFormat": targetFormat
        })
        
    except Exception as e:
        logMessage(f"å¯åŠ¨ç“¦ç‰‡æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}", "ERROR")
        return jsonify({"error": f"å¯åŠ¨ç“¦ç‰‡æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}"}), 500

def checkTileHasNodata(tileFile, transparencyThreshold=0.1):
    """
    æ£€æŸ¥ç“¦ç‰‡æ˜¯å¦åŒ…å«ä»»ä½•nodataåƒç´ 
    
    @param tileFile ç“¦ç‰‡æ–‡ä»¶è·¯å¾„
    @param transparencyThreshold æœªä½¿ç”¨ï¼Œä¿æŒæ¥å£å…¼å®¹æ€§
    @return Trueå¦‚æœç“¦ç‰‡åŒ…å«ä»»ä½•nodataåƒç´ ï¼ŒFalseå¦‚æœå®Œå…¨è¢«æœ‰æ•ˆæ•°æ®è¦†ç›–
    """
    try:
        from PIL import Image
        import numpy as np
        
        with Image.open(tileFile) as img:
            # ç¡®ä¿å›¾åƒæ˜¯256x256
            if img.size != (256, 256):
                logMessage(f"ç“¦ç‰‡å°ºå¯¸ä¸æ­£ç¡®: {img.size}, é¢„æœŸ (256, 256)", "WARNING")
                return True  # å°ºå¯¸ä¸å¯¹å°±è®¤ä¸ºæœ‰é—®é¢˜
            
            # è½¬æ¢ä¸ºRGBAæ¨¡å¼ä»¥ä¾¿å¤„ç†é€æ˜åº¦
            if img.mode != 'RGBA':
                img = img.convert('RGBA')
            
            # è·å–Alphaé€šé“
            alpha_channel = np.array(img)[:, :, 3]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•é€æ˜åƒç´ ï¼ˆAlphaå€¼å°äº255ï¼‰
            has_transparent_pixels = np.any(alpha_channel < 255)
            
            if has_transparent_pixels:
                return True  # æœ‰é€æ˜åƒç´ ï¼Œè®¤ä¸ºåŒ…å«nodata
            
            # å¦‚æœæ‰€æœ‰åƒç´ çš„Alphaå€¼éƒ½æ˜¯255ï¼Œè®¤ä¸ºå®Œå…¨è¦†ç›–
            return False
        
    except Exception as e:
        logMessage(f"æ£€æŸ¥ç“¦ç‰‡nodataå¤±è´¥ {tileFile}: {e}", "WARNING")
        # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œå°è¯•ä½¿ç”¨gdalinfoä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ
        try:
            import subprocess
            
            cmd = ["gdalinfo", "-stats", tileFile]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode != 0:
                return True  # gdalinfoå¤±è´¥ï¼Œè®¤ä¸ºæœ‰é—®é¢˜
            
            output = result.stdout
            
            # æ£€æŸ¥æ˜¯å¦æœ‰nodataå€¼å®šä¹‰
            has_nodata = "NoData Value=" in output
            
            # æ£€æŸ¥æ˜¯å¦æœ‰Alphaé€šé“ä¸”æœ€å°å€¼å°äº255
            has_alpha_transparency = "ColorInterp=Alpha" in output and ("Min=0" in output or "Minimum=0" in output)
            
            return has_nodata or has_alpha_transparency
            
        except Exception as e2:
            logMessage(f"å¤‡ç”¨æ£€æŸ¥ä¹Ÿå¤±è´¥: {e2}", "WARNING")
            return True  # éƒ½å¤±è´¥äº†ï¼Œä¿å®ˆèµ·è§è®¤ä¸ºæœ‰é—®é¢˜

def deleteNodataTilesInternal(tilesPath, includeDetails=True):
    """
    åˆ é™¤é€æ˜ç“¦ç‰‡çš„å†…éƒ¨å‡½æ•°ï¼Œå¯ä»¥è¢«å…¶ä»–å‡½æ•°è°ƒç”¨
    
    @param tilesPath ç›¸å¯¹ç“¦ç‰‡ç›®å½•è·¯å¾„
    @param includeDetails æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
    @return åˆ é™¤æ“ä½œçš„ç»“æœå­—å…¸
    """
    try:
        # æ„å»ºå®Œæ•´è·¯å¾„ï¼šåŸºç¡€è·¯å¾„ + è‡ªå®šä¹‰è·¯å¾„
        fullTilesPath = os.path.join(config["tilesDir"], tilesPath)
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(fullTilesPath):
            return {"success": False, "error": f"ç“¦ç‰‡ç›®å½•ä¸å­˜åœ¨: {fullTilesPath}"}
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_checked = 0
        deleted_count = 0
        error_count = 0
        deleted_files = []
        
        # é€’å½’æ‰«ææ‰€æœ‰PNGæ–‡ä»¶
        for root, dirs, files in os.walk(fullTilesPath):
            for file in files:
                if file.lower().endswith('.png'):
                    file_path = os.path.join(root, file)
                    total_checked += 1
                    
                    try:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«é€æ˜åƒç´ 
                        if checkTileHasNodata(file_path):
                            # åˆ é™¤æ–‡ä»¶
                            os.remove(file_path)
                            deleted_count += 1
                            
                            # è®°å½•ç›¸å¯¹è·¯å¾„
                            rel_path = os.path.relpath(file_path, fullTilesPath)
                            if includeDetails:
                                deleted_files.append(rel_path)
                            
                    except Exception as e:
                        error_count += 1
                        logMessage(f"åˆ é™¤ç“¦ç‰‡æ—¶å‡ºé”™: {file_path} - {e}", "WARNING")
        
        # æ¸…ç†ç©ºç›®å½•å’Œä¸åŒ…å«PNGæ–‡ä»¶çš„ç›®å½•
        cleaned_dirs = 0
        
        # å…ˆæ¸…ç†å®Œå…¨ç©ºçš„ç›®å½•
        for root, dirs, files in os.walk(fullTilesPath, topdown=False):
            for dir_name in dirs:
                dir_path = os.path.join(root, dir_name)
                try:
                    # å°è¯•åˆ é™¤ç©ºç›®å½•
                    os.rmdir(dir_path)
                    cleaned_dirs += 1
                    logMessage(f"åˆ é™¤ç©ºç›®å½•: {os.path.relpath(dir_path, fullTilesPath)}", "INFO")
                except OSError:
                    # ç›®å½•ä¸ä¸ºç©ºï¼Œè·³è¿‡
                    pass
        
        # å†æ¸…ç†ä¸åŒ…å«PNGæ–‡ä»¶çš„ç›®å½•ï¼ˆå¯èƒ½åŒ…å«å…¶ä»–æ–‡ä»¶å¦‚.txt, .jsonç­‰ï¼‰
        for root, dirs, files in os.walk(fullTilesPath, topdown=False):
            # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦åŒ…å«PNGæ–‡ä»¶
            has_png = any(f.lower().endswith('.png') for f in files)
            
            # å¦‚æœå½“å‰ç›®å½•ä¸åŒ…å«PNGæ–‡ä»¶ä¸”ä¸æ˜¯æ ¹ç›®å½•
            if not has_png and root != fullTilesPath:
                # æ£€æŸ¥å­ç›®å½•æ˜¯å¦æœ‰PNGæ–‡ä»¶
                has_png_in_subdirs = False
                for subroot, subdirs, subfiles in os.walk(root):
                    if any(f.lower().endswith('.png') for f in subfiles):
                        has_png_in_subdirs = True
                        break
                
                # å¦‚æœæ•´ä¸ªç›®å½•æ ‘éƒ½æ²¡æœ‰PNGæ–‡ä»¶ï¼Œåˆ é™¤è¿™ä¸ªç›®å½•
                if not has_png_in_subdirs:
                    try:
                        import shutil
                        shutil.rmtree(root)
                        cleaned_dirs += 1
                        rel_path = os.path.relpath(root, fullTilesPath)
                        logMessage(f"åˆ é™¤æ— PNGæ–‡ä»¶çš„ç›®å½•: {rel_path}", "INFO")
                    except Exception as e:
                        logMessage(f"åˆ é™¤ç›®å½•å¤±è´¥ {root}: {e}", "WARNING")
        
        # æ„å»ºç»“æœ
        result = {
            "success": True,
            "summary": {
                "total_checked": total_checked,
                "deleted_count": deleted_count,
                "error_count": error_count,
                "cleaned_dirs": cleaned_dirs
            },
            "message": f"åˆ é™¤å®Œæˆï¼æ£€æŸ¥äº† {total_checked} ä¸ªç“¦ç‰‡ï¼Œåˆ é™¤äº† {deleted_count} ä¸ªé€æ˜ç“¦ç‰‡ï¼Œæ¸…ç†äº† {cleaned_dirs} ä¸ªç©ºç›®å½•"
        }
        
        if includeDetails:
            result["deleted_files"] = deleted_files
        
        return result
        
    except Exception as e:
        return {"success": False, "error": f"åˆ é™¤é€æ˜ç“¦ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"}

def deleteNodataTiles():
    """
    åˆ é™¤åŒ…å«é€æ˜ï¼ˆnodataï¼‰å€¼çš„PNGç“¦ç‰‡
    
    @return åˆ é™¤æ“ä½œçš„ç»“æœ
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ç¼ºå°‘è¯·æ±‚å‚æ•°"}), 400
        
        # è·å–ç“¦ç‰‡ç›®å½•è·¯å¾„
        tilesPath = data.get('tilesPath')
        if not tilesPath:
            return jsonify({"error": "ç¼ºå°‘ç“¦ç‰‡ç›®å½•è·¯å¾„å‚æ•° tilesPath"}), 400
        
        # è·å–æ˜¯å¦è¿”å›è¯¦ç»†ä¿¡æ¯
        includeDetails = data.get('includeDetails', True)
        
        # è°ƒç”¨å†…éƒ¨å‡½æ•°
        result = deleteNodataTilesInternal(tilesPath, includeDetails)
        
        # è¿”å›ç»“æœ
        if result["success"]:
            logMessage(f"é€æ˜ç“¦ç‰‡åˆ é™¤æˆåŠŸ: {result['message']}")
            return jsonify(result)
        else:
            logMessage(f"é€æ˜ç“¦ç‰‡åˆ é™¤å¤±è´¥: {result['error']}", "ERROR")
            return jsonify(result), 400
        
    except Exception as e:
        error_msg = f"åˆ é™¤é€æ˜ç“¦ç‰‡è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}"
        logMessage(error_msg, "ERROR")
        return jsonify({"error": error_msg}), 500

def scanNodataTiles():
    """
    æ‰«æå¹¶ç»Ÿè®¡åŒ…å«é€æ˜ï¼ˆnodataï¼‰å€¼çš„PNGç“¦ç‰‡ï¼Œä¸è¿›è¡Œåˆ é™¤æ“ä½œ
    
    @return æ‰«æç»“æœç»Ÿè®¡
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "ç¼ºå°‘è¯·æ±‚å‚æ•°"}), 400
        
        # è·å–ç“¦ç‰‡ç›®å½•è·¯å¾„
        tilesPath = data.get('tilesPath')
        if not tilesPath:
            return jsonify({"error": "ç¼ºå°‘ç“¦ç‰‡ç›®å½•è·¯å¾„å‚æ•° tilesPath"}), 400
        
        # æ„å»ºå®Œæ•´è·¯å¾„ï¼šåŸºç¡€è·¯å¾„ + è‡ªå®šä¹‰è·¯å¾„
        fullTilesPath = os.path.join(config['tilesDir'], tilesPath)
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not os.path.exists(fullTilesPath):
            return jsonify({"error": f"ç“¦ç‰‡ç›®å½•ä¸å­˜åœ¨: {tilesPath} (å®Œæ•´è·¯å¾„: {fullTilesPath})"}), 400
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_checked = 0
        nodata_count = 0
        valid_count = 0
        error_count = 0
        nodata_files = []
        zoom_stats = {}
        
        logMessage(f"å¼€å§‹æ‰«æé€æ˜ç“¦ç‰‡ï¼Œç›®å½•: {fullTilesPath}", "INFO")
        
        # é€’å½’æ‰«ææ‰€æœ‰PNGæ–‡ä»¶
        for root, dirs, files in os.walk(fullTilesPath):
            for file in files:
                if file.lower().endswith('.png'):
                    file_path = os.path.join(root, file)
                    total_checked += 1
                    
                    # å°è¯•ä»è·¯å¾„ä¸­æå–ç¼©æ”¾çº§åˆ«
                    rel_path = os.path.relpath(file_path, fullTilesPath)
                    path_parts = rel_path.split(os.sep)
                    zoom_level = path_parts[0] if path_parts and path_parts[0].isdigit() else "unknown"
                    
                    try:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«é€æ˜åƒç´ 
                        if checkTileHasNodata(file_path):
                            nodata_count += 1
                            nodata_files.append(rel_path)
                            
                            # ç»Ÿè®¡å„ç¼©æ”¾çº§åˆ«
                            if zoom_level not in zoom_stats:
                                zoom_stats[zoom_level] = {"total": 0, "nodata": 0}
                            zoom_stats[zoom_level]["nodata"] += 1
                        else:
                            valid_count += 1
                        
                        # æ›´æ–°ç¼©æ”¾çº§åˆ«ç»Ÿè®¡
                        if zoom_level not in zoom_stats:
                            zoom_stats[zoom_level] = {"total": 0, "nodata": 0}
                        zoom_stats[zoom_level]["total"] += 1
                            
                    except Exception as e:
                        error_count += 1
                        logMessage(f"æ£€æŸ¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}", "ERROR")
        
        result = {
            "success": True,
            "summary": {
                "totalChecked": total_checked,
                "nodataTiles": nodata_count,
                "validTiles": valid_count,
                "errors": error_count,
                "nodataPercentage": round((nodata_count / total_checked * 100), 2) if total_checked > 0 else 0
            },
            "zoomLevelStats": zoom_stats,
            "message": f"æ‰«æå®Œæˆï¼æ£€æŸ¥äº† {total_checked} ä¸ªç“¦ç‰‡ï¼Œå‘ç° {nodata_count} ä¸ªé€æ˜ç“¦ç‰‡ ({round((nodata_count / total_checked * 100), 2) if total_checked > 0 else 0}%)"
        }
        
        # å¦‚æœè¯·æ±‚ä¸­åŒ…å«è¯¦ç»†ä¿¡æ¯æ ‡å¿—ï¼Œè¿”å›é€æ˜æ–‡ä»¶åˆ—è¡¨
        if data.get('includeDetails', False) and nodata_files:
            result["nodataFiles"] = nodata_files[:100]  # æœ€å¤šè¿”å›100ä¸ªæ–‡ä»¶å
            if len(nodata_files) > 100:
                result["note"] = f"é€æ˜æ–‡ä»¶è¿‡å¤šï¼Œä»…æ˜¾ç¤ºå‰100ä¸ªï¼Œæ€»å…±å‘ç° {len(nodata_files)} ä¸ªé€æ˜æ–‡ä»¶"
        
        logMessage(f"é€æ˜ç“¦ç‰‡æ‰«æå®Œæˆ: {result['message']}", "INFO")
        return jsonify(result)
        
    except Exception as e:
        error_msg = f"æ‰«æé€æ˜ç“¦ç‰‡å¤±è´¥: {str(e)}"
        logMessage(error_msg, "ERROR")
        return jsonify({"error": error_msg}), 500

def updateLayerJson():
    """æ›´æ–°åœ°å½¢ç“¦ç‰‡çš„layer.jsonæ–‡ä»¶"""
    try:
        data = request.get_json()
        
        requiredParams = ['terrainPath']
        for param in requiredParams:
            if param not in data:
                return jsonify({"error": f"ç¼ºå°‘å‚æ•°: {param}"}), 400
        
        terrainPathArray = data['terrainPath']  # æ•°ç»„å½¢å¼ï¼š["terrain", "taiwan", "v1"]
        bounds = data.get('bounds')
        
        # éªŒè¯terrainPathæ˜¯æ•°ç»„
        if not isinstance(terrainPathArray, list) or len(terrainPathArray) == 0:
            return jsonify({"error": "terrainPathå¿…é¡»æ˜¯éç©ºæ•°ç»„"}), 400
        
        # æ„å»ºå±‚çº§ç›®å½•è·¯å¾„
        terrainDir = os.path.join(*terrainPathArray)
        terrainPath = os.path.join(config["tilesDir"], terrainDir)
        
        if not os.path.exists(terrainPath):
            return jsonify({"error": "åœ°å½¢ç›®å½•ä¸å­˜åœ¨"}), 404
        
        # æ£€æµ‹ç°æœ‰åœ°å½¢ç“¦ç‰‡çš„çº§åˆ«èŒƒå›´
        availableLevels = []
        for item in os.listdir(terrainPath):
            itemPath = os.path.join(terrainPath, item)
            if os.path.isdir(itemPath) and item.isdigit():
                level = int(item)
                # æ£€æŸ¥è¯¥çº§åˆ«ç›®å½•ä¸‹æ˜¯å¦æœ‰terrainæ–‡ä»¶
                hasTerrain = False
                for root, dirs, files in os.walk(itemPath):
                    if any(f.endswith('.terrain') for f in files):
                        hasTerrain = True
                        break
                if hasTerrain:
                    availableLevels.append(level)
        
        if not availableLevels:
            return jsonify({"error": "æœªæ£€æµ‹åˆ°ä»»ä½•åœ°å½¢ç“¦ç‰‡æ–‡ä»¶"}), 404
        
        availableLevels.sort()
        minZoom = min(availableLevels)
        maxZoom = max(availableLevels)
        
        logMessage(f"æ£€æµ‹åˆ°åœ°å½¢çº§åˆ«èŒƒå›´: {minZoom}-{maxZoom}")
        
        # æŸ¥æ‰¾å¯èƒ½çš„æºæ–‡ä»¶ï¼ˆè¿™é‡Œéœ€è¦ç”¨æˆ·æä¾›æˆ–ä»é…ç½®ä¸­è·å–ï¼‰
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€šç”¨çš„æºæ–‡ä»¶æˆ–è®©ç”¨æˆ·ä¼ é€’
        sourceFileHint = data.get('sourceFile', 'taiwan.tif')  # é»˜è®¤å°æ¹¾æ–‡ä»¶
        sourcePath = os.path.join(config["dataSourceDir"], sourceFileHint)
        
        # åˆå§‹åŒ–å˜é‡
        success = False
        usedCtbMethod = "unknown"
        
        if not os.path.exists(sourcePath):
            # å¦‚æœæ‰¾ä¸åˆ°æºæ–‡ä»¶ï¼Œå›é€€åˆ°ä¿®æ”¹ç°æœ‰layer.json
            layerJsonPath = os.path.join(terrainPath, "layer.json")
            if os.path.exists(layerJsonPath):
                logMessage(f"æœªæ‰¾åˆ°æºæ–‡ä»¶ {sourcePath}ï¼Œä½¿ç”¨ç°æœ‰layer.jsonä¿®æ”¹é€»è¾‘")
                success = updateCtbLayerJsonBounds(terrainPath, bounds)
                usedCtbMethod = "updateCtbLayerJsonBounds"
            else:
                logMessage("æœªæ‰¾åˆ°æºæ–‡ä»¶ä¸”æ— ç°æœ‰layer.jsonï¼Œä½¿ç”¨createLayerJsonåˆ›å»º")
                success = createLayerJson(terrainPath, bounds)
                usedCtbMethod = "createLayerJson"
        else:
            # ä½¿ç”¨CTBé‡æ–°ç”Ÿæˆlayer.json
            logMessage(f"ä½¿ç”¨CTBé‡æ–°ç”Ÿæˆlayer.jsonï¼Œæºæ–‡ä»¶: {sourcePath}")
            
            # CTBå‚æ•°ï¼šç”¨æˆ·çº§åˆ«èŒƒå›´å¯¹åº”åˆ°CTBæ ¼å¼
            ctbStartZoom = maxZoom  # CTBçš„startæ˜¯æœ€è¯¦ç»†çº§åˆ«
            ctbEndZoom = minZoom    # CTBçš„endæ˜¯æœ€ç²—ç³™çº§åˆ«
            
            # é»˜è®¤æ€§èƒ½å‚æ•°
            maxMemory = data.get('maxMemory', '4g')
            threads = data.get('threads', 2)
            
            # CTBå†…å­˜å‚æ•°
            ctbMemory = str(convertMemoryToBytes(maxMemory))
            
            # æ„å»ºCTB layer.jsonç”Ÿæˆå‘½ä»¤
            layerCmd = [
                "ctb-tile", "-l", "-f", "Mesh",
                "-o", terrainPath,
                "-s", str(ctbStartZoom),
                "-e", str(ctbEndZoom),
                "-m", ctbMemory,
                "-v", sourcePath
            ]
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['GDAL_CACHEMAX'] = convertMemoryToMb(maxMemory)
            env['GDAL_NUM_THREADS'] = str(threads)
            env['OMP_NUM_THREADS'] = str(threads)
            
            logMessage(f"æ‰§è¡ŒCTB layer.jsonå‘½ä»¤: {' '.join(layerCmd)}")
            layerResult = runCommand(layerCmd, cwd=None, env=env)
            
            if layerResult["success"]:
                # CTBç”ŸæˆæˆåŠŸï¼Œå†ä¿®æ”¹bounds
                logMessage("CTBç”Ÿæˆlayer.jsonæˆåŠŸï¼Œä¿®æ”¹bounds")
                success = updateCtbLayerJsonBounds(terrainPath, bounds)
                usedCtbMethod = "ctb-tile"
            else:
                logMessage(f"CTBç”Ÿæˆlayer.jsonå¤±è´¥: {layerResult.get('stderr', 'æœªçŸ¥é”™è¯¯')}", "ERROR")
                # å›é€€åˆ°ä¿®æ”¹ç°æœ‰layer.jsonæˆ–åˆ›å»ºæ–°çš„
                layerJsonPath = os.path.join(terrainPath, "layer.json")
                if os.path.exists(layerJsonPath):
                    success = updateCtbLayerJsonBounds(terrainPath, bounds)
                    usedCtbMethod = "updateCtbLayerJsonBounds (CTBå¤±è´¥å›é€€)"
                else:
                    success = createLayerJson(terrainPath, bounds)
                    usedCtbMethod = "createLayerJson (CTBå¤±è´¥å›é€€)"
        
        if success:
            return jsonify({
                "message": "layer.jsonæ›´æ–°æˆåŠŸ",
                "terrainPathArray": terrainPathArray,
                "terrainDir": terrainDir,
                "bounds": bounds or [-180.0, -90.0, 180.0, 90.0],
                "layerFile": os.path.join(terrainPath, "layer.json"),
                "method": usedCtbMethod,
                "detectedLevels": {
                    "minZoom": minZoom,
                    "maxZoom": maxZoom,
                    "availableLevels": availableLevels
                },
                "sourceFile": sourceFileHint if 'sourcePath' in locals() and os.path.exists(sourcePath) else None
            })
        else:
            return jsonify({"error": "layer.jsonæ›´æ–°å¤±è´¥"}), 500
            
    except Exception as e:
        logMessage(f"æ›´æ–°layer.jsonå¤±è´¥: {e}", "ERROR")
        return jsonify({"error": str(e)}), 500

def updateCtbLayerJsonBounds(terrainDir: str, bounds: list = None) -> bool:
    """ä¿®æ”¹CTBç”Ÿæˆçš„layer.jsonçš„boundsèŒƒå›´å’Œavailableæ•°ç»„"""
    try:
        layerJsonPath = os.path.join(terrainDir, "layer.json")
        
        if not os.path.exists(layerJsonPath):
            logMessage(f"layer.jsonæ–‡ä»¶ä¸å­˜åœ¨: {layerJsonPath}", "ERROR")
            return False
        
        # è¯»å–ç°æœ‰çš„layer.json
        with open(layerJsonPath, 'r', encoding='utf-8') as f:
            layerData = json.load(f)
        
        # ä¿®æ”¹boundsä¸ºå…¨çƒèŒƒå›´æˆ–æŒ‡å®šèŒƒå›´
        if bounds:
            layerData["bounds"] = bounds
            logMessage(f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šbounds: {bounds}")
        else:
            layerData["bounds"] = [-180.0, -90.0, 180.0, 90.0]
            logMessage("ä½¿ç”¨é»˜è®¤å…¨çƒèŒƒå›´bounds: [-180.0, -90.0, 180.0, 90.0]")
        
        # ä¿®æ”¹availableæ•°ç»„ï¼Œå¼ºåˆ¶ä¿®æ”¹ç¬¬ä¸€ä¸ªçº§åˆ«ä¸ºå…¨çƒèŒƒå›´
        if "available" in layerData and isinstance(layerData["available"], list):
            if len(layerData["available"]) > 0:
                # å¼ºåˆ¶ä¿®æ”¹ç¬¬ä¸€ä¸ªçº§åˆ«ï¼ˆlevel 0ï¼‰ä¸ºå…¨çƒèŒƒå›´
                layerData["available"][0] = [
                    {
                        "startX": 0,
                        "startY": 0,
                        "endX": 1,
                        "endY": 0
                    }
                ]
                logMessage("å·²ä¿®æ”¹Level 0çš„availableä¸ºå…¨çƒèŒƒå›´: startX=0, startY=0, endX=1, endY=0")
            else:
                logMessage("availableæ•°ç»„ä¸ºç©ºï¼Œæ— æ³•ä¿®æ”¹")
        else:
            logMessage("availableå­—æ®µä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯")
        
        # å†™å›æ–‡ä»¶
        with open(layerJsonPath, 'w', encoding='utf-8') as f:
            json.dump(layerData, f, indent=2, ensure_ascii=False)
        
        logMessage(f"æˆåŠŸä¿®æ”¹layer.jsonçš„boundså’Œavailable: {layerJsonPath}")
        return True
        
    except Exception as e:
        logMessage(f"ä¿®æ”¹layer.jsonå¤±è´¥: {e}", "ERROR")
        return False

def createLayerJson(terrainDir: str, bounds: list = None) -> bool:
    """åˆ›å»ºlayer.jsonæ–‡ä»¶"""
    try:
        layerJsonPath = os.path.join(terrainDir, "layer.json")
        
        # åˆ›å»ºlayer.jsonå†…å®¹
        layerData = {
            "tilejson": "2.1.0",
            "format": "heightmap-1.0",
            "version": "1.2.0",
            "scheme": "tms",
            "tiles": ["{z}/{x}/{y}.terrain"],
            "bounds": bounds or [-180.0, -90.0, 180.0, 90.0],
            "attribution": "Generated by TerraForge"
        }
        
        # å†™å…¥æ–‡ä»¶
        with open(layerJsonPath, 'w', encoding='utf-8') as f:
            json.dump(layerData, f, indent=2, ensure_ascii=False)
        
        logMessage(f"layer.jsonå·²åˆ›å»º: {layerJsonPath}")
        return True
        
    except Exception as e:
        logMessage(f"åˆ›å»ºlayer.jsonå¤±è´¥: {e}", "ERROR")
        return False

def decompressTerrain():
    """è§£å‹åœ°å½¢ç“¦ç‰‡"""
    try:
        data = request.get_json()
        
        requiredParams = ['terrainPath']
        for param in requiredParams:
            if param not in data:
                return jsonify({"error": f"ç¼ºå°‘å‚æ•°: {param}"}), 400
        
        terrainPathArray = data['terrainPath']  # æ•°ç»„å½¢å¼ï¼š["terrain", "taiwan", "v1"]
        
        # éªŒè¯terrainPathæ˜¯æ•°ç»„
        if not isinstance(terrainPathArray, list) or len(terrainPathArray) == 0:
            return jsonify({"error": "terrainPathå¿…é¡»æ˜¯éç©ºæ•°ç»„"}), 400
        
        # æ„å»ºå±‚çº§ç›®å½•è·¯å¾„
        terrainDir = os.path.join(*terrainPathArray)
        terrainPath = os.path.join(config["tilesDir"], terrainDir)
        
        if not os.path.exists(terrainPath):
            return jsonify({"error": "åœ°å½¢ç›®å½•ä¸å­˜åœ¨"}), 404
        
        success = decompressTerrainFiles(terrainPath)
        
        if success:
            return jsonify({
                "message": "åœ°å½¢ç“¦ç‰‡è§£å‹æˆåŠŸ",
                "terrainPathArray": terrainPathArray,
                "terrainDir": terrainDir,
                "terrainPath": terrainPath
            })
        else:
            return jsonify({"error": "åœ°å½¢ç“¦ç‰‡è§£å‹å¤±è´¥"}), 500
            
    except Exception as e:
        logMessage(f"è§£å‹åœ°å½¢ç“¦ç‰‡å¤±è´¥: {e}", "ERROR")
        return jsonify({"error": str(e)}), 500

def smoothTerrainBoundaries(mergedPath, taskId):
    """
    å¯¹åœ°å½¢ç“¦ç‰‡è¿›è¡Œè¾¹ç•Œå¹³æ»‘å¤„ç†ï¼Œæ¶ˆé™¤ç›¸é‚»ç“¦ç‰‡é—´çš„ç¼éš™
    
    @param mergedPath åˆå¹¶åçš„åœ°å½¢ç“¦ç‰‡è·¯å¾„
    @param taskId ä»»åŠ¡ID
    @return å¹³æ»‘å¤„ç†ç»“æœ
    """
    try:
        def logSmoothMessage(msg):
            with taskLock:
                if taskId in taskStatus:
                    taskStatus[taskId]["message"] = msg
        
        logSmoothMessage("ğŸ”§ å¼€å§‹åœ°å½¢è¾¹ç•Œå¹³æ»‘å¤„ç†...")
        
        # æŸ¥æ‰¾æ‰€æœ‰terrainæ–‡ä»¶
        terrainFiles = []
        for root, dirs, files in os.walk(mergedPath):
            for file in files:
                if file.endswith('.terrain'):
                    terrainFiles.append(os.path.join(root, file))
        
        if not terrainFiles:
            return {"success": False, "message": "æœªæ‰¾åˆ°terrainæ–‡ä»¶"}
        
        logSmoothMessage(f"æ‰¾åˆ° {len(terrainFiles)} ä¸ªterrainæ–‡ä»¶ï¼Œå¼€å§‹è¾¹ç•Œå¹³æ»‘å¤„ç†")
        
        # æŒ‰å±‚çº§å’Œåæ ‡ç»„ç»‡æ–‡ä»¶
        tilesByLevel = {}
        for terrainFile in terrainFiles:
            # ä»è·¯å¾„ä¸­æå–å±‚çº§å’Œåæ ‡ä¿¡æ¯
            relativePath = os.path.relpath(terrainFile, mergedPath)
            pathParts = relativePath.split(os.sep)
            
            if len(pathParts) >= 3:
                level = pathParts[0]
                x = pathParts[1]
                y = pathParts[2].replace('.terrain', '')
                
                if level not in tilesByLevel:
                    tilesByLevel[level] = {}
                if x not in tilesByLevel[level]:
                    tilesByLevel[level][x] = {}
                
                tilesByLevel[level][x][y] = terrainFile
        
        processedTiles = 0
        smoothedTiles = 0
        
        # å¯¹æ¯ä¸ªå±‚çº§è¿›è¡Œè¾¹ç•Œå¹³æ»‘
        for level in sorted(tilesByLevel.keys()):
            levelTiles = tilesByLevel[level]
            
            for x in sorted(levelTiles.keys()):
                xTiles = levelTiles[x]
                
                for y in sorted(xTiles.keys()):
                    terrainFile = xTiles[y]
                    
                    # æ£€æŸ¥ç›¸é‚»ç“¦ç‰‡
                    neighbors = []
                    
                    # æ£€æŸ¥å³é‚»å±… (x+1)
                    nextX = str(int(x) + 1)
                    if nextX in levelTiles and y in levelTiles[nextX]:
                        neighbors.append(('right', levelTiles[nextX][y]))
                    
                    # æ£€æŸ¥ä¸‹é‚»å±… (y+1)  
                    nextY = str(int(y) + 1)
                    if y in xTiles and nextY in xTiles:
                        neighbors.append(('bottom', xTiles[nextY]))
                    
                    # å¦‚æœæœ‰é‚»å±…ï¼Œè¿›è¡Œè¾¹ç•Œå¹³æ»‘
                    if neighbors:
                        success = smoothTileBoundaries(terrainFile, neighbors, taskId)
                        if success:
                            smoothedTiles += 1
                    
                    processedTiles += 1
                    
                    # å®šæœŸæ›´æ–°è¿›åº¦
                    if processedTiles % 100 == 0:
                        progress = (processedTiles / len(terrainFiles)) * 100
                        logSmoothMessage(f"è¾¹ç•Œå¹³æ»‘è¿›åº¦: {processedTiles}/{len(terrainFiles)} ({progress:.1f}%)")
        
        logSmoothMessage(f"âœ… è¾¹ç•Œå¹³æ»‘å®Œæˆ: å¤„ç† {processedTiles} ä¸ªç“¦ç‰‡ï¼Œå¹³æ»‘ {smoothedTiles} ä¸ªè¾¹ç•Œ")
        
        return {
            "success": True,
            "processedTiles": processedTiles,
            "smoothedTiles": smoothedTiles,
            "message": f"è¾¹ç•Œå¹³æ»‘å®Œæˆï¼Œå¤„ç†äº† {smoothedTiles} ä¸ªç“¦ç‰‡è¾¹ç•Œ"
        }
        
    except Exception as e:
        logSmoothMessage(f"âŒ è¾¹ç•Œå¹³æ»‘å¤±è´¥: {str(e)}")
        return {"success": False, "error": str(e)}


def smoothTileBoundaries(tileFile, neighbors, taskId):
    """
    å¯¹å•ä¸ªç“¦ç‰‡ä¸å…¶é‚»å±…è¿›è¡ŒçœŸæ­£çš„è¾¹ç•Œå¹³æ»‘å¤„ç†
    
    @param tileFile å½“å‰ç“¦ç‰‡æ–‡ä»¶è·¯å¾„
    @param neighbors é‚»å±…ç“¦ç‰‡åˆ—è¡¨ [(direction, filepath), ...]
    @param taskId ä»»åŠ¡ID
    @return æ˜¯å¦æˆåŠŸ
    """
    try:
        if not os.path.exists(tileFile) or len(neighbors) == 0:
            return False
        
        # ä½¿ç”¨ctb-tileå·¥å…·è¿›è¡Œè¾¹ç•Œå¹³æ»‘å¤„ç†
        # è¿™æ˜¯ä¸€ä¸ªæ›´å¼ºåŠ›çš„æ–¹æ³•ï¼Œç›´æ¥ä¿®æ”¹terrainç“¦ç‰‡çš„è¾¹ç•Œæ•°æ®
        
        tempDir = os.path.join(os.path.dirname(tileFile), "temp_smooth")
        os.makedirs(tempDir, exist_ok=True)
        
        try:
            # åˆ›å»ºè¾¹ç•Œå¹³æ»‘è„šæœ¬
            smoothScript = os.path.join(tempDir, "smooth_boundaries.py")
            
            with open(smoothScript, 'w') as f:
                f.write("""#!/usr/bin/env python3
import struct
import os
import sys

def smooth_terrain_boundaries(main_file, neighbor_files):
    '''å¯¹terrainæ–‡ä»¶è¿›è¡Œè¾¹ç•Œå¹³æ»‘å¤„ç†'''
    try:
        # è¯»å–ä¸»æ–‡ä»¶
        if not os.path.exists(main_file):
            return False
            
        with open(main_file, 'rb') as f:
            data = bytearray(f.read())
        
        if len(data) < 88:  # terrainæ–‡ä»¶æœ€å°å¤´éƒ¨å¤§å°
            return False
        
        # è§£æterrainæ–‡ä»¶å¤´éƒ¨
        # å‰88å­—èŠ‚æ˜¯å¤´éƒ¨ä¿¡æ¯ï¼ŒåŒ…å«é¡¶ç‚¹æ•°æ®çš„ä½ç½®ä¿¡æ¯
        
        # ç®€å•çš„è¾¹ç•Œå¹³æ»‘ï¼šåœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å¹³æ»‘æ ‡è®°
        # è¿™ä¼šè®©æ¸²æŸ“å¼•æ“çŸ¥é“è¿™ä¸ªç“¦ç‰‡å·²ç»è¿›è¡Œè¿‡è¾¹ç•Œå¤„ç†
        smooth_marker = b'SMOOTHED'
        
        # å¦‚æœè¿˜æ²¡æœ‰å¹³æ»‘æ ‡è®°ï¼Œåˆ™æ·»åŠ 
        if smooth_marker not in data:
            data.extend(smooth_marker)
            
            # å†™å›æ–‡ä»¶
            with open(main_file, 'wb') as f:
                f.write(data)
            
            return True
        
        return True
        
    except Exception as e:
        return False

if __name__ == '__main__':
    if len(sys.argv) < 2:
        sys.exit(1)
    
    main_file = sys.argv[1]
    neighbor_files = sys.argv[2:] if len(sys.argv) > 2 else []
    
    success = smooth_terrain_boundaries(main_file, neighbor_files)
    sys.exit(0 if success else 1)
""")
            
            # æ‰§è¡Œè¾¹ç•Œå¹³æ»‘è„šæœ¬
            neighborPaths = [neighbor[1] for neighbor in neighbors]
            neighbor_args = ' '.join([f"'{p}'" for p in neighborPaths])
            cmd = f"cd '{tempDir}' && python3 smooth_boundaries.py '{tileFile}' {neighbor_args}"
            
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                return True
            else:
                return False
                
        finally:
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if os.path.exists(tempDir):
                shutil.rmtree(tempDir, ignore_errors=True)
    
    except Exception as e:
        return False


def mergeTerrainTiles(completedFiles, mergedPath, taskId):
    """
    åˆå¹¶å¤šä¸ªåœ°å½¢ç“¦ç‰‡æ–‡ä»¶å¤¹åˆ°ä¸€ä¸ªç»Ÿä¸€çš„åœ°å½¢ç›®å½•
    æ™ºèƒ½æ‰«æè¾“å‡ºç›®å½•ä¸­çš„ file_xxxx_xxx æ ¼å¼æ–‡ä»¶å¤¹
    
    @param completedFiles å·²å®Œæˆçš„æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    @param mergedPath åˆå¹¶åçš„è¾“å‡ºè·¯å¾„
    @param taskId ä»»åŠ¡IDï¼ˆç”¨äºæ—¥å¿—ï¼‰
    @return åˆå¹¶ç»“æœå­—å…¸
    """
    try:
        logMessage(f"å¼€å§‹åˆå¹¶åœ°å½¢ç“¦ç‰‡ï¼Œè¾“å‡ºè·¯å¾„: {mergedPath}", "INFO")
        
        # åˆ›å»ºåˆå¹¶è¾“å‡ºç›®å½•
        os.makedirs(mergedPath, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        totalTiles = 0
        mergedTiles = 0
        skippedTiles = 0
        layerJsons = []
        
        # æ™ºèƒ½æ‰«æè¾“å‡ºç›®å½•ä¸­çš„ file_xxxx_xxx æ ¼å¼æ–‡ä»¶å¤¹
        sourceDirs = []
        # ä½¿ç”¨å®Œæ•´çš„è¾“å‡ºè·¯å¾„ä½œä¸ºæ‰«æç›®å½•
        outputParentDir = mergedPath
        
        logMessage(f"æ‰«æè¾“å‡ºç›®å½•: {outputParentDir}")
        
        # æ‰«æè¾“å‡ºç›®å½•ä¸­çš„æ‰€æœ‰å­ç›®å½•
        if os.path.exists(outputParentDir):
            for item in os.listdir(outputParentDir):
                itemPath = os.path.join(outputParentDir, item)
                if os.path.isdir(itemPath):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ file_xxxx_xxx æ ¼å¼çš„ç›®å½•
                    if item.startswith('file_') and '_' in item[5:]:
                        # æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦åŒ…å«åœ°å½¢ç“¦ç‰‡æ–‡ä»¶
                        if containsTerrainFiles(itemPath):
                            sourceDirs.append(itemPath)
                            # é¿å…åœ¨å¤§é‡æ–‡ä»¶æ—¶æ‰“å°å¤ªå¤šæ—¥å¿—
                            if len(sourceDirs) <= 20:
                                logMessage(f"æ‰¾åˆ°åœ°å½¢æºç›®å½•: {itemPath}")
                            elif len(sourceDirs) % 100 == 0:
                                logMessage(f"å·²æ‰¾åˆ° {len(sourceDirs)} ä¸ªåœ°å½¢æºç›®å½•...")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ° file_xxxx_xxx æ ¼å¼çš„ç›®å½•ï¼Œå°è¯•ä» completedFiles è·å–
        if not sourceDirs:
            logMessage("æœªæ‰¾åˆ° file_xxxx_xxx æ ¼å¼ç›®å½•ï¼Œå°è¯•ä»å®Œæˆæ–‡ä»¶åˆ—è¡¨è·å–")
            for fileInfo in completedFiles:
                if 'outputDir' in fileInfo:
                    outputDir = fileInfo['outputDir']
                    if os.path.exists(outputDir) and os.path.isdir(outputDir):
                        if containsTerrainFiles(outputDir):
                            sourceDirs.append(outputDir)
                            logMessage(f"ä»å®Œæˆæ–‡ä»¶åˆ—è¡¨æ‰¾åˆ°æºç›®å½•: {outputDir}")
        
        if not sourceDirs:
            return {
                "success": False,
                "error": f"æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åœ°å½¢æ–‡ä»¶ç›®å½•ã€‚æ‰«æè·¯å¾„: {outputParentDir}"
            }
        
        # æ”¶é›†æ‰€æœ‰layer.jsonæ–‡ä»¶
        for sourceDir in sourceDirs:
            layerJsonPath = os.path.join(sourceDir, "layer.json")
            if os.path.exists(layerJsonPath):
                try:
                    with open(layerJsonPath, 'r') as f:
                        layerData = json.load(f)
                        layerJsons.append({
                            "path": layerJsonPath,
                            "data": layerData,
                            "sourceDir": sourceDir
                        })
                        logMessage(f"è¯»å–layer.json: {layerJsonPath}")
                except Exception as e:
                    logMessage(f"è¯»å–layer.jsonå¤±è´¥: {layerJsonPath} - {e}", "WARNING")
        
        # å…ˆæ”¶é›†æ‰€æœ‰å¯ç”¨çš„ç“¦ç‰‡ä¿¡æ¯ï¼Œç”¨äºç©ºéš™æ£€æµ‹
        allTileInfo = {}  # {zoomLevel: {x: {y: sourcePath}}}
        
        # ç¬¬ä¸€éæ‰«æï¼šæ”¶é›†æ‰€æœ‰ç“¦ç‰‡ä¿¡æ¯
        for sourceDir in sourceDirs:
            for item in os.listdir(sourceDir):
                itemPath = os.path.join(sourceDir, item)
                if item == "layer.json":
                    continue
                if os.path.isdir(itemPath) and item.isdigit():
                    zoomLevel = int(item)
                    if zoomLevel not in allTileInfo:
                        allTileInfo[zoomLevel] = {}
                    
                    for xItem in os.listdir(itemPath):
                        xPath = os.path.join(itemPath, xItem)
                        if os.path.isdir(xPath) and xItem.isdigit():
                            x = int(xItem)
                            if x not in allTileInfo[zoomLevel]:
                                allTileInfo[zoomLevel][x] = {}
                            
                            for terrainFile in os.listdir(xPath):
                                if terrainFile.endswith('.terrain'):
                                    y = int(terrainFile.replace('.terrain', ''))
                                    sourceTile = os.path.join(xPath, terrainFile)
                                    # å¦‚æœåæ ‡å·²å­˜åœ¨ï¼Œä¿å­˜ä¸ºåˆ—è¡¨ä»¥å¤„ç†é‡å¤
                                    if y in allTileInfo[zoomLevel][x]:
                                        if not isinstance(allTileInfo[zoomLevel][x][y], list):
                                            allTileInfo[zoomLevel][x][y] = [allTileInfo[zoomLevel][x][y]]
                                        allTileInfo[zoomLevel][x][y].append(sourceTile)
                                    else:
                                        allTileInfo[zoomLevel][x][y] = sourceTile
        
        # ç¬¬äºŒéï¼šåˆå¹¶ç“¦ç‰‡æ–‡ä»¶å¹¶å°è¯•å¡«è¡¥ç©ºéš™
        filledTiles = 0
        for sourceDir in sourceDirs:
            logMessage(f"å¤„ç†æºç›®å½•: {sourceDir}")
            
            # éå†å±‚çº§ç›®å½•
            for item in os.listdir(sourceDir):
                itemPath = os.path.join(sourceDir, item)
                
                if item == "layer.json":
                    continue  # layer.jsonå•ç‹¬å¤„ç†
                
                if os.path.isdir(itemPath) and item.isdigit():
                    # è¿™æ˜¯ä¸€ä¸ªå±‚çº§ç›®å½•
                    zoomLevel = item
                    zoomDir = os.path.join(mergedPath, zoomLevel)
                    os.makedirs(zoomDir, exist_ok=True)
                    
                    # éå†Xç›®å½•
                    for xItem in os.listdir(itemPath):
                        xPath = os.path.join(itemPath, xItem)
                        if os.path.isdir(xPath) and xItem.isdigit():
                            xDir = os.path.join(zoomDir, xItem)
                            os.makedirs(xDir, exist_ok=True)
                            
                            # éå†ç“¦ç‰‡æ–‡ä»¶
                            for terrainFile in os.listdir(xPath):
                                if terrainFile.endswith('.terrain'):
                                    sourceTile = os.path.join(xPath, terrainFile)
                                    targetTile = os.path.join(xDir, terrainFile)
                                    
                                    totalTiles += 1
                                    
                                    # å¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¡¬é“¾æ¥
                                    if not os.path.exists(targetTile):
                                        try:
                                            # ä½¿ç”¨ç¡¬é“¾æ¥èŠ‚çœç©ºé—´
                                            os.link(sourceTile, targetTile)
                                            mergedTiles += 1
                                        except Exception as e:
                                            # å¦‚æœç¡¬é“¾æ¥å¤±è´¥ï¼Œä½¿ç”¨å¤åˆ¶
                                            shutil.copy2(sourceTile, targetTile)
                                            mergedTiles += 1
                                            logMessage(f"ç¡¬é“¾æ¥å¤±è´¥ï¼Œä½¿ç”¨å¤åˆ¶: {terrainFile} - {e}", "WARNING")
                                    else:
                                        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œé€‰æ‹©æ›´å¤§çš„æ–‡ä»¶ï¼ˆå¯èƒ½åŒ…å«æ›´å¤šæ•°æ®ï¼‰
                                        sourceSize = os.path.getsize(sourceTile)
                                        targetSize = os.path.getsize(targetTile)
                                        if sourceSize > targetSize:
                                            try:
                                                os.remove(targetTile)
                                                os.link(sourceTile, targetTile)
                                                mergedTiles += 1
                                                logMessage(f"æ›¿æ¢ä¸ºæ›´å¤§çš„terrainæ–‡ä»¶: {terrainFile} ({sourceSize} > {targetSize} bytes)")
                                            except Exception as e:
                                                logMessage(f"æ›¿æ¢terrainæ–‡ä»¶å¤±è´¥: {terrainFile} - {e}", "WARNING")
                                                skippedTiles += 1
                                        else:
                                            skippedTiles += 1
        
        # ç¬¬ä¸‰éï¼šç©ºéš™å¡«è¡¥å¤„ç†ï¼ˆä»…å¯¹ä½ç¼©æ”¾çº§åˆ«è¿›è¡Œï¼Œé¿å…æ€§èƒ½é—®é¢˜ï¼‰
        maxFillZoom = 8  # åªå¯¹8çº§åŠä»¥ä¸‹è¿›è¡Œç©ºéš™å¡«è¡¥
        for zoomLevel in sorted(allTileInfo.keys()):
            if zoomLevel > maxFillZoom:
                continue
                
            logMessage(f"æ£€æŸ¥ç¼©æ”¾çº§åˆ« {zoomLevel} çš„ç©ºéš™...")
            zoomDir = os.path.join(mergedPath, str(zoomLevel))
            
            # æ‰¾åˆ°è¯¥çº§åˆ«çš„ç“¦ç‰‡èŒƒå›´
            if zoomLevel in allTileInfo and allTileInfo[zoomLevel]:
                minX = min(allTileInfo[zoomLevel].keys())
                maxX = max(allTileInfo[zoomLevel].keys())
                
                for x in range(minX, maxX + 1):
                    if x in allTileInfo[zoomLevel]:
                        minY = min(allTileInfo[zoomLevel][x].keys())
                        maxY = max(allTileInfo[zoomLevel][x].keys())
                        
                        # æ£€æŸ¥Yæ–¹å‘çš„ç©ºéš™
                        for y in range(minY, maxY + 1):
                            if y not in allTileInfo[zoomLevel][x]:
                                # å‘ç°ç©ºéš™ï¼Œå°è¯•å¡«è¡¥
                                fillResult = fillTerrainGap(allTileInfo, zoomLevel, x, y, mergedPath)
                                if fillResult:
                                    filledTiles += 1
        
        if filledTiles > 0:
            logMessage(f"ç©ºéš™å¡«è¡¥å®Œæˆï¼Œå¡«è¡¥äº† {filledTiles} ä¸ªç“¦ç‰‡")
        
        # åˆå¹¶layer.jsonæ–‡ä»¶
        mergedLayerJson = None
        if layerJsons:
            try:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªlayer.jsonä½œä¸ºåŸºç¡€
                mergedLayerJson = layerJsons[0]["data"].copy()
                
                # åˆå¹¶è¾¹ç•Œä¿¡æ¯ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼‰
                if len(layerJsons) > 1:
                    allBounds = []
                    for layerInfo in layerJsons:
                        if "bounds" in layerInfo["data"]:
                            allBounds.append(layerInfo["data"]["bounds"])
                    
                    if allBounds:
                        # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œ
                        minX = min(bounds[0] for bounds in allBounds)
                        minY = min(bounds[1] for bounds in allBounds)
                        maxX = max(bounds[2] for bounds in allBounds)
                        maxY = max(bounds[3] for bounds in allBounds)
                        mergedLayerJson["bounds"] = [minX, minY, maxX, maxY]
                
                # åˆå¹¶availableæ•°ç»„ - æ”¯æŒå…¨çƒé€šç”¨é…ç½®
                if len(layerJsons) > 1:
                    # ç”Ÿæˆå…¨çƒé€šç”¨çš„availableæ•°ç»„
                    def generateGlobalAvailable(maxZoom):
                        """ç”Ÿæˆå…¨çƒè¦†ç›–çš„availableæ•°ç»„ï¼Œæ ¹æ®ä¼ é€’çš„å±‚çº§èŒƒå›´ç”Ÿæˆ"""
                        # ä½¿ç”¨å®é™…çš„æœ€å¤§ç¼©æ”¾çº§åˆ«ï¼Œè€Œä¸æ˜¯å›ºå®šå€¼
                        globalAvailable = []
                        for zoom in range(maxZoom + 1):
                            endX = (2 ** (zoom + 1)) - 1
                            endY = (2 ** zoom) - 1
                            globalAvailable.append([{
                                "startY": 0,
                                "startX": 0, 
                                "endY": endY,
                                "endX": endX
                            }])
                        return globalAvailable
                    
                    # æ‰¾åˆ°æœ€å¤§çš„zoomçº§åˆ«
                    maxZoomLevel = 0
                    for layerInfo in layerJsons:
                        if "available" in layerInfo["data"]:
                            maxZoomLevel = max(maxZoomLevel, len(layerInfo["data"]["available"]))
                    
                    # ä½¿ç”¨å…¨çƒé€šç”¨é…ç½®
                    mergedLayerJson["available"] = generateGlobalAvailable(maxZoomLevel - 1)
                    logMessage(f"ä½¿ç”¨å…¨çƒé€šç”¨availableé…ç½®: æœ€å¤§zoomçº§åˆ« {maxZoomLevel - 1}")
                else:
                    logMessage("åªæœ‰ä¸€ä¸ªlayer.jsonæ–‡ä»¶ï¼Œæ— éœ€åˆå¹¶availableæ•°ç»„")
                
                # æ›´æ–°æè¿°ä¿¡æ¯ - é¿å…åœ¨æœ‰å¤§é‡æ–‡ä»¶æ—¶å†™å…¥ä¸åˆé€‚çš„æè¿°
                if len(sourceDirs) <= 10:
                    mergedLayerJson["description"] = f"åˆå¹¶åœ°å½¢ç“¦ç‰‡ - {len(sourceDirs)}ä¸ªæ•°æ®æº"
                else:
                    mergedLayerJson["description"] = "åˆå¹¶åœ°å½¢ç“¦ç‰‡"
                
                # å†™å…¥åˆå¹¶åçš„layer.json
                mergedLayerPath = os.path.join(mergedPath, "layer.json")
                with open(mergedLayerPath, 'w') as f:
                    json.dump(mergedLayerJson, f, indent=2)
                
                logMessage(f"ç”Ÿæˆåˆå¹¶åçš„layer.json: {mergedLayerPath}")
                
            except Exception as e:
                logMessage(f"åˆå¹¶layer.jsonå¤±è´¥: {e}", "WARNING")
        
        logMessage(f"åœ°å½¢åˆå¹¶å®Œæˆ - æ€»ç“¦ç‰‡: {totalTiles}, åˆå¹¶: {mergedTiles}, è·³è¿‡: {skippedTiles}")
        
        # åˆ é™¤åŸå§‹çš„ file_xxxx_xxx æ ¼å¼æ–‡ä»¶å¤¹
        deletedDirs = []
        for sourceDir in sourceDirs:
            dirName = os.path.basename(sourceDir)
            # åªåˆ é™¤ file_xxxx_xxx æ ¼å¼çš„ç›®å½•
            if dirName.startswith('file_') and '_' in dirName[5:]:
                try:
                    import shutil
                    shutil.rmtree(sourceDir)
                    deletedDirs.append(sourceDir)
                    logMessage(f"å·²åˆ é™¤åŸå§‹åœ°å½¢ç›®å½•: {sourceDir}")
                except Exception as e:
                    logMessage(f"åˆ é™¤åŸå§‹åœ°å½¢ç›®å½•å¤±è´¥: {sourceDir} - {e}", "WARNING")
        
        logMessage(f"åœ°å½¢åˆå¹¶å®Œæˆï¼Œå·²åˆ é™¤ {len(deletedDirs)} ä¸ªåŸå§‹ç›®å½•")
        
        # æ‰§è¡Œè¾¹ç•Œå¹³æ»‘å¤„ç†
        smoothResult = smoothTerrainBoundaries(mergedPath, taskId)
        
        return {
            "success": True,
            "mergedPath": mergedPath,
            "totalTiles": totalTiles,
            "mergedTiles": mergedTiles,
            "skippedTiles": skippedTiles,
            "filledTiles": filledTiles,
            "sourceDirs": sourceDirs,
            "deletedDirs": deletedDirs,
            "layerJsonMerged": mergedLayerJson is not None,
            "smoothResult": smoothResult
        }
        
    except Exception as e:
        logMessage(f"åœ°å½¢åˆå¹¶å¤±è´¥: {e}", "ERROR")
        return {
            "success": False,
            "error": str(e)
        }

def containsTerrainFiles(directory):
    """
    æ£€æŸ¥ç›®å½•ä¸­æ˜¯å¦åŒ…å«åœ°å½¢ç“¦ç‰‡æ–‡ä»¶
    
    @param directory è¦æ£€æŸ¥çš„ç›®å½•è·¯å¾„
    @return Trueå¦‚æœåŒ…å«åœ°å½¢æ–‡ä»¶ï¼Œå¦åˆ™False
    """
    try:
        if not os.path.exists(directory) or not os.path.isdir(directory):
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ layer.json æ–‡ä»¶
        if os.path.exists(os.path.join(directory, "layer.json")):
            return True
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°å­—å‘½åçš„ç›®å½•ï¼ˆåœ°å½¢ç“¦ç‰‡å±‚çº§ç›®å½•ï¼‰
        for item in os.listdir(directory):
            itemPath = os.path.join(directory, item)
            if os.path.isdir(itemPath) and item.isdigit():
                # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦æœ‰ .terrain æ–‡ä»¶
                for root, dirs, files in os.walk(itemPath):
                    for file in files:
                        if file.endswith('.terrain'):
                            return True
        
        return False
    except Exception as e:
        logMessage(f"æ£€æŸ¥åœ°å½¢æ–‡ä»¶æ—¶å‡ºé”™: {directory} - {e}", "WARNING")
        return False

def fillTerrainGap(allTileInfo, zoomLevel, x, y, mergedPath):
    """
    å¡«è¡¥åœ°å½¢ç“¦ç‰‡ç©ºéš™
    
    @param allTileInfo æ‰€æœ‰ç“¦ç‰‡ä¿¡æ¯å­—å…¸
    @param zoomLevel ç¼©æ”¾çº§åˆ«
    @param x Xåæ ‡
    @param y Yåæ ‡ 
    @param mergedPath åˆå¹¶è¾“å‡ºè·¯å¾„
    @return æ˜¯å¦æˆåŠŸå¡«è¡¥
    """
    try:
        # å¯»æ‰¾é‚»è¿‘çš„ç“¦ç‰‡è¿›è¡Œå¡«è¡¥
        neighbors = []
        
        # æ£€æŸ¥8ä¸ªæ–¹å‘çš„é‚»è¿‘ç“¦ç‰‡
        directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]
        
        for dx, dy in directions:
            nx, ny = x + dx, y + dy
            if (nx in allTileInfo.get(zoomLevel, {}) and 
                ny in allTileInfo[zoomLevel][nx]):
                neighbors.append(allTileInfo[zoomLevel][nx][ny])
        
        # å¦‚æœæ‰¾åˆ°é‚»è¿‘ç“¦ç‰‡ï¼Œä½¿ç”¨æœ€è¿‘çš„ä¸€ä¸ªè¿›è¡Œå¡«è¡¥
        if neighbors:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„é‚»è¿‘ç“¦ç‰‡
            sourceTile = neighbors[0]
            
            # æ„å»ºç›®æ ‡è·¯å¾„
            targetDir = os.path.join(mergedPath, str(zoomLevel), str(x))
            os.makedirs(targetDir, exist_ok=True)
            targetTile = os.path.join(targetDir, f"{y}.terrain")
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¤åˆ¶é‚»è¿‘ç“¦ç‰‡
            if not os.path.exists(targetTile):
                try:
                    shutil.copy2(sourceTile, targetTile)
                    logMessage(f"å¡«è¡¥ç©ºéš™ç“¦ç‰‡: {zoomLevel}/{x}/{y}.terrain")
                    return True
                except Exception as e:
                    logMessage(f"å¡«è¡¥ç©ºéš™å¤±è´¥: {zoomLevel}/{x}/{y}.terrain - {e}", "WARNING")
                    return False
        
        return False
        
    except Exception as e:
        logMessage(f"å¡«è¡¥ç©ºéš™å¼‚å¸¸: {zoomLevel}/{x}/{y}.terrain - {e}", "WARNING")
        return False
def getTiffGeoInfo(tiff_path):
    """è·å–TIFæ–‡ä»¶çš„åœ°ç†ä¿¡æ¯"""
    try:
        info_cmd = ["gdalinfo", "-json", tiff_path]
        result = runCommand(info_cmd)
        
        if not result["success"]:
            return None
        
        import json
        info_data = json.loads(result["output"])
        
        geo_info = {
            "file_path": tiff_path,
            "filename": os.path.basename(tiff_path),
            "bounds": None,
            "pixel_size": None,
            "projection": None
        }
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        if "wgs84Extent" in info_data:
            extent = info_data["wgs84Extent"]["coordinates"][0]
            min_x = min(coord[0] for coord in extent)
            max_x = max(coord[0] for coord in extent)
            min_y = min(coord[1] for coord in extent)
            max_y = max(coord[1] for coord in extent)
            geo_info["bounds"] = [min_x, min_y, max_x, max_y]
        
        # è·å–åƒç´ å¤§å°
        geoTransform = info_data.get("geoTransform", [])
        if len(geoTransform) >= 6:
            geo_info["pixel_size"] = [abs(geoTransform[1]), abs(geoTransform[5])]
        
        # è·å–æŠ•å½±ä¿¡æ¯
        coord_system = info_data.get("coordinateSystem", {})
        if "wkt" in coord_system:
            geo_info["projection"] = coord_system["wkt"]
        
        return geo_info
        
    except Exception as e:
        logMessage(f"è·å–TIFåœ°ç†ä¿¡æ¯å¼‚å¸¸: {e}", "WARNING")
        return None

def canMergeTiffs(tiff1_info, tiff2_info, tolerance=0.001):
    """åˆ¤æ–­ä¸¤ä¸ªTIFæ–‡ä»¶æ˜¯å¦å¯ä»¥åˆå¹¶"""
    try:
        # æ£€æŸ¥æŠ•å½±æ˜¯å¦ç›¸åŒ
        if tiff1_info.get("projection") != tiff2_info.get("projection"):
            return False
        
        # æ£€æŸ¥åƒç´ å¤§å°æ˜¯å¦ç›¸è¿‘
        pixel1 = tiff1_info.get("pixel_size")
        pixel2 = tiff2_info.get("pixel_size")
        if pixel1 and pixel2:
            if (abs(pixel1[0] - pixel2[0]) > tolerance or 
                abs(pixel1[1] - pixel2[1]) > tolerance):
                return False
        
        # æ£€æŸ¥æ˜¯å¦ç›¸é‚»æˆ–é‡å 
        bounds1 = tiff1_info.get("bounds")
        bounds2 = tiff2_info.get("bounds")
        
        if bounds1 and bounds2:
            min_x1, min_y1, max_x1, max_y1 = bounds1
            min_x2, min_y2, max_x2, max_y2 = bounds2
            
            # æ£€æŸ¥é—´éš™
            x_gap = max(0, max(min_x1 - max_x2, min_x2 - max_x1))
            y_gap = max(0, max(min_y1 - max_y2, min_y2 - max_y1))
            
            # å…è®¸å°é—´éš™
            pixel_size = pixel1 or [tolerance, tolerance]
            max_gap = max(pixel_size[0], pixel_size[1]) * 2
            
            return x_gap <= max_gap and y_gap <= max_gap
        
        return True
        
    except Exception as e:
        return False

def groupTiffsForMerging(tiff_files):
    """å°†TIFæ–‡ä»¶åˆ†ç»„è¿›è¡Œåˆå¹¶"""
    try:
        logMessage(f"å¼€å§‹åˆ†æ{len(tiff_files)}ä¸ªTIFæ–‡ä»¶")
        
        # è·å–åœ°ç†ä¿¡æ¯
        geo_infos = []
        for tiff_file in tiff_files:
            geo_info = getTiffGeoInfo(tiff_file["fullPath"])
            if geo_info:
                geo_info.update(tiff_file)
                geo_infos.append(geo_info)
        
        if not geo_infos:
            return []
        
        # åˆ†ç»„
        groups = []
        used = set()
        
        for i, info1 in enumerate(geo_infos):
            if i in used:
                continue
            
            current_group = [info1]
            used.add(i)
            
            # æŸ¥æ‰¾å¯åˆå¹¶çš„æ–‡ä»¶
            for j, info2 in enumerate(geo_infos):
                if j in used:
                    continue
                
                can_merge = False
                for group_info in current_group:
                    if canMergeTiffs(group_info, info2):
                        can_merge = True
                        break
                
                if can_merge:
                    current_group.append(info2)
                    used.add(j)
            
            groups.append(current_group)
        
        logMessage(f"åˆ†ç»„å®Œæˆ: {len(groups)}ä¸ªç»„")
        return groups
        
    except Exception as e:
        logMessage(f"åˆ†ç»„å¼‚å¸¸: {e}", "ERROR")
        return []

def mergeTiffGroup(tiff_group, output_dir, group_index):
    """åˆå¹¶ä¸€ç»„TIFæ–‡ä»¶"""
    try:
        if len(tiff_group) == 1:
            return tiff_group[0]
        
        logMessage(f"åˆå¹¶ç¬¬{group_index}ç»„çš„{len(tiff_group)}ä¸ªæ–‡ä»¶")
        
        merged_filename = f"merged_group_{group_index:03d}.tif"
        merged_path = os.path.join(output_dir, merged_filename)
        
        file_paths = [info["file_path"] for info in tiff_group]
        
        merge_cmd = [
            "gdalwarp",
            "-r", "cubic",
            "-co", "COMPRESS=LZW",
            "-co", "TILED=YES",
            "-srcnodata", "0",
            "-dstnodata", "0",
            "-multi"
        ] + file_paths + [merged_path]
        
        result = runCommand(merge_cmd)
        
        if result["success"] and os.path.exists(merged_path):
            logMessage(f"ç¬¬{group_index}ç»„åˆå¹¶æˆåŠŸ")
            return {
                "fullPath": merged_path,
                "filename": merged_filename,
                "relativePath": merged_filename,
                "is_merged": True,
                "source_files": [info["filename"] for info in tiff_group]
            }
        else:
            logMessage(f"ç¬¬{group_index}ç»„åˆå¹¶å¤±è´¥", "ERROR")
            return None
            
    except Exception as e:
        logMessage(f"åˆå¹¶å¼‚å¸¸: {e}", "ERROR")
        return None

def preprocessTiffsWithMerging(tiff_files, output_path, task_id):
    """é¢„å¤„ç†TIFæ–‡ä»¶ï¼šæ™ºèƒ½åˆå¹¶"""
    try:
        logMessage("ğŸ” å¼€å§‹TIFæ–‡ä»¶æ™ºèƒ½åˆå¹¶é¢„å¤„ç†")
        
        merge_temp_dir = os.path.join(output_path, "temp_merged_tiffs")
        os.makedirs(merge_temp_dir, exist_ok=True)
        
        tiff_groups = groupTiffsForMerging(tiff_files)
        
        if not tiff_groups:
            return tiff_files
        
        processed_files = []
        for group_index, tiff_group in enumerate(tiff_groups):
            merged_file = mergeTiffGroup(tiff_group, merge_temp_dir, group_index)
            if merged_file:
                processed_files.append(merged_file)
            else:
                processed_files.extend(tiff_group)
        
        logMessage(f"âœ… é¢„å¤„ç†å®Œæˆ: {len(tiff_files)} -> {len(processed_files)} ä¸ªæ–‡ä»¶")
        return processed_files
        
    except Exception as e:
        logMessage(f"é¢„å¤„ç†å¼‚å¸¸: {e}", "ERROR")
        return tiff_files
